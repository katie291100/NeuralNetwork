{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of INT2_Group2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install captum\n",
    "pip install flask_compress\n",
    "conda install freetype=2.10.4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/first_visualization_test2')"
   ],
   "metadata": {
    "id": "TNY_v8m0ih6G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance\n",
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.attr_vis.features import ImageFeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ],
   "metadata": {
    "id": "BwDdxZ-LiiKI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available(): # use gpu if possible\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "JR6ZVgNKiiNH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "epochs = 4000\n",
    "batch_size = 200\n",
    "learning_rate = 0.00015\n",
    "\n",
    "# only need resize so AlexNet works\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomAffine(0, (0.1, 0.1)),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# get training/test data from CIFAR10 dataset\n",
    "train_data = torchvision.datasets.CIFAR10(root = \"./dataset/train\",\n",
    "                                        train = True, \n",
    "                                        transform = train_transform, \n",
    "                                        download = True)\n",
    "test_data = torchvision.datasets.CIFAR10(root = \"./dataset/test\",\n",
    "                                       train = False, \n",
    "                                       transform = test_transform, \n",
    "                                       download = True)\n",
    "\n",
    "_, valid = torch.utils.data.random_split(test_data,[5000,5000])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle = True, \n",
    "                                           num_workers = 3)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = False, \n",
    "                                          num_workers = 3)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle = False, num_workers = 3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(3, 128, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(128, 128, 3, 1, padding=2)\n",
    "    self.conv3 = nn.Conv2d(128, 128, 3, 1, padding=2)\n",
    "    self.conv4 = nn.Conv2d(128, 128, 3, 1, padding=1)\n",
    "    self.conv5 = nn.Conv2d(128, 128, 3, 1, padding=1)\n",
    "    self.conv6 = nn.Conv2d(128, 128, 3, 1)\n",
    "    self.conv7 = nn.Conv2d(128, 256, 3, 1)\n",
    "\n",
    "    self.maxPool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    self.drop1 = nn.Dropout(0.1)\n",
    "    self.drop2 = nn.Dropout(0.2)\n",
    "    self.drop3 = nn.Dropout(0.3)\n",
    "    self.drop4 = nn.Dropout(0.4)\n",
    "\n",
    "    self.BN1 = nn.BatchNorm2d(128)\n",
    "    self.BN2 = nn.BatchNorm2d(128)\n",
    "    self.BN3 = nn.BatchNorm2d(128)\n",
    "\n",
    "    self.fc1 = nn.Linear(256, 128)\n",
    "    self.fc2 = nn.Linear(128, 64)\n",
    "    self.fc3 = nn.Linear(64, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = nn.functional.rrelu(self.conv1(x))\n",
    "    x = self.maxPool(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv2(x))\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop1(x)\n",
    "\n",
    "    x = self.BN1(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv3(x))\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv4(x))\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop2(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv5(x))\n",
    "    x = self.BN2(x)\n",
    "    x = self.drop3(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv6(x))\n",
    "    x = self.drop4(x)\n",
    "   x = self.BN3(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv7(x))\n",
    "\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    #print(x.shape)\n",
    "    x = nn.functional.rrelu(self.fc1(x))\n",
    "    x = nn.functional.rrelu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Model creation\n",
    "\n",
    "model_copy = CNN()\n",
    "model = CNN().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    try:\n",
    "      npimg = img.numpy()\n",
    "    except:\n",
    "      npimg = img.cpu().data.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().data.numpy())\n",
    "    return preds, [nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            train_data.classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            train_data.classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def test():\n",
    "  print(\"Testing\")\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "\n",
    "    for (images, labels) in test_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predictions = outputs.max(1)\n",
    "\n",
    "      samples += labels.size(0)\n",
    "      correct += (predictions == labels).sum()\n",
    "    accuracy = 100*float(correct)/float(samples)\n",
    "    print(\"Test accuracy was\", accuracy)\n",
    "    if accuracy>87:\n",
    "        test_per_epoch ==True\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1 complete\n",
      "Loss was 2.019647005081177\n",
      "\n",
      "Training\n",
      "Epoch 2 complete\n",
      "Loss was 1.7277252378463746\n",
      "\n",
      "Training\n",
      "Epoch 3 complete\n",
      "Loss was 1.6051479272842408\n",
      "\n",
      "Training\n",
      "Epoch 4 complete\n",
      "Loss was 1.5304845929145814\n",
      "\n",
      "Training\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "# try other loss functions/optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.0015)\n",
    "\n",
    "test_per_epoch = False\n",
    "train_for_time = 0 # how many minutes to train for (and then finish current epoch)\n",
    "\n",
    "if train_for_time:\n",
    "  epochs = train_for_time*1000\n",
    "start = time.time()\n",
    "losses = []\n",
    "validls = []\n",
    "for epoch in range(epochs):\n",
    "  print(\"Training\")\n",
    "  epoch_loss = 0\n",
    "  previous_loss = 0\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forwards\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # backwards\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "  for data, labels in validloader:\n",
    "    if torch.cuda.is_available():\n",
    "        data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    target = model(data)\n",
    "    loss = criterion(target,labels)\n",
    "    valid_loss = loss.item() * data.size(0)\n",
    "  validls.append(valid_loss / len(validloader))\n",
    "    # if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "    #\n",
    "    #         # ...log the running loss\n",
    "    #         writer.add_scalar('training loss',\n",
    "    #                         epoch_loss-previous_loss / 1000,\n",
    "    #                         epoch * len(train_loader) + i)\n",
    "    #\n",
    "    #         # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "    #         # random mini-batch\n",
    "    #         writer.add_figure('predictions vs. actuals',\n",
    "    #                         plot_classes_preds(model, images, labels),\n",
    "    #                         global_step=epoch * len(train_loader) + i)\n",
    "    #         previous_loss = epoch_loss\n",
    "  \n",
    "  print(\"Epoch\", epoch+1, \"complete\")\n",
    "  print(\"Loss was\", epoch_loss/len(train_loader))\n",
    "  losses.append(epoch_loss/len(train_loader))\n",
    "  print()\n",
    "  if (epoch+1)%5 == 0 or test_per_epoch == True:\n",
    "    test()\n",
    "\n",
    "  \n",
    "  if train_for_time and time.time()-start >= train_for_time*60:\n",
    "    break\n",
    "\n",
    "if not test_per_epoch:\n",
    "  test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([losses, validls])\n",
    "df.to_csv(\"./outputnoBN2.csv\", sep = ',', index = True)"
   ],
   "metadata": {
    "id": "bYyMlOlfiyV6",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_graph(model_copy, images)\n",
    "writer.add_image('first_visualization_test', img_grid)\n",
    "writer.close()"
   ],
   "metadata": {
    "id": "bGHX3IX3iyYc",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/first_visualization_test/"
   ],
   "metadata": {
    "id": "A-g1rugJiybL",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}