{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of INT2_Group2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install captum\n",
    "pip install flask_compress\n",
    "conda install freetype=2.10.4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/first_visualization_test2')"
   ],
   "metadata": {
    "id": "TNY_v8m0ih6G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance\n",
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.attr_vis.features import ImageFeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ],
   "metadata": {
    "id": "BwDdxZ-LiiKI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available(): # use gpu if possible\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "JR6ZVgNKiiNH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "epochs = 4000\n",
    "batch_size = 200\n",
    "learning_rate = 0.00015\n",
    "\n",
    "# only need resize so AlexNet works\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomAffine(0, (0.1, 0.1)),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# get training/test data from CIFAR10 dataset\n",
    "train_data = torchvision.datasets.CIFAR10(root = \"./dataset/train\",\n",
    "                                        train = True, \n",
    "                                        transform = train_transform, \n",
    "                                        download = True)\n",
    "test_data = torchvision.datasets.CIFAR10(root = \"./dataset/test\",\n",
    "                                       train = False, \n",
    "                                       transform = test_transform, \n",
    "                                       download = True)\n",
    "\n",
    "_, valid = torch.utils.data.random_split(train_data,[40000,10000])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle = True, \n",
    "                                           num_workers = 3)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = False, \n",
    "                                          num_workers = 3)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle = False, num_workers = 3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(3, 128, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(128, 128, 3, 1, padding=2)\n",
    "    self.conv3 = nn.Conv2d(128, 128, 3, 1, padding=2)\n",
    "    self.conv4 = nn.Conv2d(128, 128, 3, 1, padding=1)\n",
    "    self.conv5 = nn.Conv2d(128, 128, 3, 1, padding=1)\n",
    "    self.conv6 = nn.Conv2d(128, 128, 3, 1)\n",
    "    self.conv7 = nn.Conv2d(128, 256, 3, 1)\n",
    "\n",
    "    self.maxPool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    self.drop1 = nn.Dropout(0.1)\n",
    "    self.drop2 = nn.Dropout(0.2)\n",
    "    self.drop3 = nn.Dropout(0.3)\n",
    "    self.drop4 = nn.Dropout(0.4)\n",
    "\n",
    "    self.BN1 = nn.BatchNorm2d(128)\n",
    "    self.BN2 = nn.BatchNorm2d(128)\n",
    "    self.BN3 = nn.BatchNorm2d(128)\n",
    "\n",
    "    self.fc1 = nn.Linear(256, 128)\n",
    "    self.fc2 = nn.Linear(128, 64)\n",
    "    self.fc3 = nn.Linear(64, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = nn.functional.rrelu(self.conv1(x))\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop1(x)\n",
    "    x = nn.functional.rrelu(self.conv2(x))\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop2(x)\n",
    "\n",
    "    x = self.BN1(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv3(x))\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv4(x))\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop3(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv5(x))\n",
    "    x = self.BN2(x)\n",
    "    x = nn.functional.rrelu(self.conv6(x))\n",
    "    x = self.drop4(x)\n",
    "  # x = self.BN3(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv7(x))\n",
    "\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    #print(x.shape)\n",
    "    x = nn.functional.rrelu(self.fc1(x))\n",
    "    x = nn.functional.rrelu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Model creation\n",
    "\n",
    "model_copy = CNN()\n",
    "model = CNN().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    try:\n",
    "      npimg = img.numpy()\n",
    "    except:\n",
    "      npimg = img.cpu().data.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().data.numpy())\n",
    "    return preds, [nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            train_data.classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            train_data.classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def test():\n",
    "  print(\"Testing\")\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "\n",
    "    for (images, labels) in test_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predictions = outputs.max(1)\n",
    "\n",
    "      samples += labels.size(0)\n",
    "      correct += (predictions == labels).sum()\n",
    "    accuracy = 100*float(correct)/float(samples)\n",
    "    print(\"Test accuracy was\", accuracy)\n",
    "    if accuracy>87:\n",
    "        test_per_epoch ==True\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1 complete\n",
      "Loss was 1.6752411885261536\n",
      "\n",
      "Training\n",
      "Epoch 2 complete\n",
      "Loss was 1.281756992816925\n",
      "\n",
      "Training\n",
      "Epoch 3 complete\n",
      "Loss was 1.0968960082530976\n",
      "\n",
      "Training\n",
      "Epoch 4 complete\n",
      "Loss was 0.9687043390274048\n",
      "\n",
      "Training\n",
      "Epoch 5 complete\n",
      "Loss was 0.8817346630096435\n",
      "\n",
      "Testing\n",
      "Test accuracy was 70.51\n",
      "\n",
      "Training\n",
      "Epoch 6 complete\n",
      "Loss was 0.8212356503009797\n",
      "\n",
      "Training\n",
      "Epoch 7 complete\n",
      "Loss was 0.7708401901721954\n",
      "\n",
      "Training\n",
      "Epoch 8 complete\n",
      "Loss was 0.7336975312232972\n",
      "\n",
      "Training\n",
      "Epoch 9 complete\n",
      "Loss was 0.7028331615924835\n",
      "\n",
      "Training\n",
      "Epoch 10 complete\n",
      "Loss was 0.677280164718628\n",
      "\n",
      "Testing\n",
      "Test accuracy was 76.43\n",
      "\n",
      "Training\n",
      "Epoch 11 complete\n",
      "Loss was 0.6502639662027359\n",
      "\n",
      "Training\n",
      "Epoch 12 complete\n",
      "Loss was 0.6308128113746643\n",
      "\n",
      "Training\n",
      "Epoch 13 complete\n",
      "Loss was 0.6145459841489792\n",
      "\n",
      "Training\n",
      "Epoch 14 complete\n",
      "Loss was 0.5985185290575028\n",
      "\n",
      "Training\n",
      "Epoch 15 complete\n",
      "Loss was 0.5819947687387467\n",
      "\n",
      "Testing\n",
      "Test accuracy was 79.37\n",
      "\n",
      "Training\n",
      "Epoch 16 complete\n",
      "Loss was 0.5661356828212738\n",
      "\n",
      "Training\n",
      "Epoch 17 complete\n",
      "Loss was 0.5555788851976394\n",
      "\n",
      "Training\n",
      "Epoch 18 complete\n",
      "Loss was 0.5399199911355972\n",
      "\n",
      "Training\n",
      "Epoch 19 complete\n",
      "Loss was 0.5346647981405258\n",
      "\n",
      "Training\n",
      "Epoch 20 complete\n",
      "Loss was 0.5206866409778595\n",
      "\n",
      "Testing\n",
      "Test accuracy was 80.35\n",
      "\n",
      "Training\n",
      "Epoch 21 complete\n",
      "Loss was 0.5105530908107757\n",
      "\n",
      "Training\n",
      "Epoch 22 complete\n",
      "Loss was 0.5055625432729721\n",
      "\n",
      "Training\n",
      "Epoch 23 complete\n",
      "Loss was 0.48968568444252014\n",
      "\n",
      "Training\n",
      "Epoch 24 complete\n",
      "Loss was 0.48408639717102053\n",
      "\n",
      "Training\n",
      "Epoch 25 complete\n",
      "Loss was 0.4746352645158768\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.98\n",
      "\n",
      "Training\n",
      "Epoch 26 complete\n",
      "Loss was 0.47464994323253634\n",
      "\n",
      "Training\n",
      "Epoch 27 complete\n",
      "Loss was 0.45729868733882906\n",
      "\n",
      "Training\n",
      "Epoch 28 complete\n",
      "Loss was 0.45305870175361634\n",
      "\n",
      "Training\n",
      "Epoch 29 complete\n",
      "Loss was 0.4505704470872879\n",
      "\n",
      "Training\n",
      "Epoch 30 complete\n",
      "Loss was 0.4416317272186279\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.29\n",
      "\n",
      "Training\n",
      "Epoch 31 complete\n",
      "Loss was 0.4325208611488342\n",
      "\n",
      "Training\n",
      "Epoch 32 complete\n",
      "Loss was 0.43171292638778686\n",
      "\n",
      "Training\n",
      "Epoch 33 complete\n",
      "Loss was 0.42638213133811953\n",
      "\n",
      "Training\n",
      "Epoch 34 complete\n",
      "Loss was 0.4223482213020325\n",
      "\n",
      "Training\n",
      "Epoch 35 complete\n",
      "Loss was 0.41424130129814146\n",
      "\n",
      "Testing\n",
      "Test accuracy was 83.21\n",
      "\n",
      "Training\n",
      "Epoch 36 complete\n",
      "Loss was 0.4068641037940979\n",
      "\n",
      "Training\n",
      "Epoch 37 complete\n",
      "Loss was 0.4067480527162552\n",
      "\n",
      "Training\n",
      "Epoch 38 complete\n",
      "Loss was 0.4002445347905159\n",
      "\n",
      "Training\n",
      "Epoch 39 complete\n",
      "Loss was 0.39804065907001496\n",
      "\n",
      "Training\n",
      "Epoch 40 complete\n",
      "Loss was 0.3951464046239853\n",
      "\n",
      "Testing\n",
      "Test accuracy was 84.14\n",
      "\n",
      "Training\n",
      "Epoch 41 complete\n",
      "Loss was 0.3896080331802368\n",
      "\n",
      "Training\n",
      "Epoch 42 complete\n",
      "Loss was 0.3804774469733238\n",
      "\n",
      "Training\n",
      "Epoch 43 complete\n",
      "Loss was 0.3798176915049553\n",
      "\n",
      "Training\n",
      "Epoch 44 complete\n",
      "Loss was 0.3792943058013916\n",
      "\n",
      "Training\n",
      "Epoch 45 complete\n",
      "Loss was 0.3704860742688179\n",
      "\n",
      "Testing\n",
      "Test accuracy was 83.62\n",
      "\n",
      "Training\n",
      "Epoch 46 complete\n",
      "Loss was 0.3721861657500267\n",
      "\n",
      "Training\n",
      "Epoch 47 complete\n",
      "Loss was 0.3603412021994591\n",
      "\n",
      "Training\n",
      "Epoch 48 complete\n",
      "Loss was 0.36359213310480115\n",
      "\n",
      "Training\n",
      "Epoch 49 complete\n",
      "Loss was 0.3592913922071457\n",
      "\n",
      "Training\n",
      "Epoch 50 complete\n",
      "Loss was 0.3564520226716995\n",
      "\n",
      "Testing\n",
      "Test accuracy was 84.58\n",
      "\n",
      "Training\n",
      "Epoch 51 complete\n",
      "Loss was 0.3530249200463295\n",
      "\n",
      "Training\n",
      "Epoch 52 complete\n",
      "Loss was 0.3500868749022484\n",
      "\n",
      "Training\n",
      "Epoch 53 complete\n",
      "Loss was 0.3486417964696884\n",
      "\n",
      "Training\n",
      "Epoch 54 complete\n",
      "Loss was 0.34877485769987104\n",
      "\n",
      "Training\n",
      "Epoch 55 complete\n",
      "Loss was 0.34460754406452176\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.25\n",
      "\n",
      "Training\n",
      "Epoch 56 complete\n",
      "Loss was 0.3412382630109787\n",
      "\n",
      "Training\n",
      "Epoch 57 complete\n",
      "Loss was 0.3373143915534019\n",
      "\n",
      "Training\n",
      "Epoch 58 complete\n",
      "Loss was 0.3314906288981438\n",
      "\n",
      "Training\n",
      "Epoch 59 complete\n",
      "Loss was 0.3350704766511917\n",
      "\n",
      "Training\n",
      "Epoch 60 complete\n",
      "Loss was 0.33215626049041747\n",
      "\n",
      "Testing\n",
      "Test accuracy was 84.85\n",
      "\n",
      "Training\n",
      "Epoch 61 complete\n",
      "Loss was 0.32806980019807813\n",
      "\n",
      "Training\n",
      "Epoch 62 complete\n",
      "Loss was 0.3245907554626465\n",
      "\n",
      "Training\n",
      "Epoch 63 complete\n",
      "Loss was 0.32158518463373187\n",
      "\n",
      "Training\n",
      "Epoch 64 complete\n",
      "Loss was 0.32058737593889236\n",
      "\n",
      "Training\n",
      "Epoch 65 complete\n",
      "Loss was 0.3212905108332634\n",
      "\n",
      "Testing\n",
      "Test accuracy was 84.85\n",
      "\n",
      "Training\n",
      "Epoch 66 complete\n",
      "Loss was 0.315421869635582\n",
      "\n",
      "Training\n",
      "Epoch 67 complete\n",
      "Loss was 0.31562225222587587\n",
      "\n",
      "Training\n",
      "Epoch 68 complete\n",
      "Loss was 0.31324392235279086\n",
      "\n",
      "Training\n",
      "Epoch 69 complete\n",
      "Loss was 0.3103189038038254\n",
      "\n",
      "Training\n",
      "Epoch 70 complete\n",
      "Loss was 0.30819745498895645\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.05\n",
      "\n",
      "Training\n",
      "Epoch 71 complete\n",
      "Loss was 0.30914775615930556\n",
      "\n",
      "Training\n",
      "Epoch 72 complete\n",
      "Loss was 0.31091348922252654\n",
      "\n",
      "Training\n",
      "Epoch 73 complete\n",
      "Loss was 0.30529321885108945\n",
      "\n",
      "Training\n",
      "Epoch 74 complete\n",
      "Loss was 0.303797820687294\n",
      "\n",
      "Training\n",
      "Epoch 75 complete\n",
      "Loss was 0.3013524710536003\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.67\n",
      "\n",
      "Training\n",
      "Epoch 76 complete\n",
      "Loss was 0.29838641780614855\n",
      "\n",
      "Training\n",
      "Epoch 77 complete\n",
      "Loss was 0.29259719455242156\n",
      "\n",
      "Training\n",
      "Epoch 78 complete\n",
      "Loss was 0.29982428419589996\n",
      "\n",
      "Training\n",
      "Epoch 79 complete\n",
      "Loss was 0.2906597829461098\n",
      "\n",
      "Training\n",
      "Epoch 80 complete\n",
      "Loss was 0.29579653549194335\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.2\n",
      "\n",
      "Training\n",
      "Epoch 81 complete\n",
      "Loss was 0.29051964163780214\n",
      "\n",
      "Training\n",
      "Epoch 82 complete\n",
      "Loss was 0.2895276585817337\n",
      "\n",
      "Training\n",
      "Epoch 83 complete\n",
      "Loss was 0.2906919732093811\n",
      "\n",
      "Training\n",
      "Epoch 84 complete\n",
      "Loss was 0.2888606539964676\n",
      "\n",
      "Training\n",
      "Epoch 85 complete\n",
      "Loss was 0.28735522270202635\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.69\n",
      "\n",
      "Training\n",
      "Epoch 86 complete\n",
      "Loss was 0.2833621626496315\n",
      "\n",
      "Training\n",
      "Epoch 87 complete\n",
      "Loss was 0.2813178861141205\n",
      "\n",
      "Training\n",
      "Epoch 88 complete\n",
      "Loss was 0.2841331980228424\n",
      "\n",
      "Training\n",
      "Epoch 89 complete\n",
      "Loss was 0.28377868968248365\n",
      "\n",
      "Training\n",
      "Epoch 90 complete\n",
      "Loss was 0.2818159802556038\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.43\n",
      "\n",
      "Training\n",
      "Epoch 91 complete\n",
      "Loss was 0.27911054611206054\n",
      "\n",
      "Training\n",
      "Epoch 92 complete\n",
      "Loss was 0.27910498428344727\n",
      "\n",
      "Training\n",
      "Epoch 93 complete\n",
      "Loss was 0.2760988486409187\n",
      "\n",
      "Training\n",
      "Epoch 94 complete\n",
      "Loss was 0.2749569222331047\n",
      "\n",
      "Training\n",
      "Epoch 95 complete\n",
      "Loss was 0.27561679303646086\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.95\n",
      "\n",
      "Training\n",
      "Epoch 96 complete\n",
      "Loss was 0.2716449544429779\n",
      "\n",
      "Training\n",
      "Epoch 97 complete\n",
      "Loss was 0.2696074000597\n",
      "\n",
      "Training\n",
      "Epoch 98 complete\n",
      "Loss was 0.2713611268401146\n",
      "\n",
      "Training\n",
      "Epoch 99 complete\n",
      "Loss was 0.2677830904722214\n",
      "\n",
      "Training\n",
      "Epoch 100 complete\n",
      "Loss was 0.26594997811317445\n",
      "\n",
      "Testing\n",
      "Test accuracy was 85.99\n",
      "\n",
      "Training\n",
      "Epoch 101 complete\n",
      "Loss was 0.2724250226020813\n",
      "\n",
      "Training\n",
      "Epoch 102 complete\n",
      "Loss was 0.26680356401205063\n",
      "\n",
      "Training\n",
      "Epoch 103 complete\n",
      "Loss was 0.26685524278879164\n",
      "\n",
      "Training\n",
      "Epoch 104 complete\n",
      "Loss was 0.26468995147943497\n",
      "\n",
      "Training\n",
      "Epoch 105 complete\n",
      "Loss was 0.26487059265375135\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.23\n",
      "\n",
      "Training\n",
      "Epoch 106 complete\n",
      "Loss was 0.2596268305182457\n",
      "\n",
      "Training\n",
      "Epoch 107 complete\n",
      "Loss was 0.2633722974061966\n",
      "\n",
      "Training\n",
      "Epoch 108 complete\n",
      "Loss was 0.260433458507061\n",
      "\n",
      "Training\n",
      "Epoch 109 complete\n",
      "Loss was 0.2588413817286491\n",
      "\n",
      "Training\n",
      "Epoch 110 complete\n",
      "Loss was 0.2577271814644337\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.45\n",
      "\n",
      "Training\n",
      "Epoch 111 complete\n",
      "Loss was 0.2641010500192642\n",
      "\n",
      "Training\n",
      "Epoch 112 complete\n",
      "Loss was 0.259353639960289\n",
      "\n",
      "Training\n",
      "Epoch 113 complete\n",
      "Loss was 0.2590863245725632\n",
      "\n",
      "Training\n",
      "Epoch 114 complete\n",
      "Loss was 0.2581588668823242\n",
      "\n",
      "Training\n",
      "Epoch 115 complete\n",
      "Loss was 0.2568518052697182\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.84\n",
      "\n",
      "Training\n",
      "Epoch 116 complete\n",
      "Loss was 0.25392856645584105\n",
      "\n",
      "Training\n",
      "Epoch 117 complete\n",
      "Loss was 0.25238106405735017\n",
      "\n",
      "Training\n",
      "Epoch 118 complete\n",
      "Loss was 0.2553143933713436\n",
      "\n",
      "Training\n",
      "Epoch 119 complete\n",
      "Loss was 0.2542207579612732\n",
      "\n",
      "Training\n",
      "Epoch 120 complete\n",
      "Loss was 0.2509250963330269\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.61\n",
      "\n",
      "Training\n",
      "Epoch 121 complete\n",
      "Loss was 0.24745859977602958\n",
      "\n",
      "Training\n",
      "Epoch 122 complete\n",
      "Loss was 0.2465100173354149\n",
      "\n",
      "Training\n",
      "Epoch 123 complete\n",
      "Loss was 0.248709867477417\n",
      "\n",
      "Training\n",
      "Epoch 124 complete\n",
      "Loss was 0.2529864775836468\n",
      "\n",
      "Training\n",
      "Epoch 125 complete\n",
      "Loss was 0.2448984629511833\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.39\n",
      "\n",
      "Training\n",
      "Epoch 126 complete\n",
      "Loss was 0.2499046869277954\n",
      "\n",
      "Training\n",
      "Epoch 127 complete\n",
      "Loss was 0.2484510338306427\n",
      "\n",
      "Training\n",
      "Epoch 128 complete\n",
      "Loss was 0.24811216527223587\n",
      "\n",
      "Training\n",
      "Epoch 129 complete\n",
      "Loss was 0.24453720778226853\n",
      "\n",
      "Training\n",
      "Epoch 130 complete\n",
      "Loss was 0.24181360340118407\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.77\n",
      "\n",
      "Training\n",
      "Epoch 131 complete\n",
      "Loss was 0.24334057295322417\n",
      "\n",
      "Training\n",
      "Epoch 132 complete\n",
      "Loss was 0.24644311064481736\n",
      "\n",
      "Training\n",
      "Epoch 133 complete\n",
      "Loss was 0.24143249708414077\n",
      "\n",
      "Training\n",
      "Epoch 134 complete\n",
      "Loss was 0.2401568526625633\n",
      "\n",
      "Training\n",
      "Epoch 135 complete\n",
      "Loss was 0.23804094284772873\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.12\n",
      "\n",
      "Training\n",
      "Epoch 136 complete\n",
      "Loss was 0.24500002181529998\n",
      "\n",
      "Training\n",
      "Epoch 137 complete\n",
      "Loss was 0.2416179309487343\n",
      "\n",
      "Training\n",
      "Epoch 138 complete\n",
      "Loss was 0.24141793781518936\n",
      "\n",
      "Training\n",
      "Epoch 139 complete\n",
      "Loss was 0.23897588205337525\n",
      "\n",
      "Training\n",
      "Epoch 140 complete\n",
      "Loss was 0.2420079397857189\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.06\n",
      "\n",
      "Training\n",
      "Epoch 141 complete\n",
      "Loss was 0.23973768746852875\n",
      "\n",
      "Training\n",
      "Epoch 142 complete\n",
      "Loss was 0.23864297285676003\n",
      "\n",
      "Training\n",
      "Epoch 143 complete\n",
      "Loss was 0.23831749874353408\n",
      "\n",
      "Training\n",
      "Epoch 144 complete\n",
      "Loss was 0.23467656400799752\n",
      "\n",
      "Training\n",
      "Epoch 145 complete\n",
      "Loss was 0.23831254744529723\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.73\n",
      "\n",
      "Training\n",
      "Epoch 146 complete\n",
      "Loss was 0.2386262686252594\n",
      "\n",
      "Training\n",
      "Epoch 147 complete\n",
      "Loss was 0.2352585520744324\n",
      "\n",
      "Training\n",
      "Epoch 148 complete\n",
      "Loss was 0.23561382484436036\n",
      "\n",
      "Training\n",
      "Epoch 149 complete\n",
      "Loss was 0.23426025435328485\n",
      "\n",
      "Training\n",
      "Epoch 150 complete\n",
      "Loss was 0.23420821699500083\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.95\n",
      "\n",
      "Training\n",
      "Epoch 151 complete\n",
      "Loss was 0.23097496858239175\n",
      "\n",
      "Training\n",
      "Epoch 152 complete\n",
      "Loss was 0.23203866264224052\n",
      "\n",
      "Training\n",
      "Epoch 153 complete\n",
      "Loss was 0.23552835804224015\n",
      "\n",
      "Training\n",
      "Epoch 154 complete\n",
      "Loss was 0.23118684914708137\n",
      "\n",
      "Training\n",
      "Epoch 155 complete\n",
      "Loss was 0.22815019437670708\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.75\n",
      "\n",
      "Training\n",
      "Epoch 156 complete\n",
      "Loss was 0.22787219631671907\n",
      "\n",
      "Training\n",
      "Epoch 157 complete\n",
      "Loss was 0.23182345801591872\n",
      "\n",
      "Training\n",
      "Epoch 158 complete\n",
      "Loss was 0.2289463581442833\n",
      "\n",
      "Training\n",
      "Epoch 159 complete\n",
      "Loss was 0.23109423115849495\n",
      "\n",
      "Training\n",
      "Epoch 160 complete\n",
      "Loss was 0.23015983706712723\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.65\n",
      "\n",
      "Training\n",
      "Epoch 161 complete\n",
      "Loss was 0.2280664724111557\n",
      "\n",
      "Training\n",
      "Epoch 162 complete\n",
      "Loss was 0.22311247700452805\n",
      "\n",
      "Training\n",
      "Epoch 163 complete\n",
      "Loss was 0.23207697945833206\n",
      "\n",
      "Training\n",
      "Epoch 164 complete\n",
      "Loss was 0.22728814753890036\n",
      "\n",
      "Training\n",
      "Epoch 165 complete\n",
      "Loss was 0.22732765072584152\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.01\n",
      "\n",
      "Training\n",
      "Epoch 166 complete\n",
      "Loss was 0.22221110966801644\n",
      "\n",
      "Training\n",
      "Epoch 167 complete\n",
      "Loss was 0.22648722928762435\n",
      "\n",
      "Training\n",
      "Epoch 168 complete\n",
      "Loss was 0.22402118703722954\n",
      "\n",
      "Training\n",
      "Epoch 169 complete\n",
      "Loss was 0.22810196685791015\n",
      "\n",
      "Training\n",
      "Epoch 170 complete\n",
      "Loss was 0.22259390220046044\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.77\n",
      "\n",
      "Training\n",
      "Epoch 171 complete\n",
      "Loss was 0.22629964265227318\n",
      "\n",
      "Training\n",
      "Epoch 172 complete\n",
      "Loss was 0.22131863993406295\n",
      "\n",
      "Training\n",
      "Epoch 173 complete\n",
      "Loss was 0.22515982913970947\n",
      "\n",
      "Training\n",
      "Epoch 174 complete\n",
      "Loss was 0.22195639377832413\n",
      "\n",
      "Training\n",
      "Epoch 175 complete\n",
      "Loss was 0.21546547532081603\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.68\n",
      "\n",
      "Training\n",
      "Epoch 176 complete\n",
      "Loss was 0.22088815170526505\n",
      "\n",
      "Training\n",
      "Epoch 177 complete\n",
      "Loss was 0.22366738203167916\n",
      "\n",
      "Training\n",
      "Epoch 178 complete\n",
      "Loss was 0.22140911358594895\n",
      "\n",
      "Training\n",
      "Epoch 179 complete\n",
      "Loss was 0.22217872938513755\n",
      "\n",
      "Training\n",
      "Epoch 180 complete\n",
      "Loss was 0.22262371507287027\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.91\n",
      "\n",
      "Training\n",
      "Epoch 181 complete\n",
      "Loss was 0.21698261162638663\n",
      "\n",
      "Training\n",
      "Epoch 182 complete\n",
      "Loss was 0.21960126742720604\n",
      "\n",
      "Training\n",
      "Epoch 183 complete\n",
      "Loss was 0.2177291791141033\n",
      "\n",
      "Training\n",
      "Epoch 184 complete\n",
      "Loss was 0.21849618244171143\n",
      "\n",
      "Training\n",
      "Epoch 185 complete\n",
      "Loss was 0.2225095498561859\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.71\n",
      "\n",
      "Training\n",
      "Epoch 186 complete\n",
      "Loss was 0.221102765083313\n",
      "\n",
      "Training\n",
      "Epoch 187 complete\n",
      "Loss was 0.21612889790534973\n",
      "\n",
      "Training\n",
      "Epoch 188 complete\n",
      "Loss was 0.21585052478313446\n",
      "\n",
      "Training\n",
      "Epoch 189 complete\n",
      "Loss was 0.21955034843087196\n",
      "\n",
      "Training\n",
      "Epoch 190 complete\n",
      "Loss was 0.2153745808005333\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.3\n",
      "\n",
      "Training\n",
      "Epoch 191 complete\n",
      "Loss was 0.22158197611570357\n",
      "\n",
      "Training\n",
      "Epoch 192 complete\n",
      "Loss was 0.21731053191423416\n",
      "\n",
      "Training\n",
      "Epoch 193 complete\n",
      "Loss was 0.21801930850744247\n",
      "\n",
      "Training\n",
      "Epoch 194 complete\n",
      "Loss was 0.2116701692342758\n",
      "\n",
      "Training\n",
      "Epoch 195 complete\n",
      "Loss was 0.21543423217535018\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.56\n",
      "\n",
      "Training\n",
      "Epoch 196 complete\n",
      "Loss was 0.22089314302802085\n",
      "\n",
      "Training\n",
      "Epoch 197 complete\n",
      "Loss was 0.21736448484659196\n",
      "\n",
      "Training\n",
      "Epoch 198 complete\n",
      "Loss was 0.21323094281554222\n",
      "\n",
      "Training\n",
      "Epoch 199 complete\n",
      "Loss was 0.21479002076387405\n",
      "\n",
      "Training\n",
      "Epoch 200 complete\n",
      "Loss was 0.2142986654639244\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.86\n",
      "\n",
      "Training\n",
      "Epoch 201 complete\n",
      "Loss was 0.21273207327723503\n",
      "\n",
      "Training\n",
      "Epoch 202 complete\n",
      "Loss was 0.21342145437002183\n",
      "\n",
      "Training\n",
      "Epoch 203 complete\n",
      "Loss was 0.21378639391064644\n",
      "\n",
      "Training\n",
      "Epoch 204 complete\n",
      "Loss was 0.20831326058506966\n",
      "\n",
      "Training\n",
      "Epoch 205 complete\n",
      "Loss was 0.2170107319355011\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.15\n",
      "\n",
      "Training\n",
      "Epoch 206 complete\n",
      "Loss was 0.20932228377461434\n",
      "\n",
      "Training\n",
      "Epoch 207 complete\n",
      "Loss was 0.2119537075459957\n",
      "\n",
      "Training\n",
      "Epoch 208 complete\n",
      "Loss was 0.2146641949415207\n",
      "\n",
      "Training\n",
      "Epoch 209 complete\n",
      "Loss was 0.21508455449342728\n",
      "\n",
      "Training\n",
      "Epoch 210 complete\n",
      "Loss was 0.20898830875754357\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.25\n",
      "\n",
      "Training\n",
      "Epoch 211 complete\n",
      "Loss was 0.21133393809199333\n",
      "\n",
      "Training\n",
      "Epoch 212 complete\n",
      "Loss was 0.2096415833234787\n",
      "\n",
      "Training\n",
      "Epoch 213 complete\n",
      "Loss was 0.21070672088861467\n",
      "\n",
      "Training\n",
      "Epoch 214 complete\n",
      "Loss was 0.2095790787935257\n",
      "\n",
      "Training\n",
      "Epoch 215 complete\n",
      "Loss was 0.21017496559023857\n",
      "\n",
      "Testing\n",
      "Test accuracy was 86.91\n",
      "\n",
      "Training\n",
      "Epoch 216 complete\n",
      "Loss was 0.20400487253069877\n",
      "\n",
      "Training\n",
      "Epoch 217 complete\n",
      "Loss was 0.20972715669870376\n",
      "\n",
      "Training\n",
      "Epoch 218 complete\n",
      "Loss was 0.21124446856975557\n",
      "\n",
      "Training\n",
      "Epoch 219 complete\n",
      "Loss was 0.20951031324267388\n",
      "\n",
      "Training\n",
      "Epoch 220 complete\n",
      "Loss was 0.20879112812876702\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.39\n",
      "\n",
      "Training\n",
      "Epoch 221 complete\n",
      "Loss was 0.2085983137190342\n",
      "\n",
      "Training\n",
      "Epoch 222 complete\n",
      "Loss was 0.2053450227379799\n",
      "\n",
      "Training\n",
      "Epoch 223 complete\n",
      "Loss was 0.20903406968712807\n",
      "\n",
      "Training\n",
      "Epoch 224 complete\n",
      "Loss was 0.20692440405488013\n",
      "\n",
      "Training\n",
      "Epoch 225 complete\n",
      "Loss was 0.20764071896672248\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.36\n",
      "\n",
      "Training\n",
      "Epoch 226 complete\n",
      "Loss was 0.20674421468377113\n",
      "\n",
      "Training\n",
      "Epoch 227 complete\n",
      "Loss was 0.20542954444885253\n",
      "\n",
      "Training\n",
      "Epoch 228 complete\n",
      "Loss was 0.20951350456476212\n",
      "\n",
      "Training\n",
      "Epoch 229 complete\n",
      "Loss was 0.20734831297397613\n",
      "\n",
      "Training\n",
      "Epoch 230 complete\n",
      "Loss was 0.2061499550640583\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.44\n",
      "\n",
      "Training\n",
      "Epoch 231 complete\n",
      "Loss was 0.20153538525104522\n",
      "\n",
      "Training\n",
      "Epoch 232 complete\n",
      "Loss was 0.20327519962191581\n",
      "\n",
      "Training\n",
      "Epoch 233 complete\n",
      "Loss was 0.2076600942313671\n",
      "\n",
      "Training\n",
      "Epoch 234 complete\n",
      "Loss was 0.2034641327857971\n",
      "\n",
      "Training\n",
      "Epoch 235 complete\n",
      "Loss was 0.20094266006350517\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.34\n",
      "\n",
      "Training\n",
      "Epoch 236 complete\n",
      "Loss was 0.2075835652947426\n",
      "\n",
      "Training\n",
      "Epoch 237 complete\n",
      "Loss was 0.20323713797330856\n",
      "\n",
      "Training\n",
      "Epoch 238 complete\n",
      "Loss was 0.20360614275932312\n",
      "\n",
      "Training\n",
      "Epoch 239 complete\n",
      "Loss was 0.19853365170955659\n",
      "\n",
      "Training\n",
      "Epoch 240 complete\n",
      "Loss was 0.20988853999972343\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.62\n",
      "\n",
      "Training\n",
      "Epoch 241 complete\n",
      "Loss was 0.20199326160550118\n",
      "\n",
      "Training\n",
      "Epoch 242 complete\n",
      "Loss was 0.2044165471792221\n",
      "\n",
      "Training\n",
      "Epoch 243 complete\n",
      "Loss was 0.20333616298437118\n",
      "\n",
      "Training\n",
      "Epoch 244 complete\n",
      "Loss was 0.2018634978234768\n",
      "\n",
      "Training\n",
      "Epoch 245 complete\n",
      "Loss was 0.20212072804570197\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.88\n",
      "\n",
      "Training\n",
      "Epoch 246 complete\n",
      "Loss was 0.19893515980243684\n",
      "\n",
      "Training\n",
      "Epoch 247 complete\n",
      "Loss was 0.20261806008219718\n",
      "\n",
      "Training\n",
      "Epoch 248 complete\n",
      "Loss was 0.1980959356725216\n",
      "\n",
      "Training\n",
      "Epoch 249 complete\n",
      "Loss was 0.20207551622390746\n",
      "\n",
      "Training\n",
      "Epoch 250 complete\n",
      "Loss was 0.20543552780151367\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.26\n",
      "\n",
      "Training\n",
      "Epoch 251 complete\n",
      "Loss was 0.19776978132128714\n",
      "\n",
      "Training\n",
      "Epoch 252 complete\n",
      "Loss was 0.20013862910866737\n",
      "\n",
      "Training\n",
      "Epoch 253 complete\n",
      "Loss was 0.19776786348223685\n",
      "\n",
      "Training\n",
      "Epoch 254 complete\n",
      "Loss was 0.19981582283973695\n",
      "\n",
      "Training\n",
      "Epoch 255 complete\n",
      "Loss was 0.19940270826220513\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.62\n",
      "\n",
      "Training\n",
      "Epoch 256 complete\n",
      "Loss was 0.2010101296007633\n",
      "\n",
      "Training\n",
      "Epoch 257 complete\n",
      "Loss was 0.20127799877524377\n",
      "\n",
      "Training\n",
      "Epoch 258 complete\n",
      "Loss was 0.20001981601119043\n",
      "\n",
      "Training\n",
      "Epoch 259 complete\n",
      "Loss was 0.1969359163939953\n",
      "\n",
      "Training\n",
      "Epoch 260 complete\n",
      "Loss was 0.19889209535717964\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.33\n",
      "\n",
      "Training\n",
      "Epoch 261 complete\n",
      "Loss was 0.1985525357723236\n",
      "\n",
      "Training\n",
      "Epoch 262 complete\n",
      "Loss was 0.1981119319498539\n",
      "\n",
      "Training\n",
      "Epoch 263 complete\n",
      "Loss was 0.19778123250603677\n",
      "\n",
      "Training\n",
      "Epoch 264 complete\n",
      "Loss was 0.19986758440732955\n",
      "\n",
      "Training\n",
      "Epoch 265 complete\n",
      "Loss was 0.1969333164393902\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.5\n",
      "\n",
      "Training\n",
      "Epoch 266 complete\n",
      "Loss was 0.19920067900419236\n",
      "\n",
      "Training\n",
      "Epoch 267 complete\n",
      "Loss was 0.19331767219305038\n",
      "\n",
      "Training\n",
      "Epoch 268 complete\n",
      "Loss was 0.19632156056165695\n",
      "\n",
      "Training\n",
      "Epoch 269 complete\n",
      "Loss was 0.19660557913780213\n",
      "\n",
      "Training\n",
      "Epoch 270 complete\n",
      "Loss was 0.19834708732366563\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.24\n",
      "\n",
      "Training\n",
      "Epoch 271 complete\n",
      "Loss was 0.19505947935581208\n",
      "\n",
      "Training\n",
      "Epoch 272 complete\n",
      "Loss was 0.19904120540618897\n",
      "\n",
      "Training\n",
      "Epoch 273 complete\n",
      "Loss was 0.19620899188518523\n",
      "\n",
      "Training\n",
      "Epoch 274 complete\n",
      "Loss was 0.19724117693305016\n",
      "\n",
      "Training\n",
      "Epoch 275 complete\n",
      "Loss was 0.1985438788533211\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.63\n",
      "\n",
      "Training\n",
      "Epoch 276 complete\n",
      "Loss was 0.19598111417889594\n",
      "\n",
      "Training\n",
      "Epoch 277 complete\n",
      "Loss was 0.19883719548583031\n",
      "\n",
      "Training\n",
      "Epoch 278 complete\n",
      "Loss was 0.19817745798826217\n",
      "\n",
      "Training\n",
      "Epoch 279 complete\n",
      "Loss was 0.19673771569132806\n",
      "\n",
      "Training\n",
      "Epoch 280 complete\n",
      "Loss was 0.19495882019400596\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.33\n",
      "\n",
      "Training\n",
      "Epoch 281 complete\n",
      "Loss was 0.19676124680042267\n",
      "\n",
      "Training\n",
      "Epoch 282 complete\n",
      "Loss was 0.1938637274801731\n",
      "\n",
      "Training\n",
      "Epoch 283 complete\n",
      "Loss was 0.1995678118765354\n",
      "\n",
      "Training\n",
      "Epoch 284 complete\n",
      "Loss was 0.1974424846470356\n",
      "\n",
      "Training\n",
      "Epoch 285 complete\n",
      "Loss was 0.19597124928236007\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.17\n",
      "\n",
      "Training\n",
      "Epoch 286 complete\n",
      "Loss was 0.19327122387290002\n",
      "\n",
      "Training\n",
      "Epoch 287 complete\n",
      "Loss was 0.19456361889839172\n",
      "\n",
      "Training\n",
      "Epoch 288 complete\n",
      "Loss was 0.1903757740855217\n",
      "\n",
      "Training\n",
      "Epoch 289 complete\n",
      "Loss was 0.19608164003491402\n",
      "\n",
      "Training\n",
      "Epoch 290 complete\n",
      "Loss was 0.1946155149936676\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.12\n",
      "\n",
      "Training\n",
      "Epoch 291 complete\n",
      "Loss was 0.18927907329797744\n",
      "\n",
      "Training\n",
      "Epoch 292 complete\n",
      "Loss was 0.19912351828813551\n",
      "\n",
      "Training\n",
      "Epoch 293 complete\n",
      "Loss was 0.19140377947688103\n",
      "\n",
      "Training\n",
      "Epoch 294 complete\n",
      "Loss was 0.19518259438872337\n",
      "\n",
      "Training\n",
      "Epoch 295 complete\n",
      "Loss was 0.19320898231863975\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.58\n",
      "\n",
      "Training\n",
      "Epoch 296 complete\n",
      "Loss was 0.1956838900744915\n",
      "\n",
      "Training\n",
      "Epoch 297 complete\n",
      "Loss was 0.19089587700366975\n",
      "\n",
      "Training\n",
      "Epoch 298 complete\n",
      "Loss was 0.19260594496130942\n",
      "\n",
      "Training\n",
      "Epoch 299 complete\n",
      "Loss was 0.19208807745575904\n",
      "\n",
      "Training\n",
      "Epoch 300 complete\n",
      "Loss was 0.19233727556467056\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.92\n",
      "\n",
      "Training\n",
      "Epoch 301 complete\n",
      "Loss was 0.19165122789144515\n",
      "\n",
      "Training\n",
      "Epoch 302 complete\n",
      "Loss was 0.19397298693656922\n",
      "\n",
      "Training\n",
      "Epoch 303 complete\n",
      "Loss was 0.19584659790992737\n",
      "\n",
      "Training\n",
      "Epoch 304 complete\n",
      "Loss was 0.19392019537091254\n",
      "\n",
      "Training\n",
      "Epoch 305 complete\n",
      "Loss was 0.19084389072656632\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.87\n",
      "\n",
      "Training\n",
      "Epoch 306 complete\n",
      "Loss was 0.1890841093957424\n",
      "\n",
      "Training\n",
      "Epoch 307 complete\n",
      "Loss was 0.19351354587078096\n",
      "\n",
      "Training\n",
      "Epoch 308 complete\n",
      "Loss was 0.19251175871491433\n",
      "\n",
      "Training\n",
      "Epoch 309 complete\n",
      "Loss was 0.19490735366940498\n",
      "\n",
      "Training\n",
      "Epoch 310 complete\n",
      "Loss was 0.18795792570710182\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.38\n",
      "\n",
      "Training\n",
      "Epoch 311 complete\n",
      "Loss was 0.1940903082191944\n",
      "\n",
      "Training\n",
      "Epoch 312 complete\n",
      "Loss was 0.1902439311146736\n",
      "\n",
      "Training\n",
      "Epoch 313 complete\n",
      "Loss was 0.19252687108516692\n",
      "\n",
      "Training\n",
      "Epoch 314 complete\n",
      "Loss was 0.1918344895541668\n",
      "\n",
      "Training\n",
      "Epoch 315 complete\n",
      "Loss was 0.1873665770292282\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.75\n",
      "\n",
      "Training\n",
      "Epoch 316 complete\n",
      "Loss was 0.18812283754348755\n",
      "\n",
      "Training\n",
      "Epoch 317 complete\n",
      "Loss was 0.18985770705342292\n",
      "\n",
      "Training\n",
      "Epoch 318 complete\n",
      "Loss was 0.19163526636362077\n",
      "\n",
      "Training\n",
      "Epoch 319 complete\n",
      "Loss was 0.18716922652721404\n",
      "\n",
      "Training\n",
      "Epoch 320 complete\n",
      "Loss was 0.19174896112084389\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.12\n",
      "\n",
      "Training\n",
      "Epoch 321 complete\n",
      "Loss was 0.19224651274085044\n",
      "\n",
      "Training\n",
      "Epoch 322 complete\n",
      "Loss was 0.19041631117463112\n",
      "\n",
      "Training\n",
      "Epoch 323 complete\n",
      "Loss was 0.19069871819019318\n",
      "\n",
      "Training\n",
      "Epoch 324 complete\n",
      "Loss was 0.19194931504130364\n",
      "\n",
      "Training\n",
      "Epoch 325 complete\n",
      "Loss was 0.18775989592075348\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.55\n",
      "\n",
      "Training\n",
      "Epoch 326 complete\n",
      "Loss was 0.18312631916999816\n",
      "\n",
      "Training\n",
      "Epoch 327 complete\n",
      "Loss was 0.1862594931125641\n",
      "\n",
      "Training\n",
      "Epoch 328 complete\n",
      "Loss was 0.195139539539814\n",
      "\n",
      "Training\n",
      "Epoch 329 complete\n",
      "Loss was 0.1876955433487892\n",
      "\n",
      "Training\n",
      "Epoch 330 complete\n",
      "Loss was 0.1872177267372608\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.52\n",
      "\n",
      "Training\n",
      "Epoch 331 complete\n",
      "Loss was 0.1891055796444416\n",
      "\n",
      "Training\n",
      "Epoch 332 complete\n",
      "Loss was 0.18949337360262872\n",
      "\n",
      "Training\n",
      "Epoch 333 complete\n",
      "Loss was 0.18888850682973862\n",
      "\n",
      "Training\n",
      "Epoch 334 complete\n",
      "Loss was 0.18633924442529679\n",
      "\n",
      "Training\n",
      "Epoch 335 complete\n",
      "Loss was 0.18918034729361535\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.85\n",
      "\n",
      "Training\n",
      "Epoch 336 complete\n",
      "Loss was 0.18800447034835815\n",
      "\n",
      "Training\n",
      "Epoch 337 complete\n",
      "Loss was 0.18972931012511254\n",
      "\n",
      "Training\n",
      "Epoch 338 complete\n",
      "Loss was 0.18862709778547287\n",
      "\n",
      "Training\n",
      "Epoch 339 complete\n",
      "Loss was 0.18822958424687386\n",
      "\n",
      "Training\n",
      "Epoch 340 complete\n",
      "Loss was 0.18385638257861137\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.74\n",
      "\n",
      "Training\n",
      "Epoch 341 complete\n",
      "Loss was 0.18546499541401862\n",
      "\n",
      "Training\n",
      "Epoch 342 complete\n",
      "Loss was 0.18688754865527152\n",
      "\n",
      "Training\n",
      "Epoch 343 complete\n",
      "Loss was 0.18874673527479172\n",
      "\n",
      "Training\n",
      "Epoch 344 complete\n",
      "Loss was 0.1882254091501236\n",
      "\n",
      "Training\n",
      "Epoch 345 complete\n",
      "Loss was 0.1850914821624756\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.47\n",
      "\n",
      "Training\n",
      "Epoch 346 complete\n",
      "Loss was 0.18608542680740356\n",
      "\n",
      "Training\n",
      "Epoch 347 complete\n",
      "Loss was 0.18607178580760955\n",
      "\n",
      "Training\n",
      "Epoch 348 complete\n",
      "Loss was 0.18779914197325706\n",
      "\n",
      "Training\n",
      "Epoch 349 complete\n",
      "Loss was 0.1867864899635315\n",
      "\n",
      "Training\n",
      "Epoch 350 complete\n",
      "Loss was 0.18527603855729102\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.82\n",
      "\n",
      "Training\n",
      "Epoch 351 complete\n",
      "Loss was 0.18782971954345704\n",
      "\n",
      "Training\n",
      "Epoch 352 complete\n",
      "Loss was 0.18886130625009537\n",
      "\n",
      "Training\n",
      "Epoch 353 complete\n",
      "Loss was 0.18742329198122024\n",
      "\n",
      "Training\n",
      "Epoch 354 complete\n",
      "Loss was 0.18696025043725967\n",
      "\n",
      "Training\n",
      "Epoch 355 complete\n",
      "Loss was 0.18445534950494766\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.65\n",
      "\n",
      "Training\n",
      "Epoch 356 complete\n",
      "Loss was 0.18445706030726433\n",
      "\n",
      "Training\n",
      "Epoch 357 complete\n",
      "Loss was 0.18361913749575615\n",
      "\n",
      "Training\n",
      "Epoch 358 complete\n",
      "Loss was 0.1849447733461857\n",
      "\n",
      "Training\n",
      "Epoch 359 complete\n",
      "Loss was 0.18473642188310624\n",
      "\n",
      "Training\n",
      "Epoch 360 complete\n",
      "Loss was 0.18343776285648347\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.61\n",
      "\n",
      "Training\n",
      "Epoch 361 complete\n",
      "Loss was 0.18457794213294984\n",
      "\n",
      "Training\n",
      "Epoch 362 complete\n",
      "Loss was 0.1807829205393791\n",
      "\n",
      "Training\n",
      "Epoch 363 complete\n",
      "Loss was 0.18642302364110946\n",
      "\n",
      "Training\n",
      "Epoch 364 complete\n",
      "Loss was 0.18511702063679694\n",
      "\n",
      "Training\n",
      "Epoch 365 complete\n",
      "Loss was 0.1866883977651596\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.0\n",
      "\n",
      "Training\n",
      "Epoch 366 complete\n",
      "Loss was 0.18078109723329544\n",
      "\n",
      "Training\n",
      "Epoch 367 complete\n",
      "Loss was 0.18556572622060777\n",
      "\n",
      "Training\n",
      "Epoch 368 complete\n",
      "Loss was 0.18347224429249764\n",
      "\n",
      "Training\n",
      "Epoch 369 complete\n",
      "Loss was 0.18389894616603852\n",
      "\n",
      "Training\n",
      "Epoch 370 complete\n",
      "Loss was 0.18789179530739783\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.54\n",
      "\n",
      "Training\n",
      "Epoch 371 complete\n",
      "Loss was 0.18131331971287729\n",
      "\n",
      "Training\n",
      "Epoch 372 complete\n",
      "Loss was 0.18085120984911918\n",
      "\n",
      "Training\n",
      "Epoch 373 complete\n",
      "Loss was 0.18234389543533325\n",
      "\n",
      "Training\n",
      "Epoch 374 complete\n",
      "Loss was 0.18571497625112535\n",
      "\n",
      "Training\n",
      "Epoch 375 complete\n",
      "Loss was 0.18512071919441223\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.18\n",
      "\n",
      "Training\n",
      "Epoch 376 complete\n",
      "Loss was 0.1809578543305397\n",
      "\n",
      "Training\n",
      "Epoch 377 complete\n",
      "Loss was 0.18306014028191567\n",
      "\n",
      "Training\n",
      "Epoch 378 complete\n",
      "Loss was 0.1824665800333023\n",
      "\n",
      "Training\n",
      "Epoch 379 complete\n",
      "Loss was 0.1823487222790718\n",
      "\n",
      "Training\n",
      "Epoch 380 complete\n",
      "Loss was 0.18103750801086427\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.91\n",
      "\n",
      "Training\n",
      "Epoch 381 complete\n",
      "Loss was 0.1825948642194271\n",
      "\n",
      "Training\n",
      "Epoch 382 complete\n",
      "Loss was 0.18243513002991676\n",
      "\n",
      "Training\n",
      "Epoch 383 complete\n",
      "Loss was 0.18756541481614114\n",
      "\n",
      "Training\n",
      "Epoch 384 complete\n",
      "Loss was 0.18002391237020493\n",
      "\n",
      "Training\n",
      "Epoch 385 complete\n",
      "Loss was 0.18144763627648353\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.61\n",
      "\n",
      "Training\n",
      "Epoch 386 complete\n",
      "Loss was 0.18122684282064438\n",
      "\n",
      "Training\n",
      "Epoch 387 complete\n",
      "Loss was 0.17831496161222457\n",
      "\n",
      "Training\n",
      "Epoch 388 complete\n",
      "Loss was 0.18347681552171707\n",
      "\n",
      "Training\n",
      "Epoch 389 complete\n",
      "Loss was 0.17943376246094703\n",
      "\n",
      "Training\n",
      "Epoch 390 complete\n",
      "Loss was 0.18276512119174004\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.64\n",
      "\n",
      "Training\n",
      "Epoch 391 complete\n",
      "Loss was 0.1814955148100853\n",
      "\n",
      "Training\n",
      "Epoch 392 complete\n",
      "Loss was 0.18273537564277648\n",
      "\n",
      "Training\n",
      "Epoch 393 complete\n",
      "Loss was 0.18175057294964791\n",
      "\n",
      "Training\n",
      "Epoch 394 complete\n",
      "Loss was 0.18343796390295028\n",
      "\n",
      "Training\n",
      "Epoch 395 complete\n",
      "Loss was 0.18373449873924255\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.83\n",
      "\n",
      "Training\n",
      "Epoch 396 complete\n",
      "Loss was 0.17758163720369338\n",
      "\n",
      "Training\n",
      "Epoch 397 complete\n",
      "Loss was 0.1784895960986614\n",
      "\n",
      "Training\n",
      "Epoch 398 complete\n",
      "Loss was 0.183965461820364\n",
      "\n",
      "Training\n",
      "Epoch 399 complete\n",
      "Loss was 0.1834091607928276\n",
      "\n",
      "Training\n",
      "Epoch 400 complete\n",
      "Loss was 0.18162523159384728\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.53\n",
      "\n",
      "Training\n",
      "Epoch 401 complete\n",
      "Loss was 0.18342712470889092\n",
      "\n",
      "Training\n",
      "Epoch 402 complete\n",
      "Loss was 0.17884072190523148\n",
      "\n",
      "Training\n",
      "Epoch 403 complete\n",
      "Loss was 0.18114961072802543\n",
      "\n",
      "Training\n",
      "Epoch 404 complete\n",
      "Loss was 0.18366768354177476\n",
      "\n",
      "Training\n",
      "Epoch 405 complete\n",
      "Loss was 0.17918157336115836\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.31\n",
      "\n",
      "Training\n",
      "Epoch 406 complete\n",
      "Loss was 0.18061870980262756\n",
      "\n",
      "Training\n",
      "Epoch 407 complete\n",
      "Loss was 0.17957345911860467\n",
      "\n",
      "Training\n",
      "Epoch 408 complete\n",
      "Loss was 0.1810017090141773\n",
      "\n",
      "Training\n",
      "Epoch 409 complete\n",
      "Loss was 0.1851946919262409\n",
      "\n",
      "Training\n",
      "Epoch 410 complete\n",
      "Loss was 0.17925733229517937\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.27\n",
      "\n",
      "Training\n",
      "Epoch 411 complete\n",
      "Loss was 0.18051415690779685\n",
      "\n",
      "Training\n",
      "Epoch 412 complete\n",
      "Loss was 0.18062391170859338\n",
      "\n",
      "Training\n",
      "Epoch 413 complete\n",
      "Loss was 0.18346664929389953\n",
      "\n",
      "Training\n",
      "Epoch 414 complete\n",
      "Loss was 0.18449801632761956\n",
      "\n",
      "Training\n",
      "Epoch 415 complete\n",
      "Loss was 0.18107651916146278\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.81\n",
      "\n",
      "Training\n",
      "Epoch 416 complete\n",
      "Loss was 0.17666956904530526\n",
      "\n",
      "Training\n",
      "Epoch 417 complete\n",
      "Loss was 0.17720163801312447\n",
      "\n",
      "Training\n",
      "Epoch 418 complete\n",
      "Loss was 0.18329646959900855\n",
      "\n",
      "Training\n",
      "Epoch 419 complete\n",
      "Loss was 0.17771031519770622\n",
      "\n",
      "Training\n",
      "Epoch 420 complete\n",
      "Loss was 0.17734075367450713\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.05\n",
      "\n",
      "Training\n",
      "Epoch 421 complete\n",
      "Loss was 0.1789588775038719\n",
      "\n",
      "Training\n",
      "Epoch 422 complete\n",
      "Loss was 0.17984586142003536\n",
      "\n",
      "Training\n",
      "Epoch 423 complete\n",
      "Loss was 0.18180183616280557\n",
      "\n",
      "Training\n",
      "Epoch 424 complete\n",
      "Loss was 0.18097027349472045\n",
      "\n",
      "Training\n",
      "Epoch 425 complete\n",
      "Loss was 0.1795813644528389\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.71\n",
      "\n",
      "Training\n",
      "Epoch 426 complete\n",
      "Loss was 0.17874606648087502\n",
      "\n",
      "Training\n",
      "Epoch 427 complete\n",
      "Loss was 0.18242005249857904\n",
      "\n",
      "Training\n",
      "Epoch 428 complete\n",
      "Loss was 0.17855843436717986\n",
      "\n",
      "Training\n",
      "Epoch 429 complete\n",
      "Loss was 0.18056206437945366\n",
      "\n",
      "Training\n",
      "Epoch 430 complete\n",
      "Loss was 0.17843721669912338\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.81\n",
      "\n",
      "Training\n",
      "Epoch 431 complete\n",
      "Loss was 0.17568243128061295\n",
      "\n",
      "Training\n",
      "Epoch 432 complete\n",
      "Loss was 0.17799705678224564\n",
      "\n",
      "Training\n",
      "Epoch 433 complete\n",
      "Loss was 0.17895634171366692\n",
      "\n",
      "Training\n",
      "Epoch 434 complete\n",
      "Loss was 0.17915256357192993\n",
      "\n",
      "Training\n",
      "Epoch 435 complete\n",
      "Loss was 0.17859162724018096\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.06\n",
      "\n",
      "Training\n",
      "Epoch 436 complete\n",
      "Loss was 0.17527959683537483\n",
      "\n",
      "Training\n",
      "Epoch 437 complete\n",
      "Loss was 0.17694973176717757\n",
      "\n",
      "Training\n",
      "Epoch 438 complete\n",
      "Loss was 0.17531020858883858\n",
      "\n",
      "Training\n",
      "Epoch 439 complete\n",
      "Loss was 0.17749023799598218\n",
      "\n",
      "Training\n",
      "Epoch 440 complete\n",
      "Loss was 0.17779283422231673\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.65\n",
      "\n",
      "Training\n",
      "Epoch 441 complete\n",
      "Loss was 0.1740440424978733\n",
      "\n",
      "Training\n",
      "Epoch 442 complete\n",
      "Loss was 0.17839152851700782\n",
      "\n",
      "Training\n",
      "Epoch 443 complete\n",
      "Loss was 0.17377392342686654\n",
      "\n",
      "Training\n",
      "Epoch 444 complete\n",
      "Loss was 0.17611556252837182\n",
      "\n",
      "Training\n",
      "Epoch 445 complete\n",
      "Loss was 0.17735503169894218\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.2\n",
      "\n",
      "Training\n",
      "Epoch 446 complete\n",
      "Loss was 0.1806999394595623\n",
      "\n",
      "Training\n",
      "Epoch 447 complete\n",
      "Loss was 0.17886985969543456\n",
      "\n",
      "Training\n",
      "Epoch 448 complete\n",
      "Loss was 0.17614963215589524\n",
      "\n",
      "Training\n",
      "Epoch 449 complete\n",
      "Loss was 0.17764620488882066\n",
      "\n",
      "Training\n",
      "Epoch 450 complete\n",
      "Loss was 0.1752592171728611\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.75\n",
      "\n",
      "Training\n",
      "Epoch 451 complete\n",
      "Loss was 0.1733839610517025\n",
      "\n",
      "Training\n",
      "Epoch 452 complete\n",
      "Loss was 0.17990072119235992\n",
      "\n",
      "Training\n",
      "Epoch 453 complete\n",
      "Loss was 0.17974026247859\n",
      "\n",
      "Training\n",
      "Epoch 454 complete\n",
      "Loss was 0.1744452750980854\n",
      "\n",
      "Training\n",
      "Epoch 455 complete\n",
      "Loss was 0.1780834338068962\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.48\n",
      "\n",
      "Training\n",
      "Epoch 456 complete\n",
      "Loss was 0.1772153003513813\n",
      "\n",
      "Training\n",
      "Epoch 457 complete\n",
      "Loss was 0.1762305503487587\n",
      "\n",
      "Training\n",
      "Epoch 458 complete\n",
      "Loss was 0.1819545075893402\n",
      "\n",
      "Training\n",
      "Epoch 459 complete\n",
      "Loss was 0.17648285242915154\n",
      "\n",
      "Training\n",
      "Epoch 460 complete\n",
      "Loss was 0.17135665276646614\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.13\n",
      "\n",
      "Training\n",
      "Epoch 461 complete\n",
      "Loss was 0.17774258503317833\n",
      "\n",
      "Training\n",
      "Epoch 462 complete\n",
      "Loss was 0.174037200063467\n",
      "\n",
      "Training\n",
      "Epoch 463 complete\n",
      "Loss was 0.17882664209604263\n",
      "\n",
      "Training\n",
      "Epoch 464 complete\n",
      "Loss was 0.17865527591109276\n",
      "\n",
      "Training\n",
      "Epoch 465 complete\n",
      "Loss was 0.1780781638920307\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.87\n",
      "\n",
      "Training\n",
      "Epoch 466 complete\n",
      "Loss was 0.17524916130304335\n",
      "\n",
      "Training\n",
      "Epoch 467 complete\n",
      "Loss was 0.16871519148349762\n",
      "\n",
      "Training\n",
      "Epoch 468 complete\n",
      "Loss was 0.17121762602031232\n",
      "\n",
      "Training\n",
      "Epoch 469 complete\n",
      "Loss was 0.18083346071839332\n",
      "\n",
      "Training\n",
      "Epoch 470 complete\n",
      "Loss was 0.17764453384280204\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.98\n",
      "\n",
      "Training\n",
      "Epoch 471 complete\n",
      "Loss was 0.17464742502570152\n",
      "\n",
      "Training\n",
      "Epoch 472 complete\n",
      "Loss was 0.17781047609448433\n",
      "\n",
      "Training\n",
      "Epoch 473 complete\n",
      "Loss was 0.17296997252106666\n",
      "\n",
      "Training\n",
      "Epoch 474 complete\n",
      "Loss was 0.17482814407348632\n",
      "\n",
      "Training\n",
      "Epoch 475 complete\n",
      "Loss was 0.17663370051980018\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.78\n",
      "\n",
      "Training\n",
      "Epoch 476 complete\n",
      "Loss was 0.17124231868982315\n",
      "\n",
      "Training\n",
      "Epoch 477 complete\n",
      "Loss was 0.172007207095623\n",
      "\n",
      "Training\n",
      "Epoch 478 complete\n",
      "Loss was 0.17598144039511682\n",
      "\n",
      "Training\n",
      "Epoch 479 complete\n",
      "Loss was 0.17665930768847465\n",
      "\n",
      "Training\n",
      "Epoch 480 complete\n",
      "Loss was 0.174685755610466\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.62\n",
      "\n",
      "Training\n",
      "Epoch 481 complete\n",
      "Loss was 0.17414577010273932\n",
      "\n",
      "Training\n",
      "Epoch 482 complete\n",
      "Loss was 0.1746626453101635\n",
      "\n",
      "Training\n",
      "Epoch 483 complete\n",
      "Loss was 0.172683319658041\n",
      "\n",
      "Training\n",
      "Epoch 484 complete\n",
      "Loss was 0.17057283666729928\n",
      "\n",
      "Training\n",
      "Epoch 485 complete\n",
      "Loss was 0.16799382510781288\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.59\n",
      "\n",
      "Training\n",
      "Epoch 486 complete\n",
      "Loss was 0.1758480988740921\n",
      "\n",
      "Training\n",
      "Epoch 487 complete\n",
      "Loss was 0.17211370870471002\n",
      "\n",
      "Training\n",
      "Epoch 488 complete\n",
      "Loss was 0.17682327750325202\n",
      "\n",
      "Training\n",
      "Epoch 489 complete\n",
      "Loss was 0.17119242921471595\n",
      "\n",
      "Training\n",
      "Epoch 490 complete\n",
      "Loss was 0.17090528544783593\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.61\n",
      "\n",
      "Training\n",
      "Epoch 491 complete\n",
      "Loss was 0.17323813351988793\n",
      "\n",
      "Training\n",
      "Epoch 492 complete\n",
      "Loss was 0.17364041885733605\n",
      "\n",
      "Training\n",
      "Epoch 493 complete\n",
      "Loss was 0.1779028678536415\n",
      "\n",
      "Training\n",
      "Epoch 494 complete\n",
      "Loss was 0.17142479521036147\n",
      "\n",
      "Training\n",
      "Epoch 495 complete\n",
      "Loss was 0.17331326428055763\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.6\n",
      "\n",
      "Training\n",
      "Epoch 496 complete\n",
      "Loss was 0.17472578340768813\n",
      "\n",
      "Training\n",
      "Epoch 497 complete\n",
      "Loss was 0.17196926391124726\n",
      "\n",
      "Training\n",
      "Epoch 498 complete\n",
      "Loss was 0.17240607899427413\n",
      "\n",
      "Training\n",
      "Epoch 499 complete\n",
      "Loss was 0.17450102165341377\n",
      "\n",
      "Training\n",
      "Epoch 500 complete\n",
      "Loss was 0.1730942971408367\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.56\n",
      "\n",
      "Training\n",
      "Epoch 501 complete\n",
      "Loss was 0.17191225972771645\n",
      "\n",
      "Training\n",
      "Epoch 502 complete\n",
      "Loss was 0.17165498596429823\n",
      "\n",
      "Training\n",
      "Epoch 503 complete\n",
      "Loss was 0.1782409326136112\n",
      "\n",
      "Training\n",
      "Epoch 504 complete\n",
      "Loss was 0.17516428837180137\n",
      "\n",
      "Training\n",
      "Epoch 505 complete\n",
      "Loss was 0.17247376599907874\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.97\n",
      "\n",
      "Training\n",
      "Epoch 506 complete\n",
      "Loss was 0.17771298137307168\n",
      "\n",
      "Training\n",
      "Epoch 507 complete\n",
      "Loss was 0.17252158001065254\n",
      "\n",
      "Training\n",
      "Epoch 508 complete\n",
      "Loss was 0.1738003092110157\n",
      "\n",
      "Training\n",
      "Epoch 509 complete\n",
      "Loss was 0.17714607870578766\n",
      "\n",
      "Training\n",
      "Epoch 510 complete\n",
      "Loss was 0.1728007918000221\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.11\n",
      "\n",
      "Training\n",
      "Epoch 511 complete\n",
      "Loss was 0.1688929141163826\n",
      "\n",
      "Training\n",
      "Epoch 512 complete\n",
      "Loss was 0.1704680066406727\n",
      "\n",
      "Training\n",
      "Epoch 513 complete\n",
      "Loss was 0.17408247247338296\n",
      "\n",
      "Training\n",
      "Epoch 514 complete\n",
      "Loss was 0.1698327333331108\n",
      "\n",
      "Training\n",
      "Epoch 515 complete\n",
      "Loss was 0.17535395017266273\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.82\n",
      "\n",
      "Training\n",
      "Epoch 516 complete\n",
      "Loss was 0.17101964688301086\n",
      "\n",
      "Training\n",
      "Epoch 517 complete\n",
      "Loss was 0.17043141946196555\n",
      "\n",
      "Training\n",
      "Epoch 518 complete\n",
      "Loss was 0.1695611695945263\n",
      "\n",
      "Training\n",
      "Epoch 519 complete\n",
      "Loss was 0.17336978250741958\n",
      "\n",
      "Training\n",
      "Epoch 520 complete\n",
      "Loss was 0.17166091319918633\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.28\n",
      "\n",
      "Training\n",
      "Epoch 521 complete\n",
      "Loss was 0.17282839635014535\n",
      "\n",
      "Training\n",
      "Epoch 522 complete\n",
      "Loss was 0.17107848772406578\n",
      "\n",
      "Training\n",
      "Epoch 523 complete\n",
      "Loss was 0.17014510944485664\n",
      "\n",
      "Training\n",
      "Epoch 524 complete\n",
      "Loss was 0.1685081270635128\n",
      "\n",
      "Training\n",
      "Epoch 525 complete\n",
      "Loss was 0.1722841142117977\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.18\n",
      "\n",
      "Training\n",
      "Epoch 526 complete\n",
      "Loss was 0.17445868611335755\n",
      "\n",
      "Training\n",
      "Epoch 527 complete\n",
      "Loss was 0.16655209547281266\n",
      "\n",
      "Training\n",
      "Epoch 528 complete\n",
      "Loss was 0.17119013237953187\n",
      "\n",
      "Training\n",
      "Epoch 529 complete\n",
      "Loss was 0.17415547454357147\n",
      "\n",
      "Training\n",
      "Epoch 530 complete\n",
      "Loss was 0.1683037869632244\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.13\n",
      "\n",
      "Training\n",
      "Epoch 531 complete\n",
      "Loss was 0.17345075595378875\n",
      "\n",
      "Training\n",
      "Epoch 532 complete\n",
      "Loss was 0.16807266610860824\n",
      "\n",
      "Training\n",
      "Epoch 533 complete\n",
      "Loss was 0.17513934350013732\n",
      "\n",
      "Training\n",
      "Epoch 534 complete\n",
      "Loss was 0.1712915013730526\n",
      "\n",
      "Training\n",
      "Epoch 535 complete\n",
      "Loss was 0.17271800002455712\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.3\n",
      "\n",
      "Training\n",
      "Epoch 536 complete\n",
      "Loss was 0.16994171646237374\n",
      "\n",
      "Training\n",
      "Epoch 537 complete\n",
      "Loss was 0.1725365557074547\n",
      "\n",
      "Training\n",
      "Epoch 538 complete\n",
      "Loss was 0.1727325828075409\n",
      "\n",
      "Training\n",
      "Epoch 539 complete\n",
      "Loss was 0.1722217847108841\n",
      "\n",
      "Training\n",
      "Epoch 540 complete\n",
      "Loss was 0.17042898270487786\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.25\n",
      "\n",
      "Training\n",
      "Epoch 541 complete\n",
      "Loss was 0.1717612394988537\n",
      "\n",
      "Training\n",
      "Epoch 542 complete\n",
      "Loss was 0.17501852384209632\n",
      "\n",
      "Training\n",
      "Epoch 543 complete\n",
      "Loss was 0.17404481118917464\n",
      "\n",
      "Training\n",
      "Epoch 544 complete\n",
      "Loss was 0.17061487039923667\n",
      "\n",
      "Training\n",
      "Epoch 545 complete\n",
      "Loss was 0.16911530610918998\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.66\n",
      "\n",
      "Training\n",
      "Epoch 546 complete\n",
      "Loss was 0.16944682320952414\n",
      "\n",
      "Training\n",
      "Epoch 547 complete\n",
      "Loss was 0.16822044214606285\n",
      "\n",
      "Training\n",
      "Epoch 548 complete\n",
      "Loss was 0.1684329808950424\n",
      "\n",
      "Training\n",
      "Epoch 549 complete\n",
      "Loss was 0.17172192388772964\n",
      "\n",
      "Training\n",
      "Epoch 550 complete\n",
      "Loss was 0.1693591747879982\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.69\n",
      "\n",
      "Training\n",
      "Epoch 551 complete\n",
      "Loss was 0.1701665765941143\n",
      "\n",
      "Training\n",
      "Epoch 552 complete\n",
      "Loss was 0.1742935291826725\n",
      "\n",
      "Training\n",
      "Epoch 553 complete\n",
      "Loss was 0.16801246762275696\n",
      "\n",
      "Training\n",
      "Epoch 554 complete\n",
      "Loss was 0.16967706477642058\n",
      "\n",
      "Training\n",
      "Epoch 555 complete\n",
      "Loss was 0.17114847487211227\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.21\n",
      "\n",
      "Training\n",
      "Epoch 556 complete\n",
      "Loss was 0.1684846204519272\n",
      "\n",
      "Training\n",
      "Epoch 557 complete\n",
      "Loss was 0.16886963731050492\n",
      "\n",
      "Training\n",
      "Epoch 558 complete\n",
      "Loss was 0.1716515364944935\n",
      "\n",
      "Training\n",
      "Epoch 559 complete\n",
      "Loss was 0.16640971261262893\n",
      "\n",
      "Training\n",
      "Epoch 560 complete\n",
      "Loss was 0.1679786938726902\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.06\n",
      "\n",
      "Training\n",
      "Epoch 561 complete\n",
      "Loss was 0.1695382562279701\n",
      "\n",
      "Training\n",
      "Epoch 562 complete\n",
      "Loss was 0.17265199452638627\n",
      "\n",
      "Training\n",
      "Epoch 563 complete\n",
      "Loss was 0.16924646463990212\n",
      "\n",
      "Training\n",
      "Epoch 564 complete\n",
      "Loss was 0.16967491430044174\n",
      "\n",
      "Training\n",
      "Epoch 565 complete\n",
      "Loss was 0.17017726948857306\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.06\n",
      "\n",
      "Training\n",
      "Epoch 566 complete\n",
      "Loss was 0.17100038973987103\n",
      "\n",
      "Training\n",
      "Epoch 567 complete\n",
      "Loss was 0.1706603524684906\n",
      "\n",
      "Training\n",
      "Epoch 568 complete\n",
      "Loss was 0.16782403126358986\n",
      "\n",
      "Training\n",
      "Epoch 569 complete\n",
      "Loss was 0.16905466502904892\n",
      "\n",
      "Training\n",
      "Epoch 570 complete\n",
      "Loss was 0.17204682186245918\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.42\n",
      "\n",
      "Training\n",
      "Epoch 571 complete\n",
      "Loss was 0.16972069105505944\n",
      "\n",
      "Training\n",
      "Epoch 572 complete\n",
      "Loss was 0.16838396593928337\n",
      "\n",
      "Training\n",
      "Epoch 573 complete\n",
      "Loss was 0.16937612617015838\n",
      "\n",
      "Training\n",
      "Epoch 574 complete\n",
      "Loss was 0.17522459232807158\n",
      "\n",
      "Training\n",
      "Epoch 575 complete\n",
      "Loss was 0.16818557259440423\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.5\n",
      "\n",
      "Training\n",
      "Epoch 576 complete\n",
      "Loss was 0.16568543827533722\n",
      "\n",
      "Training\n",
      "Epoch 577 complete\n",
      "Loss was 0.16852398997545243\n",
      "\n",
      "Training\n",
      "Epoch 578 complete\n",
      "Loss was 0.17211183246970177\n",
      "\n",
      "Training\n",
      "Epoch 579 complete\n",
      "Loss was 0.17230200308561325\n",
      "\n",
      "Training\n",
      "Epoch 580 complete\n",
      "Loss was 0.17223371690511705\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.22\n",
      "\n",
      "Training\n",
      "Epoch 581 complete\n",
      "Loss was 0.1629518981873989\n",
      "\n",
      "Training\n",
      "Epoch 582 complete\n",
      "Loss was 0.16839578518271447\n",
      "\n",
      "Training\n",
      "Epoch 583 complete\n",
      "Loss was 0.16958904314041137\n",
      "\n",
      "Training\n",
      "Epoch 584 complete\n",
      "Loss was 0.16990349596738816\n",
      "\n",
      "Training\n",
      "Epoch 585 complete\n",
      "Loss was 0.17205906736850737\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.68\n",
      "\n",
      "Training\n",
      "Epoch 586 complete\n",
      "Loss was 0.16815952396392822\n",
      "\n",
      "Training\n",
      "Epoch 587 complete\n",
      "Loss was 0.16745707324147224\n",
      "\n",
      "Training\n",
      "Epoch 588 complete\n",
      "Loss was 0.1696685082912445\n",
      "\n",
      "Training\n",
      "Epoch 589 complete\n",
      "Loss was 0.16725706109404564\n",
      "\n",
      "Training\n",
      "Epoch 590 complete\n",
      "Loss was 0.1682271327674389\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.06\n",
      "\n",
      "Training\n",
      "Epoch 591 complete\n",
      "Loss was 0.16650873017311096\n",
      "\n",
      "Training\n",
      "Epoch 592 complete\n",
      "Loss was 0.16891899421811105\n",
      "\n",
      "Training\n",
      "Epoch 593 complete\n",
      "Loss was 0.1687071980535984\n",
      "\n",
      "Training\n",
      "Epoch 594 complete\n",
      "Loss was 0.1709948589503765\n",
      "\n",
      "Training\n",
      "Epoch 595 complete\n",
      "Loss was 0.16741145592927933\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.97\n",
      "\n",
      "Training\n",
      "Epoch 596 complete\n",
      "Loss was 0.16871583834290504\n",
      "\n",
      "Training\n",
      "Epoch 597 complete\n",
      "Loss was 0.17156302452087402\n",
      "\n",
      "Training\n",
      "Epoch 598 complete\n",
      "Loss was 0.1696301556825638\n",
      "\n",
      "Training\n",
      "Epoch 599 complete\n",
      "Loss was 0.16978247225284576\n",
      "\n",
      "Training\n",
      "Epoch 600 complete\n",
      "Loss was 0.16556537699699403\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.71\n",
      "\n",
      "Training\n",
      "Epoch 601 complete\n",
      "Loss was 0.16340754561126233\n",
      "\n",
      "Training\n",
      "Epoch 602 complete\n",
      "Loss was 0.1647152791917324\n",
      "\n",
      "Training\n",
      "Epoch 603 complete\n",
      "Loss was 0.16842952740192413\n",
      "\n",
      "Training\n",
      "Epoch 604 complete\n",
      "Loss was 0.16297772914171219\n",
      "\n",
      "Training\n",
      "Epoch 605 complete\n",
      "Loss was 0.1660976521372795\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.17\n",
      "\n",
      "Training\n",
      "Epoch 606 complete\n",
      "Loss was 0.16722659453749655\n",
      "\n",
      "Training\n",
      "Epoch 607 complete\n",
      "Loss was 0.16999856367707253\n",
      "\n",
      "Training\n",
      "Epoch 608 complete\n",
      "Loss was 0.16770515695214272\n",
      "\n",
      "Training\n",
      "Epoch 609 complete\n",
      "Loss was 0.16702894726395606\n",
      "\n",
      "Training\n",
      "Epoch 610 complete\n",
      "Loss was 0.1669245054423809\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.52\n",
      "\n",
      "Training\n",
      "Epoch 611 complete\n",
      "Loss was 0.1664894995391369\n",
      "\n",
      "Training\n",
      "Epoch 612 complete\n",
      "Loss was 0.16713458862900735\n",
      "\n",
      "Training\n",
      "Epoch 613 complete\n",
      "Loss was 0.1679130973815918\n",
      "\n",
      "Training\n",
      "Epoch 614 complete\n",
      "Loss was 0.16812274467945099\n",
      "\n",
      "Training\n",
      "Epoch 615 complete\n",
      "Loss was 0.16860528790950774\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.1\n",
      "\n",
      "Training\n",
      "Epoch 616 complete\n",
      "Loss was 0.16331845462322236\n",
      "\n",
      "Training\n",
      "Epoch 617 complete\n",
      "Loss was 0.17061757519841195\n",
      "\n",
      "Training\n",
      "Epoch 618 complete\n",
      "Loss was 0.16326533204317092\n",
      "\n",
      "Training\n",
      "Epoch 619 complete\n",
      "Loss was 0.16572223579883574\n",
      "\n",
      "Training\n",
      "Epoch 620 complete\n",
      "Loss was 0.16626451647281645\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.39\n",
      "\n",
      "Training\n",
      "Epoch 621 complete\n",
      "Loss was 0.17162713807821273\n",
      "\n",
      "Training\n",
      "Epoch 622 complete\n",
      "Loss was 0.16777939248085022\n",
      "\n",
      "Training\n",
      "Epoch 623 complete\n",
      "Loss was 0.16871847954392433\n",
      "\n",
      "Training\n",
      "Epoch 624 complete\n",
      "Loss was 0.16807727333903313\n",
      "\n",
      "Training\n",
      "Epoch 625 complete\n",
      "Loss was 0.16412337052822112\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.12\n",
      "\n",
      "Training\n",
      "Epoch 626 complete\n",
      "Loss was 0.16897720608115196\n",
      "\n",
      "Training\n",
      "Epoch 627 complete\n",
      "Loss was 0.16709545707702636\n",
      "\n",
      "Training\n",
      "Epoch 628 complete\n",
      "Loss was 0.17266305762529374\n",
      "\n",
      "Training\n",
      "Epoch 629 complete\n",
      "Loss was 0.16702863323688508\n",
      "\n",
      "Training\n",
      "Epoch 630 complete\n",
      "Loss was 0.16977551800012589\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.87\n",
      "\n",
      "Training\n",
      "Epoch 631 complete\n",
      "Loss was 0.1726517231464386\n",
      "\n",
      "Training\n",
      "Epoch 632 complete\n",
      "Loss was 0.16238055941462518\n",
      "\n",
      "Training\n",
      "Epoch 633 complete\n",
      "Loss was 0.16412787055969238\n",
      "\n",
      "Training\n",
      "Epoch 634 complete\n",
      "Loss was 0.16437724137306214\n",
      "\n",
      "Training\n",
      "Epoch 635 complete\n",
      "Loss was 0.1640939692556858\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.47\n",
      "\n",
      "Training\n",
      "Epoch 636 complete\n",
      "Loss was 0.1667742286026478\n",
      "\n",
      "Training\n",
      "Epoch 637 complete\n",
      "Loss was 0.16627326315641403\n",
      "\n",
      "Training\n",
      "Epoch 638 complete\n",
      "Loss was 0.17114072731137275\n",
      "\n",
      "Training\n",
      "Epoch 639 complete\n",
      "Loss was 0.16740316039323808\n",
      "\n",
      "Training\n",
      "Epoch 640 complete\n",
      "Loss was 0.16837139430642128\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.02\n",
      "\n",
      "Training\n",
      "Epoch 641 complete\n",
      "Loss was 0.16875983965396882\n",
      "\n",
      "Training\n",
      "Epoch 642 complete\n",
      "Loss was 0.1669043880403042\n",
      "\n",
      "Training\n",
      "Epoch 643 complete\n",
      "Loss was 0.1659759016931057\n",
      "\n",
      "Training\n",
      "Epoch 644 complete\n",
      "Loss was 0.1661639915406704\n",
      "\n",
      "Training\n",
      "Epoch 645 complete\n",
      "Loss was 0.1703674376308918\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.09\n",
      "\n",
      "Training\n",
      "Epoch 646 complete\n",
      "Loss was 0.16511693224310875\n",
      "\n",
      "Training\n",
      "Epoch 647 complete\n",
      "Loss was 0.16115866667032241\n",
      "\n",
      "Training\n",
      "Epoch 648 complete\n",
      "Loss was 0.17217443469166754\n",
      "\n",
      "Training\n",
      "Epoch 649 complete\n",
      "Loss was 0.16509571555256844\n",
      "\n",
      "Training\n",
      "Epoch 650 complete\n",
      "Loss was 0.1673367336690426\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.65\n",
      "\n",
      "Training\n",
      "Epoch 651 complete\n",
      "Loss was 0.1663733748495579\n",
      "\n",
      "Training\n",
      "Epoch 652 complete\n",
      "Loss was 0.16667334732413291\n",
      "\n",
      "Training\n",
      "Epoch 653 complete\n",
      "Loss was 0.16774886864423752\n",
      "\n",
      "Training\n",
      "Epoch 654 complete\n",
      "Loss was 0.1682337556183338\n",
      "\n",
      "Training\n",
      "Epoch 655 complete\n",
      "Loss was 0.16348463422060014\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.45\n",
      "\n",
      "Training\n",
      "Epoch 656 complete\n",
      "Loss was 0.1687345395088196\n",
      "\n",
      "Training\n",
      "Epoch 657 complete\n",
      "Loss was 0.1632339131832123\n",
      "\n",
      "Training\n",
      "Epoch 658 complete\n",
      "Loss was 0.1648038513958454\n",
      "\n",
      "Training\n",
      "Epoch 659 complete\n",
      "Loss was 0.16374614971876145\n",
      "\n",
      "Training\n",
      "Epoch 660 complete\n",
      "Loss was 0.16914883336424827\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.95\n",
      "\n",
      "Training\n",
      "Epoch 661 complete\n",
      "Loss was 0.16692031639814378\n",
      "\n",
      "Training\n",
      "Epoch 662 complete\n",
      "Loss was 0.1631107371747494\n",
      "\n",
      "Training\n",
      "Epoch 663 complete\n",
      "Loss was 0.158936871021986\n",
      "\n",
      "Training\n",
      "Epoch 664 complete\n",
      "Loss was 0.16882960894703866\n",
      "\n",
      "Training\n",
      "Epoch 665 complete\n",
      "Loss was 0.16755565094947816\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.31\n",
      "\n",
      "Training\n",
      "Epoch 666 complete\n",
      "Loss was 0.16129956954717636\n",
      "\n",
      "Training\n",
      "Epoch 667 complete\n",
      "Loss was 0.1645638274848461\n",
      "\n",
      "Training\n",
      "Epoch 668 complete\n",
      "Loss was 0.1638170995414257\n",
      "\n",
      "Training\n",
      "Epoch 669 complete\n",
      "Loss was 0.1745185867547989\n",
      "\n",
      "Training\n",
      "Epoch 670 complete\n",
      "Loss was 0.1673941433429718\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.28\n",
      "\n",
      "Training\n",
      "Epoch 671 complete\n",
      "Loss was 0.16135053384304046\n",
      "\n",
      "Training\n",
      "Epoch 672 complete\n",
      "Loss was 0.1623005536198616\n",
      "\n",
      "Training\n",
      "Epoch 673 complete\n",
      "Loss was 0.16170072132349014\n",
      "\n",
      "Training\n",
      "Epoch 674 complete\n",
      "Loss was 0.16770910918712617\n",
      "\n",
      "Training\n",
      "Epoch 675 complete\n",
      "Loss was 0.17057962435483934\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.43\n",
      "\n",
      "Training\n",
      "Epoch 676 complete\n",
      "Loss was 0.165525471419096\n",
      "\n",
      "Training\n",
      "Epoch 677 complete\n",
      "Loss was 0.1613031051158905\n",
      "\n",
      "Training\n",
      "Epoch 678 complete\n",
      "Loss was 0.16755965325236322\n",
      "\n",
      "Training\n",
      "Epoch 679 complete\n",
      "Loss was 0.16367830047011375\n",
      "\n",
      "Training\n",
      "Epoch 680 complete\n",
      "Loss was 0.16458340805768967\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.42\n",
      "\n",
      "Training\n",
      "Epoch 681 complete\n",
      "Loss was 0.1664717309474945\n",
      "\n",
      "Training\n",
      "Epoch 682 complete\n",
      "Loss was 0.16439747688174247\n",
      "\n",
      "Training\n",
      "Epoch 683 complete\n",
      "Loss was 0.16763312742114067\n",
      "\n",
      "Training\n",
      "Epoch 684 complete\n",
      "Loss was 0.16225381204485892\n",
      "\n",
      "Training\n",
      "Epoch 685 complete\n",
      "Loss was 0.16801473531126976\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.78\n",
      "\n",
      "Training\n",
      "Epoch 686 complete\n",
      "Loss was 0.16539740270376205\n",
      "\n",
      "Training\n",
      "Epoch 687 complete\n",
      "Loss was 0.16570112884044647\n",
      "\n",
      "Training\n",
      "Epoch 688 complete\n",
      "Loss was 0.16469231063127518\n",
      "\n",
      "Training\n",
      "Epoch 689 complete\n",
      "Loss was 0.15826624098420145\n",
      "\n",
      "Training\n",
      "Epoch 690 complete\n",
      "Loss was 0.16359747332334518\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.37\n",
      "\n",
      "Training\n",
      "Epoch 691 complete\n",
      "Loss was 0.16602335572242738\n",
      "\n",
      "Training\n",
      "Epoch 692 complete\n",
      "Loss was 0.16892694115638732\n",
      "\n",
      "Training\n",
      "Epoch 693 complete\n",
      "Loss was 0.16794378900527954\n",
      "\n",
      "Training\n",
      "Epoch 694 complete\n",
      "Loss was 0.16442582759261132\n",
      "\n",
      "Training\n",
      "Epoch 695 complete\n",
      "Loss was 0.16128587871789932\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.8\n",
      "\n",
      "Training\n",
      "Epoch 696 complete\n",
      "Loss was 0.16398282194137573\n",
      "\n",
      "Training\n",
      "Epoch 697 complete\n",
      "Loss was 0.16491904516518116\n",
      "\n",
      "Training\n",
      "Epoch 698 complete\n",
      "Loss was 0.16153451842069627\n",
      "\n",
      "Training\n",
      "Epoch 699 complete\n",
      "Loss was 0.1650466878861189\n",
      "\n",
      "Training\n",
      "Epoch 700 complete\n",
      "Loss was 0.1631010671854019\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.1\n",
      "\n",
      "Training\n",
      "Epoch 701 complete\n",
      "Loss was 0.16178149822354318\n",
      "\n",
      "Training\n",
      "Epoch 702 complete\n",
      "Loss was 0.16281121212244035\n",
      "\n",
      "Training\n",
      "Epoch 703 complete\n",
      "Loss was 0.1649922551214695\n",
      "\n",
      "Training\n",
      "Epoch 704 complete\n",
      "Loss was 0.16541877198219299\n",
      "\n",
      "Training\n",
      "Epoch 705 complete\n",
      "Loss was 0.1641942574977875\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.61\n",
      "\n",
      "Training\n",
      "Epoch 706 complete\n",
      "Loss was 0.15968114456534385\n",
      "\n",
      "Training\n",
      "Epoch 707 complete\n",
      "Loss was 0.16092776706814765\n",
      "\n",
      "Training\n",
      "Epoch 708 complete\n",
      "Loss was 0.1643710631132126\n",
      "\n",
      "Training\n",
      "Epoch 709 complete\n",
      "Loss was 0.1601511351764202\n",
      "\n",
      "Training\n",
      "Epoch 710 complete\n",
      "Loss was 0.16472801181674004\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.77\n",
      "\n",
      "Training\n",
      "Epoch 711 complete\n",
      "Loss was 0.16703509882092477\n",
      "\n",
      "Training\n",
      "Epoch 712 complete\n",
      "Loss was 0.1614874271452427\n",
      "\n",
      "Training\n",
      "Epoch 713 complete\n",
      "Loss was 0.16896049624681472\n",
      "\n",
      "Training\n",
      "Epoch 714 complete\n",
      "Loss was 0.16463450503349303\n",
      "\n",
      "Training\n",
      "Epoch 715 complete\n",
      "Loss was 0.16511362463235854\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.81\n",
      "\n",
      "Training\n",
      "Epoch 716 complete\n",
      "Loss was 0.16555709764361382\n",
      "\n",
      "Training\n",
      "Epoch 717 complete\n",
      "Loss was 0.16650722271203994\n",
      "\n",
      "Training\n",
      "Epoch 718 complete\n",
      "Loss was 0.16248074474930763\n",
      "\n",
      "Training\n",
      "Epoch 719 complete\n",
      "Loss was 0.1580248968601227\n",
      "\n",
      "Training\n",
      "Epoch 720 complete\n",
      "Loss was 0.1650239490866661\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.06\n",
      "\n",
      "Training\n",
      "Epoch 721 complete\n",
      "Loss was 0.1640183421075344\n",
      "\n",
      "Training\n",
      "Epoch 722 complete\n",
      "Loss was 0.16113005104660988\n",
      "\n",
      "Training\n",
      "Epoch 723 complete\n",
      "Loss was 0.16378513938188552\n",
      "\n",
      "Training\n",
      "Epoch 724 complete\n",
      "Loss was 0.16903572356700897\n",
      "\n",
      "Training\n",
      "Epoch 725 complete\n",
      "Loss was 0.1617751563489437\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.08\n",
      "\n",
      "Training\n",
      "Epoch 726 complete\n",
      "Loss was 0.1619594964236021\n",
      "\n",
      "Training\n",
      "Epoch 727 complete\n",
      "Loss was 0.16294124254584313\n",
      "\n",
      "Training\n",
      "Epoch 728 complete\n",
      "Loss was 0.16135218808054924\n",
      "\n",
      "Training\n",
      "Epoch 729 complete\n",
      "Loss was 0.16625692811608314\n",
      "\n",
      "Training\n",
      "Epoch 730 complete\n",
      "Loss was 0.1613581691980362\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.57\n",
      "\n",
      "Training\n",
      "Epoch 731 complete\n",
      "Loss was 0.16018928134441376\n",
      "\n",
      "Training\n",
      "Epoch 732 complete\n",
      "Loss was 0.15998031288385392\n",
      "\n",
      "Training\n",
      "Epoch 733 complete\n",
      "Loss was 0.16240346199274064\n",
      "\n",
      "Training\n",
      "Epoch 734 complete\n",
      "Loss was 0.16605209475755692\n",
      "\n",
      "Training\n",
      "Epoch 735 complete\n",
      "Loss was 0.161601555198431\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.36\n",
      "\n",
      "Training\n",
      "Epoch 736 complete\n",
      "Loss was 0.16514428931474687\n",
      "\n",
      "Training\n",
      "Epoch 737 complete\n",
      "Loss was 0.16474178221821784\n",
      "\n",
      "Training\n",
      "Epoch 738 complete\n",
      "Loss was 0.1638634040057659\n",
      "\n",
      "Training\n",
      "Epoch 739 complete\n",
      "Loss was 0.1572146716415882\n",
      "\n",
      "Training\n",
      "Epoch 740 complete\n",
      "Loss was 0.1624961449354887\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.09\n",
      "\n",
      "Training\n",
      "Epoch 741 complete\n",
      "Loss was 0.1646844421327114\n",
      "\n",
      "Training\n",
      "Epoch 742 complete\n",
      "Loss was 0.16411939710378648\n",
      "\n",
      "Training\n",
      "Epoch 743 complete\n",
      "Loss was 0.1603279177546501\n",
      "\n",
      "Training\n",
      "Epoch 744 complete\n",
      "Loss was 0.16467502543330192\n",
      "\n",
      "Training\n",
      "Epoch 745 complete\n",
      "Loss was 0.16310473212599755\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.97\n",
      "\n",
      "Training\n",
      "Epoch 746 complete\n",
      "Loss was 0.16298278245329856\n",
      "\n",
      "Training\n",
      "Epoch 747 complete\n",
      "Loss was 0.1626182664334774\n",
      "\n",
      "Training\n",
      "Epoch 748 complete\n",
      "Loss was 0.16469115993380545\n",
      "\n",
      "Training\n",
      "Epoch 749 complete\n",
      "Loss was 0.1627670506834984\n",
      "\n",
      "Training\n",
      "Epoch 750 complete\n",
      "Loss was 0.16240698978304863\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.05\n",
      "\n",
      "Training\n",
      "Epoch 751 complete\n",
      "Loss was 0.16294391438364983\n",
      "\n",
      "Training\n",
      "Epoch 752 complete\n",
      "Loss was 0.16153309345245362\n",
      "\n",
      "Training\n",
      "Epoch 753 complete\n",
      "Loss was 0.1669271353185177\n",
      "\n",
      "Training\n",
      "Epoch 754 complete\n",
      "Loss was 0.16343175676465035\n",
      "\n",
      "Training\n",
      "Epoch 755 complete\n",
      "Loss was 0.16064752987027167\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.2\n",
      "\n",
      "Training\n",
      "Epoch 756 complete\n",
      "Loss was 0.16158121594786645\n",
      "\n",
      "Training\n",
      "Epoch 757 complete\n",
      "Loss was 0.15637246030569077\n",
      "\n",
      "Training\n",
      "Epoch 758 complete\n",
      "Loss was 0.15972724330425261\n",
      "\n",
      "Training\n",
      "Epoch 759 complete\n",
      "Loss was 0.16065711697936058\n",
      "\n",
      "Training\n",
      "Epoch 760 complete\n",
      "Loss was 0.16516635873913765\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.67\n",
      "\n",
      "Training\n",
      "Epoch 761 complete\n",
      "Loss was 0.16207608810067176\n",
      "\n",
      "Training\n",
      "Epoch 762 complete\n",
      "Loss was 0.1656119687259197\n",
      "\n",
      "Training\n",
      "Epoch 763 complete\n",
      "Loss was 0.16229306560754775\n",
      "\n",
      "Training\n",
      "Epoch 764 complete\n",
      "Loss was 0.16350608795881272\n",
      "\n",
      "Training\n",
      "Epoch 765 complete\n",
      "Loss was 0.160682314068079\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.43\n",
      "\n",
      "Training\n",
      "Epoch 766 complete\n",
      "Loss was 0.16408047240972518\n",
      "\n",
      "Training\n",
      "Epoch 767 complete\n",
      "Loss was 0.16032886165380478\n",
      "\n",
      "Training\n",
      "Epoch 768 complete\n",
      "Loss was 0.16169883340597152\n",
      "\n",
      "Training\n",
      "Epoch 769 complete\n",
      "Loss was 0.15984506207704544\n",
      "\n",
      "Training\n",
      "Epoch 770 complete\n",
      "Loss was 0.16423315167427063\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.39\n",
      "\n",
      "Training\n",
      "Epoch 771 complete\n",
      "Loss was 0.16343494920432566\n",
      "\n",
      "Training\n",
      "Epoch 772 complete\n",
      "Loss was 0.1614399919360876\n",
      "\n",
      "Training\n",
      "Epoch 773 complete\n",
      "Loss was 0.162773189753294\n",
      "\n",
      "Training\n",
      "Epoch 774 complete\n",
      "Loss was 0.1613083094060421\n",
      "\n",
      "Training\n",
      "Epoch 775 complete\n",
      "Loss was 0.15941376453638076\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.26\n",
      "\n",
      "Training\n",
      "Epoch 776 complete\n",
      "Loss was 0.16244924491643906\n",
      "\n",
      "Training\n",
      "Epoch 777 complete\n",
      "Loss was 0.16180632933974265\n",
      "\n",
      "Training\n",
      "Epoch 778 complete\n",
      "Loss was 0.1646628846824169\n",
      "\n",
      "Training\n",
      "Epoch 779 complete\n",
      "Loss was 0.16475491040945053\n",
      "\n",
      "Training\n",
      "Epoch 780 complete\n",
      "Loss was 0.16183472728729248\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.19\n",
      "\n",
      "Training\n",
      "Epoch 781 complete\n",
      "Loss was 0.1621802598834038\n",
      "\n",
      "Training\n",
      "Epoch 782 complete\n",
      "Loss was 0.16419793039560318\n",
      "\n",
      "Training\n",
      "Epoch 783 complete\n",
      "Loss was 0.16148753514885902\n",
      "\n",
      "Training\n",
      "Epoch 784 complete\n",
      "Loss was 0.16089060589671134\n",
      "\n",
      "Training\n",
      "Epoch 785 complete\n",
      "Loss was 0.1643320858478546\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.43\n",
      "\n",
      "Training\n",
      "Epoch 786 complete\n",
      "Loss was 0.15999876436591148\n",
      "\n",
      "Training\n",
      "Epoch 787 complete\n",
      "Loss was 0.1641561958193779\n",
      "\n",
      "Training\n",
      "Epoch 788 complete\n",
      "Loss was 0.1613433402776718\n",
      "\n",
      "Training\n",
      "Epoch 789 complete\n",
      "Loss was 0.16330470517277718\n",
      "\n",
      "Training\n",
      "Epoch 790 complete\n",
      "Loss was 0.16238288527727127\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.87\n",
      "\n",
      "Training\n",
      "Epoch 791 complete\n",
      "Loss was 0.16033701995015145\n",
      "\n",
      "Training\n",
      "Epoch 792 complete\n",
      "Loss was 0.1629452367722988\n",
      "\n",
      "Training\n",
      "Epoch 793 complete\n",
      "Loss was 0.1607210897654295\n",
      "\n",
      "Training\n",
      "Epoch 794 complete\n",
      "Loss was 0.16410006040334701\n",
      "\n",
      "Training\n",
      "Epoch 795 complete\n",
      "Loss was 0.16138164639472963\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.38\n",
      "\n",
      "Training\n",
      "Epoch 796 complete\n",
      "Loss was 0.1620696631669998\n",
      "\n",
      "Training\n",
      "Epoch 797 complete\n",
      "Loss was 0.158306481808424\n",
      "\n",
      "Training\n",
      "Epoch 798 complete\n",
      "Loss was 0.15575820407271385\n",
      "\n",
      "Training\n",
      "Epoch 799 complete\n",
      "Loss was 0.15800691437721254\n",
      "\n",
      "Training\n",
      "Epoch 800 complete\n",
      "Loss was 0.16466071340441704\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.82\n",
      "\n",
      "Training\n",
      "Epoch 801 complete\n",
      "Loss was 0.16130281174182892\n",
      "\n",
      "Training\n",
      "Epoch 802 complete\n",
      "Loss was 0.1614380407333374\n",
      "\n",
      "Training\n",
      "Epoch 803 complete\n",
      "Loss was 0.16157738691568374\n",
      "\n",
      "Training\n",
      "Epoch 804 complete\n",
      "Loss was 0.15793435788154603\n",
      "\n",
      "Training\n",
      "Epoch 805 complete\n",
      "Loss was 0.16334756898880004\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.52\n",
      "\n",
      "Training\n",
      "Epoch 806 complete\n",
      "Loss was 0.16189847810566424\n",
      "\n",
      "Training\n",
      "Epoch 807 complete\n",
      "Loss was 0.16230189639329912\n",
      "\n",
      "Training\n",
      "Epoch 808 complete\n",
      "Loss was 0.1598346375823021\n",
      "\n",
      "Training\n",
      "Epoch 809 complete\n",
      "Loss was 0.16159039928019048\n",
      "\n",
      "Training\n",
      "Epoch 810 complete\n",
      "Loss was 0.1581545082628727\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.08\n",
      "\n",
      "Training\n",
      "Epoch 811 complete\n",
      "Loss was 0.16091894069314003\n",
      "\n",
      "Training\n",
      "Epoch 812 complete\n",
      "Loss was 0.15970396840572357\n",
      "\n",
      "Training\n",
      "Epoch 813 complete\n",
      "Loss was 0.16455074119567872\n",
      "\n",
      "Training\n",
      "Epoch 814 complete\n",
      "Loss was 0.1615029976963997\n",
      "\n",
      "Training\n",
      "Epoch 815 complete\n",
      "Loss was 0.16191266584396363\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.62\n",
      "\n",
      "Training\n",
      "Epoch 816 complete\n",
      "Loss was 0.15918964299559593\n",
      "\n",
      "Training\n",
      "Epoch 817 complete\n",
      "Loss was 0.161018617361784\n",
      "\n",
      "Training\n",
      "Epoch 818 complete\n",
      "Loss was 0.1560039294362068\n",
      "\n",
      "Training\n",
      "Epoch 819 complete\n",
      "Loss was 0.16206930395960809\n",
      "\n",
      "Training\n",
      "Epoch 820 complete\n",
      "Loss was 0.16050574684143065\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.45\n",
      "\n",
      "Training\n",
      "Epoch 821 complete\n",
      "Loss was 0.15829266837239264\n",
      "\n",
      "Training\n",
      "Epoch 822 complete\n",
      "Loss was 0.1643668891787529\n",
      "\n",
      "Training\n",
      "Epoch 823 complete\n",
      "Loss was 0.15493718019127845\n",
      "\n",
      "Training\n",
      "Epoch 824 complete\n",
      "Loss was 0.16269372779130936\n",
      "\n",
      "Training\n",
      "Epoch 825 complete\n",
      "Loss was 0.15929419034719466\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.46\n",
      "\n",
      "Training\n",
      "Epoch 826 complete\n",
      "Loss was 0.1618628757596016\n",
      "\n",
      "Training\n",
      "Epoch 827 complete\n",
      "Loss was 0.15859680518507957\n",
      "\n",
      "Training\n",
      "Epoch 828 complete\n",
      "Loss was 0.15684015846252441\n",
      "\n",
      "Training\n",
      "Epoch 829 complete\n",
      "Loss was 0.15678269377350806\n",
      "\n",
      "Training\n",
      "Epoch 830 complete\n",
      "Loss was 0.16488736766576767\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.25\n",
      "\n",
      "Training\n",
      "Epoch 831 complete\n",
      "Loss was 0.157606143578887\n",
      "\n",
      "Training\n",
      "Epoch 832 complete\n",
      "Loss was 0.1619216444194317\n",
      "\n",
      "Training\n",
      "Epoch 833 complete\n",
      "Loss was 0.1647283022105694\n",
      "\n",
      "Training\n",
      "Epoch 834 complete\n",
      "Loss was 0.15870369377732277\n",
      "\n",
      "Training\n",
      "Epoch 835 complete\n",
      "Loss was 0.15848972183465956\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.21\n",
      "\n",
      "Training\n",
      "Epoch 836 complete\n",
      "Loss was 0.15961247646808624\n",
      "\n",
      "Training\n",
      "Epoch 837 complete\n",
      "Loss was 0.1629717082977295\n",
      "\n",
      "Training\n",
      "Epoch 838 complete\n",
      "Loss was 0.15773546658456325\n",
      "\n",
      "Training\n",
      "Epoch 839 complete\n",
      "Loss was 0.16477200308442116\n",
      "\n",
      "Training\n",
      "Epoch 840 complete\n",
      "Loss was 0.15718840077519416\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.69\n",
      "\n",
      "Training\n",
      "Epoch 841 complete\n",
      "Loss was 0.15792798978090286\n",
      "\n",
      "Training\n",
      "Epoch 842 complete\n",
      "Loss was 0.15828466305136682\n",
      "\n",
      "Training\n",
      "Epoch 843 complete\n",
      "Loss was 0.16024856278300284\n",
      "\n",
      "Training\n",
      "Epoch 844 complete\n",
      "Loss was 0.15940016360580922\n",
      "\n",
      "Training\n",
      "Epoch 845 complete\n",
      "Loss was 0.1612395721077919\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.76\n",
      "\n",
      "Training\n",
      "Epoch 846 complete\n",
      "Loss was 0.16253724324703217\n",
      "\n",
      "Training\n",
      "Epoch 847 complete\n",
      "Loss was 0.15995018443465234\n",
      "\n",
      "Training\n",
      "Epoch 848 complete\n",
      "Loss was 0.16086286252737045\n",
      "\n",
      "Training\n",
      "Epoch 849 complete\n",
      "Loss was 0.15837775629758835\n",
      "\n",
      "Training\n",
      "Epoch 850 complete\n",
      "Loss was 0.1582186854183674\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.17\n",
      "\n",
      "Training\n",
      "Epoch 851 complete\n",
      "Loss was 0.1611922450065613\n",
      "\n",
      "Training\n",
      "Epoch 852 complete\n",
      "Loss was 0.15913230115175248\n",
      "\n",
      "Training\n",
      "Epoch 853 complete\n",
      "Loss was 0.1618791007399559\n",
      "\n",
      "Training\n",
      "Epoch 854 complete\n",
      "Loss was 0.16278985160589218\n",
      "\n",
      "Training\n",
      "Epoch 855 complete\n",
      "Loss was 0.15969203612208366\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.53\n",
      "\n",
      "Training\n",
      "Epoch 856 complete\n",
      "Loss was 0.1568724409341812\n",
      "\n",
      "Training\n",
      "Epoch 857 complete\n",
      "Loss was 0.1595747038424015\n",
      "\n",
      "Training\n",
      "Epoch 858 complete\n",
      "Loss was 0.16320886290073394\n",
      "\n",
      "Training\n",
      "Epoch 859 complete\n",
      "Loss was 0.15721010768413543\n",
      "\n",
      "Training\n",
      "Epoch 860 complete\n",
      "Loss was 0.15721516755223275\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.1\n",
      "\n",
      "Training\n",
      "Epoch 861 complete\n",
      "Loss was 0.16043950310349464\n",
      "\n",
      "Training\n",
      "Epoch 862 complete\n",
      "Loss was 0.15995028159022331\n",
      "\n",
      "Training\n",
      "Epoch 863 complete\n",
      "Loss was 0.15918613696098327\n",
      "\n",
      "Training\n",
      "Epoch 864 complete\n",
      "Loss was 0.15859387394785882\n",
      "\n",
      "Training\n",
      "Epoch 865 complete\n",
      "Loss was 0.15882750341296195\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.65\n",
      "\n",
      "Training\n",
      "Epoch 866 complete\n",
      "Loss was 0.16031641618907452\n",
      "\n",
      "Training\n",
      "Epoch 867 complete\n",
      "Loss was 0.15705189844965936\n",
      "\n",
      "Training\n",
      "Epoch 868 complete\n",
      "Loss was 0.1606785168647766\n",
      "\n",
      "Training\n",
      "Epoch 869 complete\n",
      "Loss was 0.1593010061979294\n",
      "\n",
      "Training\n",
      "Epoch 870 complete\n",
      "Loss was 0.16188539129495622\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.16\n",
      "\n",
      "Training\n",
      "Epoch 871 complete\n",
      "Loss was 0.1549345410466194\n",
      "\n",
      "Training\n",
      "Epoch 872 complete\n",
      "Loss was 0.16268385043740272\n",
      "\n",
      "Training\n",
      "Epoch 873 complete\n",
      "Loss was 0.16060941484570504\n",
      "\n",
      "Training\n",
      "Epoch 874 complete\n",
      "Loss was 0.15626229935884475\n",
      "\n",
      "Training\n",
      "Epoch 875 complete\n",
      "Loss was 0.15829221384227277\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.11\n",
      "\n",
      "Training\n",
      "Epoch 876 complete\n",
      "Loss was 0.15701156860589982\n",
      "\n",
      "Training\n",
      "Epoch 877 complete\n",
      "Loss was 0.16285343062877655\n",
      "\n",
      "Training\n",
      "Epoch 878 complete\n",
      "Loss was 0.1577681204676628\n",
      "\n",
      "Training\n",
      "Epoch 879 complete\n",
      "Loss was 0.1614035915285349\n",
      "\n",
      "Training\n",
      "Epoch 880 complete\n",
      "Loss was 0.16162370747327803\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.2\n",
      "\n",
      "Training\n",
      "Epoch 881 complete\n",
      "Loss was 0.15690442204475402\n",
      "\n",
      "Training\n",
      "Epoch 882 complete\n",
      "Loss was 0.15907905817031862\n",
      "\n",
      "Training\n",
      "Epoch 883 complete\n",
      "Loss was 0.15746340750157833\n",
      "\n",
      "Training\n",
      "Epoch 884 complete\n",
      "Loss was 0.16515304362773894\n",
      "\n",
      "Training\n",
      "Epoch 885 complete\n",
      "Loss was 0.16321743127703667\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.19\n",
      "\n",
      "Training\n",
      "Epoch 886 complete\n",
      "Loss was 0.16171953323483468\n",
      "\n",
      "Training\n",
      "Epoch 887 complete\n",
      "Loss was 0.15886155876517297\n",
      "\n",
      "Training\n",
      "Epoch 888 complete\n",
      "Loss was 0.15797341564297676\n",
      "\n",
      "Training\n",
      "Epoch 889 complete\n",
      "Loss was 0.16206428721547128\n",
      "\n",
      "Training\n",
      "Epoch 890 complete\n",
      "Loss was 0.157547482162714\n",
      "\n",
      "Testing\n",
      "Test accuracy was 89.05\n",
      "\n",
      "Training\n",
      "Epoch 891 complete\n",
      "Loss was 0.1610700519979\n",
      "\n",
      "Training\n",
      "Epoch 892 complete\n",
      "Loss was 0.1587741712331772\n",
      "\n",
      "Training\n",
      "Epoch 893 complete\n",
      "Loss was 0.15827623857557774\n",
      "\n",
      "Training\n",
      "Epoch 894 complete\n",
      "Loss was 0.15650509449839592\n",
      "\n",
      "Training\n",
      "Epoch 895 complete\n",
      "Loss was 0.15859335076808928\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.39\n",
      "\n",
      "Training\n",
      "Epoch 896 complete\n",
      "Loss was 0.16254054591059686\n",
      "\n",
      "Training\n",
      "Epoch 897 complete\n",
      "Loss was 0.15854131227731705\n",
      "\n",
      "Training\n",
      "Epoch 898 complete\n",
      "Loss was 0.1610295355618\n",
      "\n",
      "Training\n",
      "Epoch 899 complete\n",
      "Loss was 0.1582126222550869\n",
      "\n",
      "Training\n",
      "Epoch 900 complete\n",
      "Loss was 0.1605189427435398\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.83\n",
      "\n",
      "Training\n",
      "Epoch 901 complete\n",
      "Loss was 0.1623174809217453\n",
      "\n",
      "Training\n",
      "Epoch 902 complete\n",
      "Loss was 0.15622295793890953\n",
      "\n",
      "Training\n",
      "Epoch 903 complete\n",
      "Loss was 0.1577660235762596\n",
      "\n",
      "Training\n",
      "Epoch 904 complete\n",
      "Loss was 0.16177275875210761\n",
      "\n",
      "Training\n",
      "Epoch 905 complete\n",
      "Loss was 0.15466661706566812\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.24\n",
      "\n",
      "Training\n",
      "Epoch 906 complete\n",
      "Loss was 0.15975449952483178\n",
      "\n",
      "Training\n",
      "Epoch 907 complete\n",
      "Loss was 0.1597170973420143\n",
      "\n",
      "Training\n",
      "Epoch 908 complete\n",
      "Loss was 0.15475873869657517\n",
      "\n",
      "Training\n",
      "Epoch 909 complete\n",
      "Loss was 0.15989123284816742\n",
      "\n",
      "Training\n",
      "Epoch 910 complete\n",
      "Loss was 0.15807618486881256\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.03\n",
      "\n",
      "Training\n",
      "Epoch 911 complete\n",
      "Loss was 0.15748307283222676\n",
      "\n",
      "Training\n",
      "Epoch 912 complete\n",
      "Loss was 0.1585441163778305\n",
      "\n",
      "Training\n",
      "Epoch 913 complete\n",
      "Loss was 0.15983222801983357\n",
      "\n",
      "Training\n",
      "Epoch 914 complete\n",
      "Loss was 0.1577250819504261\n",
      "\n",
      "Training\n",
      "Epoch 915 complete\n",
      "Loss was 0.16211514428257942\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.01\n",
      "\n",
      "Training\n",
      "Epoch 916 complete\n",
      "Loss was 0.16038004162907601\n",
      "\n",
      "Training\n",
      "Epoch 917 complete\n",
      "Loss was 0.15874075178802013\n",
      "\n",
      "Training\n",
      "Epoch 918 complete\n",
      "Loss was 0.16123002725839614\n",
      "\n",
      "Training\n",
      "Epoch 919 complete\n",
      "Loss was 0.15418903563916683\n",
      "\n",
      "Training\n",
      "Epoch 920 complete\n",
      "Loss was 0.16140644425153733\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.53\n",
      "\n",
      "Training\n",
      "Epoch 921 complete\n",
      "Loss was 0.16011064207553863\n",
      "\n",
      "Training\n",
      "Epoch 922 complete\n",
      "Loss was 0.1578398911356926\n",
      "\n",
      "Training\n",
      "Epoch 923 complete\n",
      "Loss was 0.15632183748483658\n",
      "\n",
      "Training\n",
      "Epoch 924 complete\n",
      "Loss was 0.15928043606877326\n",
      "\n",
      "Training\n",
      "Epoch 925 complete\n",
      "Loss was 0.1579944739341736\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.4\n",
      "\n",
      "Training\n",
      "Epoch 926 complete\n",
      "Loss was 0.15855370718240738\n",
      "\n",
      "Training\n",
      "Epoch 927 complete\n",
      "Loss was 0.16087171962857247\n",
      "\n",
      "Training\n",
      "Epoch 928 complete\n",
      "Loss was 0.15486233779788017\n",
      "\n",
      "Training\n",
      "Epoch 929 complete\n",
      "Loss was 0.15573304027318954\n",
      "\n",
      "Training\n",
      "Epoch 930 complete\n",
      "Loss was 0.16039035975933075\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.56\n",
      "\n",
      "Training\n",
      "Epoch 931 complete\n",
      "Loss was 0.15626011219620706\n",
      "\n",
      "Training\n",
      "Epoch 932 complete\n",
      "Loss was 0.15758742113411425\n",
      "\n",
      "Training\n",
      "Epoch 933 complete\n",
      "Loss was 0.1572236466407776\n",
      "\n",
      "Training\n",
      "Epoch 934 complete\n",
      "Loss was 0.16107266482710839\n",
      "\n",
      "Training\n",
      "Epoch 935 complete\n",
      "Loss was 0.155758398398757\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.5\n",
      "\n",
      "Training\n",
      "Epoch 936 complete\n",
      "Loss was 0.15857823134958743\n",
      "\n",
      "Training\n",
      "Epoch 937 complete\n",
      "Loss was 0.15905379816889764\n",
      "\n",
      "Training\n",
      "Epoch 938 complete\n",
      "Loss was 0.1594891891479492\n",
      "\n",
      "Training\n",
      "Epoch 939 complete\n",
      "Loss was 0.15657556903362274\n",
      "\n",
      "Training\n",
      "Epoch 940 complete\n",
      "Loss was 0.16111699041724206\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.65\n",
      "\n",
      "Training\n",
      "Epoch 941 complete\n",
      "Loss was 0.15126315712928773\n",
      "\n",
      "Training\n",
      "Epoch 942 complete\n",
      "Loss was 0.15702212044596672\n",
      "\n",
      "Training\n",
      "Epoch 943 complete\n",
      "Loss was 0.1579212911427021\n",
      "\n",
      "Training\n",
      "Epoch 944 complete\n",
      "Loss was 0.1580462502837181\n",
      "\n",
      "Training\n",
      "Epoch 945 complete\n",
      "Loss was 0.15700642386078834\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.77\n",
      "\n",
      "Training\n",
      "Epoch 946 complete\n",
      "Loss was 0.15389291372895242\n",
      "\n",
      "Training\n",
      "Epoch 947 complete\n",
      "Loss was 0.15763355737924575\n",
      "\n",
      "Training\n",
      "Epoch 948 complete\n",
      "Loss was 0.16163919812440872\n",
      "\n",
      "Training\n",
      "Epoch 949 complete\n",
      "Loss was 0.15717773422598838\n",
      "\n",
      "Training\n",
      "Epoch 950 complete\n",
      "Loss was 0.1563469811975956\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.1\n",
      "\n",
      "Training\n",
      "Epoch 951 complete\n",
      "Loss was 0.15796881693601608\n",
      "\n",
      "Training\n",
      "Epoch 952 complete\n",
      "Loss was 0.15706281447410583\n",
      "\n",
      "Training\n",
      "Epoch 953 complete\n",
      "Loss was 0.15518990936875343\n",
      "\n",
      "Training\n",
      "Epoch 954 complete\n",
      "Loss was 0.15942631223797799\n",
      "\n",
      "Training\n",
      "Epoch 955 complete\n",
      "Loss was 0.15349930576980114\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.47\n",
      "\n",
      "Training\n",
      "Epoch 956 complete\n",
      "Loss was 0.1590752350986004\n",
      "\n",
      "Training\n",
      "Epoch 957 complete\n",
      "Loss was 0.15940480580925942\n",
      "\n",
      "Training\n",
      "Epoch 958 complete\n",
      "Loss was 0.15657321161031723\n",
      "\n",
      "Training\n",
      "Epoch 959 complete\n",
      "Loss was 0.15577277332544326\n",
      "\n",
      "Training\n",
      "Epoch 960 complete\n",
      "Loss was 0.1581269173026085\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.47\n",
      "\n",
      "Training\n",
      "Epoch 961 complete\n",
      "Loss was 0.15549305194616317\n",
      "\n",
      "Training\n",
      "Epoch 962 complete\n",
      "Loss was 0.1565167486667633\n",
      "\n",
      "Training\n",
      "Epoch 963 complete\n",
      "Loss was 0.15765324109792708\n",
      "\n",
      "Training\n",
      "Epoch 964 complete\n",
      "Loss was 0.15633568061888217\n",
      "\n",
      "Training\n",
      "Epoch 965 complete\n",
      "Loss was 0.15483788266777992\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.52\n",
      "\n",
      "Training\n",
      "Epoch 966 complete\n",
      "Loss was 0.1562094658911228\n",
      "\n",
      "Training\n",
      "Epoch 967 complete\n",
      "Loss was 0.15492794114351272\n",
      "\n",
      "Training\n",
      "Epoch 968 complete\n",
      "Loss was 0.15647887471318245\n",
      "\n",
      "Training\n",
      "Epoch 969 complete\n",
      "Loss was 0.15496367958188056\n",
      "\n",
      "Training\n",
      "Epoch 970 complete\n",
      "Loss was 0.15344565729796886\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.55\n",
      "\n",
      "Training\n",
      "Epoch 971 complete\n",
      "Loss was 0.16058975586295127\n",
      "\n",
      "Training\n",
      "Epoch 972 complete\n",
      "Loss was 0.15734084305167198\n",
      "\n",
      "Training\n",
      "Epoch 973 complete\n",
      "Loss was 0.16104689252376556\n",
      "\n",
      "Training\n",
      "Epoch 974 complete\n",
      "Loss was 0.1590249856710434\n",
      "\n",
      "Training\n",
      "Epoch 975 complete\n",
      "Loss was 0.15638201519846917\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.96\n",
      "\n",
      "Training\n",
      "Epoch 976 complete\n",
      "Loss was 0.15901635026931762\n",
      "\n",
      "Training\n",
      "Epoch 977 complete\n",
      "Loss was 0.1569488835632801\n",
      "\n",
      "Training\n",
      "Epoch 978 complete\n",
      "Loss was 0.1534205167591572\n",
      "\n",
      "Training\n",
      "Epoch 979 complete\n",
      "Loss was 0.1596164273917675\n",
      "\n",
      "Training\n",
      "Epoch 980 complete\n",
      "Loss was 0.15713144227862358\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.49\n",
      "\n",
      "Training\n",
      "Epoch 981 complete\n",
      "Loss was 0.15801602935791015\n",
      "\n",
      "Training\n",
      "Epoch 982 complete\n",
      "Loss was 0.15586782918870448\n",
      "\n",
      "Training\n",
      "Epoch 983 complete\n",
      "Loss was 0.15857539471983909\n",
      "\n",
      "Training\n",
      "Epoch 984 complete\n",
      "Loss was 0.1588096767961979\n",
      "\n",
      "Training\n",
      "Epoch 985 complete\n",
      "Loss was 0.15821632823348045\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.09\n",
      "\n",
      "Training\n",
      "Epoch 986 complete\n",
      "Loss was 0.15821798712015153\n",
      "\n",
      "Training\n",
      "Epoch 987 complete\n",
      "Loss was 0.16020629939436912\n",
      "\n",
      "Training\n",
      "Epoch 988 complete\n",
      "Loss was 0.1568729337155819\n",
      "\n",
      "Training\n",
      "Epoch 989 complete\n",
      "Loss was 0.15582386913895607\n",
      "\n",
      "Training\n",
      "Epoch 990 complete\n",
      "Loss was 0.15797680762410163\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.52\n",
      "\n",
      "Training\n",
      "Epoch 991 complete\n",
      "Loss was 0.15781328842043876\n",
      "\n",
      "Training\n",
      "Epoch 992 complete\n",
      "Loss was 0.1548420182019472\n",
      "\n",
      "Training\n",
      "Epoch 993 complete\n",
      "Loss was 0.1542541382908821\n",
      "\n",
      "Training\n",
      "Epoch 994 complete\n",
      "Loss was 0.16058059453964232\n",
      "\n",
      "Training\n",
      "Epoch 995 complete\n",
      "Loss was 0.15847809094190599\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.75\n",
      "\n",
      "Training\n",
      "Epoch 996 complete\n",
      "Loss was 0.1559176147580147\n",
      "\n",
      "Training\n",
      "Epoch 997 complete\n",
      "Loss was 0.15973208302259445\n",
      "\n",
      "Training\n",
      "Epoch 998 complete\n",
      "Loss was 0.15642606848478316\n",
      "\n",
      "Training\n",
      "Epoch 999 complete\n",
      "Loss was 0.1550531290769577\n",
      "\n",
      "Training\n",
      "Epoch 1000 complete\n",
      "Loss was 0.1581300155222416\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.14\n",
      "\n",
      "Training\n",
      "Epoch 1001 complete\n",
      "Loss was 0.1588064596951008\n",
      "\n",
      "Training\n",
      "Epoch 1002 complete\n",
      "Loss was 0.1570325711965561\n",
      "\n",
      "Training\n",
      "Epoch 1003 complete\n",
      "Loss was 0.15713053353130818\n",
      "\n",
      "Training\n",
      "Epoch 1004 complete\n",
      "Loss was 0.15589835798740387\n",
      "\n",
      "Training\n",
      "Epoch 1005 complete\n",
      "Loss was 0.15707621160149574\n",
      "\n",
      "Testing\n",
      "Test accuracy was 89.04\n",
      "\n",
      "Training\n",
      "Epoch 1006 complete\n",
      "Loss was 0.1608048613369465\n",
      "\n",
      "Training\n",
      "Epoch 1007 complete\n",
      "Loss was 0.15867293420433998\n",
      "\n",
      "Training\n",
      "Epoch 1008 complete\n",
      "Loss was 0.15569330163300038\n",
      "\n",
      "Training\n",
      "Epoch 1009 complete\n",
      "Loss was 0.1542036546766758\n",
      "\n",
      "Training\n",
      "Epoch 1010 complete\n",
      "Loss was 0.15749552288651467\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.3\n",
      "\n",
      "Training\n",
      "Epoch 1011 complete\n",
      "Loss was 0.1623820121884346\n",
      "\n",
      "Training\n",
      "Epoch 1012 complete\n",
      "Loss was 0.15647075229883195\n",
      "\n",
      "Training\n",
      "Epoch 1013 complete\n",
      "Loss was 0.15925570340454578\n",
      "\n",
      "Training\n",
      "Epoch 1014 complete\n",
      "Loss was 0.15682351353764534\n",
      "\n",
      "Training\n",
      "Epoch 1015 complete\n",
      "Loss was 0.15466303902864456\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.93\n",
      "\n",
      "Training\n",
      "Epoch 1016 complete\n",
      "Loss was 0.15434986808896065\n",
      "\n",
      "Training\n",
      "Epoch 1017 complete\n",
      "Loss was 0.15860594995319843\n",
      "\n",
      "Training\n",
      "Epoch 1018 complete\n",
      "Loss was 0.15702883741259574\n",
      "\n",
      "Training\n",
      "Epoch 1019 complete\n",
      "Loss was 0.1577326200902462\n",
      "\n",
      "Training\n",
      "Epoch 1020 complete\n",
      "Loss was 0.15493551751971243\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.29\n",
      "\n",
      "Training\n",
      "Epoch 1021 complete\n",
      "Loss was 0.15684435710310937\n",
      "\n",
      "Training\n",
      "Epoch 1022 complete\n",
      "Loss was 0.15699516302347183\n",
      "\n",
      "Training\n",
      "Epoch 1023 complete\n",
      "Loss was 0.15551301243901253\n",
      "\n",
      "Training\n",
      "Epoch 1024 complete\n",
      "Loss was 0.16203365328907968\n",
      "\n",
      "Training\n",
      "Epoch 1025 complete\n",
      "Loss was 0.1576681766808033\n",
      "\n",
      "Testing\n",
      "Test accuracy was 87.98\n",
      "\n",
      "Training\n",
      "Epoch 1026 complete\n",
      "Loss was 0.15667322799563407\n",
      "\n",
      "Training\n",
      "Epoch 1027 complete\n",
      "Loss was 0.15662277418375015\n",
      "\n",
      "Training\n",
      "Epoch 1028 complete\n",
      "Loss was 0.1587526205778122\n",
      "\n",
      "Training\n",
      "Epoch 1029 complete\n",
      "Loss was 0.15934221121668815\n",
      "\n",
      "Training\n",
      "Epoch 1030 complete\n",
      "Loss was 0.1514949452728033\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.8\n",
      "\n",
      "Training\n",
      "Epoch 1031 complete\n",
      "Loss was 0.1573809162080288\n",
      "\n",
      "Training\n",
      "Epoch 1032 complete\n",
      "Loss was 0.15530924373865126\n",
      "\n",
      "Training\n",
      "Epoch 1033 complete\n",
      "Loss was 0.15075026071071626\n",
      "\n",
      "Training\n",
      "Epoch 1034 complete\n",
      "Loss was 0.1586199723780155\n",
      "\n",
      "Training\n",
      "Epoch 1035 complete\n",
      "Loss was 0.15582102954387664\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.45\n",
      "\n",
      "Training\n",
      "Epoch 1036 complete\n",
      "Loss was 0.15991218340396882\n",
      "\n",
      "Training\n",
      "Epoch 1037 complete\n",
      "Loss was 0.1564119629263878\n",
      "\n",
      "Training\n",
      "Epoch 1038 complete\n",
      "Loss was 0.15654848039150238\n",
      "\n",
      "Training\n",
      "Epoch 1039 complete\n",
      "Loss was 0.15602995127439498\n",
      "\n",
      "Training\n",
      "Epoch 1040 complete\n",
      "Loss was 0.1550919184088707\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.32\n",
      "\n",
      "Training\n",
      "Epoch 1041 complete\n",
      "Loss was 0.15369645684957503\n",
      "\n",
      "Training\n",
      "Epoch 1042 complete\n",
      "Loss was 0.1510438493937254\n",
      "\n",
      "Training\n",
      "Epoch 1043 complete\n",
      "Loss was 0.15907662203907966\n",
      "\n",
      "Training\n",
      "Epoch 1044 complete\n",
      "Loss was 0.15532599517703055\n",
      "\n",
      "Training\n",
      "Epoch 1045 complete\n",
      "Loss was 0.1591066263616085\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.25\n",
      "\n",
      "Training\n",
      "Epoch 1046 complete\n",
      "Loss was 0.154815298050642\n",
      "\n",
      "Training\n",
      "Epoch 1047 complete\n",
      "Loss was 0.16050968477129937\n",
      "\n",
      "Training\n",
      "Epoch 1048 complete\n",
      "Loss was 0.151349571198225\n",
      "\n",
      "Training\n",
      "Epoch 1049 complete\n",
      "Loss was 0.1520725332200527\n",
      "\n",
      "Training\n",
      "Epoch 1050 complete\n",
      "Loss was 0.15494417375326155\n",
      "\n",
      "Testing\n",
      "Test accuracy was 88.23\n",
      "\n",
      "Training\n",
      "Epoch 1051 complete\n",
      "Loss was 0.15470108968019486\n",
      "\n",
      "Training\n",
      "Epoch 1052 complete\n",
      "Loss was 0.15757803639769555\n",
      "\n",
      "Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21004\\2796821871.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m   \u001B[0mepoch_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m   \u001B[0mprevious_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m   \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m     \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    366\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    367\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 368\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    370\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    312\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_worker_number_rationality\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 314\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    315\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    316\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    925\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    926\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 927\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    928\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    929\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\__init__.py\u001B[0m in \u001B[0;36m_DType_reduce\u001B[1;34m(DType)\u001B[0m\n\u001B[0;32m    146\u001B[0m     \u001B[1;31m# To pickle a DType without having to add top-level names, pickle the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[1;31m# scalar type for now (and assume that reconstruction will be possible).\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 148\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mDType\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    149\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;34m\"dtype\"\u001B[0m  \u001B[1;31m# must pickle `np.dtype` as a singleton.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m     \u001B[0mscalar_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDType\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtype\u001B[0m  \u001B[1;31m# pickle the scalar type for reconstruction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "# try other loss functions/optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.0015)\n",
    "\n",
    "test_per_epoch = False\n",
    "train_for_time = 0 # how many minutes to train for (and then finish current epoch)\n",
    "\n",
    "if train_for_time:\n",
    "  epochs = train_for_time*1000\n",
    "start = time.time()\n",
    "losses = []\n",
    "validls = []\n",
    "for epoch in range(epochs):\n",
    "  print(\"Training\")\n",
    "  epoch_loss = 0\n",
    "  previous_loss = 0\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forwards\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # backwards\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "  for data, labels in validloader:\n",
    "    if torch.cuda.is_available():\n",
    "        data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    target = model(data)\n",
    "    loss = criterion(target,labels)\n",
    "    valid_loss = loss.item() * data.size(0)\n",
    "  validls.append(valid_loss / len(validloader))\n",
    "    # if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "    #\n",
    "    #         # ...log the running loss\n",
    "    #         writer.add_scalar('training loss',\n",
    "    #                         epoch_loss-previous_loss / 1000,\n",
    "    #                         epoch * len(train_loader) + i)\n",
    "    #\n",
    "    #         # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "    #         # random mini-batch\n",
    "    #         writer.add_figure('predictions vs. actuals',\n",
    "    #                         plot_classes_preds(model, images, labels),\n",
    "    #                         global_step=epoch * len(train_loader) + i)\n",
    "    #         previous_loss = epoch_loss\n",
    "  \n",
    "  print(\"Epoch\", epoch+1, \"complete\")\n",
    "  print(\"Loss was\", epoch_loss/len(train_loader))\n",
    "  losses.append(epoch_loss/len(train_loader))\n",
    "  print()\n",
    "  if (epoch+1)%5 == 0 or test_per_epoch == True:\n",
    "    test()\n",
    "\n",
    "  \n",
    "  if train_for_time and time.time()-start >= train_for_time*60:\n",
    "    break\n",
    "\n",
    "if not test_per_epoch:\n",
    "  test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([losses, validls])\n",
    "df.to_csv(\"./outputnoBN2.csv\", sep = ',', index = True)"
   ],
   "metadata": {
    "id": "bYyMlOlfiyV6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_graph(model_copy, images)\n",
    "writer.add_image('first_visualization_test', img_grid)\n",
    "writer.close()"
   ],
   "metadata": {
    "id": "bGHX3IX3iyYc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/first_visualization_test/"
   ],
   "metadata": {
    "id": "A-g1rugJiybL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}