{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of INT2_Group2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install captum\n",
    "pip install flask_compress\n",
    "conda install freetype=2.10.4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/first_visualization_test')"
   ],
   "metadata": {
    "id": "TNY_v8m0ih6G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance\n",
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.attr_vis.features import ImageFeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ],
   "metadata": {
    "id": "BwDdxZ-LiiKI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available(): # use gpu if possible\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "JR6ZVgNKiiNH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "epochs = 4000\n",
    "batch_size = 400\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# only need resize so AlexNet works\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomAffine(0, (0.1, 0.1)),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# get training/test data from CIFAR10 dataset\n",
    "train_data = torchvision.datasets.CIFAR10(root = \"./dataset/train\",\n",
    "                                        train = True, \n",
    "                                        transform = train_transform, \n",
    "                                        download = True)\n",
    "test_data = torchvision.datasets.CIFAR10(root = \"./dataset/test\",\n",
    "                                       train = False, \n",
    "                                       transform = test_transform, \n",
    "                                       download = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle = True, \n",
    "                                           num_workers = 3)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = False, \n",
    "                                          num_workers = 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(3, 128, 3, 1, padding=\"same\")\n",
    "    self.conv2 = nn.Conv2d(128, 128, 3, 1, padding=\"same\")\n",
    "    self.conv25 = nn.Conv2d(128, 128, 3, 1, padding=\"same\")\n",
    "    self.conv3 = nn.Conv2d(128, 256, 3, 1, padding=\"same\")\n",
    "    self.conv4 = nn.Conv2d(256, 256, 3, 1, padding=\"same\")\n",
    "    self.conv5 = nn.Conv2d(256, 512, 3, 1, padding=\"same\")\n",
    "    self.conv6 = nn.Conv2d(512, 512, 3, 1, padding=\"same\")\n",
    "    #self.conv7 = nn.Conv2d(48, 48, 3, 1)\n",
    "\n",
    "    self.maxPool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    self.drop1 = nn.Dropout(0.35)\n",
    "    self.drop2 = nn.Dropout(0.45)\n",
    "    self.drop3 = nn.Dropout(0.6)\n",
    "    self.drop4 = nn.Dropout(0.7)\n",
    "\n",
    "    self.BN1 = nn.BatchNorm2d(128)\n",
    "    self.BN2 = nn.BatchNorm2d(256)\n",
    "    self.BN3 = nn.BatchNorm2d(512)\n",
    "    self.BN4 = nn.BatchNorm1d(256)\n",
    "\n",
    "    self.fc1 = nn.Linear(512, 256)\n",
    "    self.fc2 = nn.Linear(256, 128)\n",
    "    self.fc3 = nn.Linear(128, 10)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = nn.functional.rrelu(self.conv1(x))\n",
    "    x = self.BN1(x)\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop1(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv2(x))\n",
    "    x = self.BN1(x)\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop1(x)\n",
    "\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv25(x))\n",
    "    x = self.BN1(x)\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop2(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv3(x))\n",
    "    x = self.BN2(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv4(x))\n",
    "    x = self.BN2(x)\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop3(x)\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv5(x))\n",
    "    x = self.BN3(x)\n",
    "    x = self.maxPool(x)\n",
    "    x = self.drop4(x)\n",
    "\n",
    "\n",
    "    x = nn.functional.rrelu(self.conv6(x))\n",
    "    x = self.drop4(x)\n",
    "    x = self.BN3(x)\n",
    "\n",
    "    #x = nn.functional.rrelu(self.conv7(x))\n",
    "\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "   # print(x.shape)\n",
    "    x = nn.functional.rrelu(self.fc1(x))\n",
    "    x = self.BN4(x)\n",
    "    x = nn.functional.rrelu(self.fc2(x))\n",
    "    x = self.drop2(x)\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Model creation\n",
    "\n",
    "model_copy = CNN()\n",
    "model = CNN().to(device)"
   ],
   "metadata": {
    "id": "9zrgyIqEiiia",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    try:\n",
    "      npimg = img.numpy()\n",
    "    except:\n",
    "      npimg = img.cpu().data.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ],
   "metadata": {
    "id": "-bgHqO1Biik6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().data.numpy())\n",
    "    return preds, [nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            train_data.classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            train_data.classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig\n"
   ],
   "metadata": {
    "id": "GH4m_yhaiinq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def test():\n",
    "  print(\"Testing\")\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "\n",
    "    for (images, labels) in test_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predictions = outputs.max(1)\n",
    "\n",
    "      samples += labels.size(0)\n",
    "      correct += (predictions == labels).sum()\n",
    "\n",
    "    print(\"Test accuracy was\",100*float(correct)/float(samples))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## Training\n",
    "\n",
    "# try other loss functions/optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.0015)\n",
    "\n",
    "test_per_epoch = True\n",
    "train_for_time = 0 # how many minutes to train for (and then finish current epoch)\n",
    "\n",
    "if train_for_time:\n",
    "  epochs = train_for_time*1000\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(\"Training\")\n",
    "  epoch_loss = 0\n",
    "  previous_loss = 0\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forwards\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # backwards\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    # if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "    #\n",
    "    #         # ...log the running loss\n",
    "    #         writer.add_scalar('training loss',\n",
    "    #                         epoch_loss-previous_loss / 1000,\n",
    "    #                         epoch * len(train_loader) + i)\n",
    "    #\n",
    "    #         # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "    #         # random mini-batch\n",
    "    #         writer.add_figure('predictions vs. actuals',\n",
    "    #                         plot_classes_preds(model, images, labels),\n",
    "    #                         global_step=epoch * len(train_loader) + i)\n",
    "    #         previous_loss = epoch_loss\n",
    "  \n",
    "  print(\"Epoch\", epoch+1, \"complete\")\n",
    "  print(\"Loss was\", epoch_loss/len(train_loader))\n",
    "  print()\n",
    "  if (epoch %5 == 0):\n",
    "    test()\n",
    "  \n",
    "  if train_for_time and time.time()-start >= train_for_time*60:\n",
    "    break\n",
    "\n",
    "if not test_per_epoch:\n",
    "  test()"
   ],
   "metadata": {
    "id": "byaDzD35itRL",
    "outputId": "2ed84bcb-89cd-4d21-ea07-66a0c2779bc3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1 complete\n",
      "Loss was 2.072716589927673\n",
      "\n",
      "Testing\n",
      "Test accuracy was 27.03\n",
      "\n",
      "Training\n",
      "Epoch 2 complete\n",
      "Loss was 1.7511952962875366\n",
      "\n",
      "Training\n",
      "Epoch 3 complete\n",
      "Loss was 1.5987860403060914\n",
      "\n",
      "Training\n",
      "Epoch 4 complete\n",
      "Loss was 1.4929287919998169\n",
      "\n",
      "Training\n",
      "Epoch 5 complete\n",
      "Loss was 1.3804418258666993\n",
      "\n",
      "Training\n",
      "Epoch 6 complete\n",
      "Loss was 1.3013760976791382\n",
      "\n",
      "Testing\n",
      "Test accuracy was 55.08\n",
      "\n",
      "Training\n",
      "Epoch 7 complete\n",
      "Loss was 1.224283595085144\n",
      "\n",
      "Training\n",
      "Epoch 8 complete\n",
      "Loss was 1.1645303087234498\n",
      "\n",
      "Training\n",
      "Epoch 9 complete\n",
      "Loss was 1.1077561511993408\n",
      "\n",
      "Training\n",
      "Epoch 10 complete\n",
      "Loss was 1.0633563594818116\n",
      "\n",
      "Training\n",
      "Epoch 11 complete\n",
      "Loss was 1.0346140432357789\n",
      "\n",
      "Testing\n",
      "Test accuracy was 64.79\n",
      "\n",
      "Training\n",
      "Epoch 12 complete\n",
      "Loss was 1.0018307566642761\n",
      "\n",
      "Training\n",
      "Epoch 13 complete\n",
      "Loss was 0.9734318466186523\n",
      "\n",
      "Training\n",
      "Epoch 14 complete\n",
      "Loss was 0.947930639743805\n",
      "\n",
      "Training\n",
      "Epoch 15 complete\n",
      "Loss was 0.9257447714805603\n",
      "\n",
      "Training\n",
      "Epoch 16 complete\n",
      "Loss was 0.9076324090957641\n",
      "\n",
      "Testing\n",
      "Test accuracy was 69.18\n",
      "\n",
      "Training\n",
      "Epoch 17 complete\n",
      "Loss was 0.8854134087562561\n",
      "\n",
      "Training\n",
      "Epoch 18 complete\n",
      "Loss was 0.8670606894493103\n",
      "\n",
      "Training\n",
      "Epoch 19 complete\n",
      "Loss was 0.8501648874282837\n",
      "\n",
      "Training\n",
      "Epoch 20 complete\n",
      "Loss was 0.8419082760810852\n",
      "\n",
      "Training\n",
      "Epoch 21 complete\n",
      "Loss was 0.8303456902503967\n",
      "\n",
      "Testing\n",
      "Test accuracy was 71.19\n",
      "\n",
      "Training\n",
      "Epoch 22 complete\n",
      "Loss was 0.8163048701286316\n",
      "\n",
      "Training\n",
      "Epoch 23 complete\n",
      "Loss was 0.8021487736701965\n",
      "\n",
      "Training\n",
      "Epoch 24 complete\n",
      "Loss was 0.789548990726471\n",
      "\n",
      "Training\n",
      "Epoch 25 complete\n",
      "Loss was 0.7805160884857177\n",
      "\n",
      "Training\n",
      "Epoch 26 complete\n",
      "Loss was 0.769315691947937\n",
      "\n",
      "Testing\n",
      "Test accuracy was 73.67\n",
      "\n",
      "Training\n",
      "Epoch 27 complete\n",
      "Loss was 0.7593016948699951\n",
      "\n",
      "Training\n",
      "Epoch 28 complete\n",
      "Loss was 0.7518294978141785\n",
      "\n",
      "Training\n",
      "Epoch 29 complete\n",
      "Loss was 0.7388920364379883\n",
      "\n",
      "Training\n",
      "Epoch 30 complete\n",
      "Loss was 0.7347824721336365\n",
      "\n",
      "Training\n",
      "Epoch 31 complete\n",
      "Loss was 0.7260646324157715\n",
      "\n",
      "Testing\n",
      "Test accuracy was 74.86\n",
      "\n",
      "Training\n",
      "Epoch 32 complete\n",
      "Loss was 0.7198322052955628\n",
      "\n",
      "Training\n",
      "Epoch 33 complete\n",
      "Loss was 0.7074489407539367\n",
      "\n",
      "Training\n",
      "Epoch 34 complete\n",
      "Loss was 0.7065972938537598\n",
      "\n",
      "Training\n",
      "Epoch 35 complete\n",
      "Loss was 0.7015644183158875\n",
      "\n",
      "Training\n",
      "Epoch 36 complete\n",
      "Loss was 0.6929101500511169\n",
      "\n",
      "Testing\n",
      "Test accuracy was 76.48\n",
      "\n",
      "Training\n",
      "Epoch 37 complete\n",
      "Loss was 0.6853337073326111\n",
      "\n",
      "Training\n",
      "Epoch 38 complete\n",
      "Loss was 0.6823780407905579\n",
      "\n",
      "Training\n",
      "Epoch 39 complete\n",
      "Loss was 0.6695103220939637\n",
      "\n",
      "Training\n",
      "Epoch 40 complete\n",
      "Loss was 0.6664573106765747\n",
      "\n",
      "Training\n",
      "Epoch 41 complete\n",
      "Loss was 0.6634471888542175\n",
      "\n",
      "Testing\n",
      "Test accuracy was 77.41\n",
      "\n",
      "Training\n",
      "Epoch 42 complete\n",
      "Loss was 0.6585442280769348\n",
      "\n",
      "Training\n",
      "Epoch 43 complete\n",
      "Loss was 0.6497437205314637\n",
      "\n",
      "Training\n",
      "Epoch 44 complete\n",
      "Loss was 0.6484909009933472\n",
      "\n",
      "Training\n",
      "Epoch 45 complete\n",
      "Loss was 0.6479145336151123\n",
      "\n",
      "Training\n",
      "Epoch 46 complete\n",
      "Loss was 0.641175164937973\n",
      "\n",
      "Testing\n",
      "Test accuracy was 77.45\n",
      "\n",
      "Training\n",
      "Epoch 47 complete\n",
      "Loss was 0.6424304599761963\n",
      "\n",
      "Training\n",
      "Epoch 48 complete\n",
      "Loss was 0.6372549271583557\n",
      "\n",
      "Training\n",
      "Epoch 49 complete\n",
      "Loss was 0.6284825918674469\n",
      "\n",
      "Training\n",
      "Epoch 50 complete\n",
      "Loss was 0.6222629528045655\n",
      "\n",
      "Training\n",
      "Epoch 51 complete\n",
      "Loss was 0.6212347345352173\n",
      "\n",
      "Testing\n",
      "Test accuracy was 77.54\n",
      "\n",
      "Training\n",
      "Epoch 52 complete\n",
      "Loss was 0.6181563150882721\n",
      "\n",
      "Training\n",
      "Epoch 53 complete\n",
      "Loss was 0.6167839140892029\n",
      "\n",
      "Training\n",
      "Epoch 54 complete\n",
      "Loss was 0.6145316083431244\n",
      "\n",
      "Training\n",
      "Epoch 55 complete\n",
      "Loss was 0.6128693060874939\n",
      "\n",
      "Training\n",
      "Epoch 56 complete\n",
      "Loss was 0.6094368636608124\n",
      "\n",
      "Testing\n",
      "Test accuracy was 78.71\n",
      "\n",
      "Training\n",
      "Epoch 57 complete\n",
      "Loss was 0.5966519458293915\n",
      "\n",
      "Training\n",
      "Epoch 58 complete\n",
      "Loss was 0.6041883702278137\n",
      "\n",
      "Training\n",
      "Epoch 59 complete\n",
      "Loss was 0.5995230338573456\n",
      "\n",
      "Training\n",
      "Epoch 60 complete\n",
      "Loss was 0.5926191048622131\n",
      "\n",
      "Training\n",
      "Epoch 61 complete\n",
      "Loss was 0.5936630499362946\n",
      "\n",
      "Testing\n",
      "Test accuracy was 78.84\n",
      "\n",
      "Training\n",
      "Epoch 62 complete\n",
      "Loss was 0.5906715369224549\n",
      "\n",
      "Training\n",
      "Epoch 63 complete\n",
      "Loss was 0.5928715486526489\n",
      "\n",
      "Training\n",
      "Epoch 64 complete\n",
      "Loss was 0.5818222966194153\n",
      "\n",
      "Training\n",
      "Epoch 65 complete\n",
      "Loss was 0.5840487763881683\n",
      "\n",
      "Training\n",
      "Epoch 66 complete\n",
      "Loss was 0.5805467064380646\n",
      "\n",
      "Testing\n",
      "Test accuracy was 78.65\n",
      "\n",
      "Training\n",
      "Epoch 67 complete\n",
      "Loss was 0.5807109782695771\n",
      "\n",
      "Training\n",
      "Epoch 68 complete\n",
      "Loss was 0.5714158790111542\n",
      "\n",
      "Training\n",
      "Epoch 69 complete\n",
      "Loss was 0.5789312212467194\n",
      "\n",
      "Training\n",
      "Epoch 70 complete\n",
      "Loss was 0.5693053781986237\n",
      "\n",
      "Training\n",
      "Epoch 71 complete\n",
      "Loss was 0.5674922676086426\n",
      "\n",
      "Testing\n",
      "Test accuracy was 79.98\n",
      "\n",
      "Training\n",
      "Epoch 72 complete\n",
      "Loss was 0.5668418500423431\n",
      "\n",
      "Training\n",
      "Epoch 73 complete\n",
      "Loss was 0.567594003200531\n",
      "\n",
      "Training\n",
      "Epoch 74 complete\n",
      "Loss was 0.5655009870529175\n",
      "\n",
      "Training\n",
      "Epoch 75 complete\n",
      "Loss was 0.5578821442127228\n",
      "\n",
      "Training\n",
      "Epoch 76 complete\n",
      "Loss was 0.5629692466259003\n",
      "\n",
      "Testing\n",
      "Test accuracy was 79.37\n",
      "\n",
      "Training\n",
      "Epoch 77 complete\n",
      "Loss was 0.5610140450000763\n",
      "\n",
      "Training\n",
      "Epoch 78 complete\n",
      "Loss was 0.5572848210334778\n",
      "\n",
      "Training\n",
      "Epoch 79 complete\n",
      "Loss was 0.5611949319839478\n",
      "\n",
      "Training\n",
      "Epoch 80 complete\n",
      "Loss was 0.5517751216888428\n",
      "\n",
      "Training\n",
      "Epoch 81 complete\n",
      "Loss was 0.5537389297485351\n",
      "\n",
      "Testing\n",
      "Test accuracy was 79.85\n",
      "\n",
      "Training\n",
      "Epoch 82 complete\n",
      "Loss was 0.5475304982662201\n",
      "\n",
      "Training\n",
      "Epoch 83 complete\n",
      "Loss was 0.5466915493011475\n",
      "\n",
      "Training\n",
      "Epoch 84 complete\n",
      "Loss was 0.5478627316951752\n",
      "\n",
      "Training\n",
      "Epoch 85 complete\n",
      "Loss was 0.5466351051330567\n",
      "\n",
      "Training\n",
      "Epoch 86 complete\n",
      "Loss was 0.5474174098968506\n",
      "\n",
      "Testing\n",
      "Test accuracy was 79.86\n",
      "\n",
      "Training\n",
      "Epoch 87 complete\n",
      "Loss was 0.548203654050827\n",
      "\n",
      "Training\n",
      "Epoch 88 complete\n",
      "Loss was 0.5455359375476837\n",
      "\n",
      "Training\n",
      "Epoch 89 complete\n",
      "Loss was 0.5322863554954529\n",
      "\n",
      "Training\n",
      "Epoch 90 complete\n",
      "Loss was 0.5404630680084228\n",
      "\n",
      "Training\n",
      "Epoch 91 complete\n",
      "Loss was 0.5365188970565796\n",
      "\n",
      "Testing\n",
      "Test accuracy was 80.86\n",
      "\n",
      "Training\n",
      "Epoch 92 complete\n",
      "Loss was 0.5409916396141052\n",
      "\n",
      "Training\n",
      "Epoch 93 complete\n",
      "Loss was 0.5360934724807739\n",
      "\n",
      "Training\n",
      "Epoch 94 complete\n",
      "Loss was 0.539555593252182\n",
      "\n",
      "Training\n",
      "Epoch 95 complete\n",
      "Loss was 0.534469656944275\n",
      "\n",
      "Training\n",
      "Epoch 96 complete\n",
      "Loss was 0.5347531206607818\n",
      "\n",
      "Testing\n",
      "Test accuracy was 80.76\n",
      "\n",
      "Training\n",
      "Epoch 97 complete\n",
      "Loss was 0.5308572895526886\n",
      "\n",
      "Training\n",
      "Epoch 98 complete\n",
      "Loss was 0.5289011545181275\n",
      "\n",
      "Training\n",
      "Epoch 99 complete\n",
      "Loss was 0.5234335157871246\n",
      "\n",
      "Training\n",
      "Epoch 100 complete\n",
      "Loss was 0.5248877015113831\n",
      "\n",
      "Training\n",
      "Epoch 101 complete\n",
      "Loss was 0.5259486603736877\n",
      "\n",
      "Testing\n",
      "Test accuracy was 80.53\n",
      "\n",
      "Training\n",
      "Epoch 102 complete\n",
      "Loss was 0.5275384767055511\n",
      "\n",
      "Training\n",
      "Epoch 103 complete\n",
      "Loss was 0.5238796987533569\n",
      "\n",
      "Training\n",
      "Epoch 104 complete\n",
      "Loss was 0.5254377269744873\n",
      "\n",
      "Training\n",
      "Epoch 105 complete\n",
      "Loss was 0.5222097215652466\n",
      "\n",
      "Training\n",
      "Epoch 106 complete\n",
      "Loss was 0.5240800063610077\n",
      "\n",
      "Testing\n",
      "Test accuracy was 80.85\n",
      "\n",
      "Training\n",
      "Epoch 107 complete\n",
      "Loss was 0.5150842130184173\n",
      "\n",
      "Training\n",
      "Epoch 108 complete\n",
      "Loss was 0.5227068126201629\n",
      "\n",
      "Training\n",
      "Epoch 109 complete\n",
      "Loss was 0.5168107163906097\n",
      "\n",
      "Training\n",
      "Epoch 110 complete\n",
      "Loss was 0.5207884647846222\n",
      "\n",
      "Training\n",
      "Epoch 111 complete\n",
      "Loss was 0.5188944172859192\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.38\n",
      "\n",
      "Training\n",
      "Epoch 112 complete\n",
      "Loss was 0.5147686092853546\n",
      "\n",
      "Training\n",
      "Epoch 113 complete\n",
      "Loss was 0.5168559160232544\n",
      "\n",
      "Training\n",
      "Epoch 114 complete\n",
      "Loss was 0.5134014370441436\n",
      "\n",
      "Training\n",
      "Epoch 115 complete\n",
      "Loss was 0.5162735915184021\n",
      "\n",
      "Training\n",
      "Epoch 116 complete\n",
      "Loss was 0.5132695560455323\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.64\n",
      "\n",
      "Training\n",
      "Epoch 117 complete\n",
      "Loss was 0.5115685076713562\n",
      "\n",
      "Training\n",
      "Epoch 118 complete\n",
      "Loss was 0.5080784466266632\n",
      "\n",
      "Training\n",
      "Epoch 119 complete\n",
      "Loss was 0.5142781629562377\n",
      "\n",
      "Training\n",
      "Epoch 120 complete\n",
      "Loss was 0.5072811357975006\n",
      "\n",
      "Training\n",
      "Epoch 121 complete\n",
      "Loss was 0.5041734275817871\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.37\n",
      "\n",
      "Training\n",
      "Epoch 122 complete\n",
      "Loss was 0.5056135125160217\n",
      "\n",
      "Training\n",
      "Epoch 123 complete\n",
      "Loss was 0.5079636659622192\n",
      "\n",
      "Training\n",
      "Epoch 124 complete\n",
      "Loss was 0.5106422715187072\n",
      "\n",
      "Training\n",
      "Epoch 125 complete\n",
      "Loss was 0.5042309544086456\n",
      "\n",
      "Training\n",
      "Epoch 126 complete\n",
      "Loss was 0.5012082197666168\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.74\n",
      "\n",
      "Training\n",
      "Epoch 127 complete\n",
      "Loss was 0.5107154228687286\n",
      "\n",
      "Training\n",
      "Epoch 128 complete\n",
      "Loss was 0.5005586564540863\n",
      "\n",
      "Training\n",
      "Epoch 129 complete\n",
      "Loss was 0.5018753778934478\n",
      "\n",
      "Training\n",
      "Epoch 130 complete\n",
      "Loss was 0.5000848252773284\n",
      "\n",
      "Training\n",
      "Epoch 131 complete\n",
      "Loss was 0.4988123333454132\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.62\n",
      "\n",
      "Training\n",
      "Epoch 132 complete\n",
      "Loss was 0.5038798830509186\n",
      "\n",
      "Training\n",
      "Epoch 133 complete\n",
      "Loss was 0.5035196597576141\n",
      "\n",
      "Training\n",
      "Epoch 134 complete\n",
      "Loss was 0.4996664831638336\n",
      "\n",
      "Training\n",
      "Epoch 135 complete\n",
      "Loss was 0.49854763197898866\n",
      "\n",
      "Training\n",
      "Epoch 136 complete\n",
      "Loss was 0.49205374693870546\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.32\n",
      "\n",
      "Training\n",
      "Epoch 137 complete\n",
      "Loss was 0.5005285367965698\n",
      "\n",
      "Training\n",
      "Epoch 138 complete\n",
      "Loss was 0.5004288296699524\n",
      "\n",
      "Training\n",
      "Epoch 139 complete\n",
      "Loss was 0.49228992342948913\n",
      "\n",
      "Training\n",
      "Epoch 140 complete\n",
      "Loss was 0.4939280731678009\n",
      "\n",
      "Training\n",
      "Epoch 141 complete\n",
      "Loss was 0.49384055185317993\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.06\n",
      "\n",
      "Training\n",
      "Epoch 142 complete\n",
      "Loss was 0.4943277678489685\n",
      "\n",
      "Training\n",
      "Epoch 143 complete\n",
      "Loss was 0.48889683508872983\n",
      "\n",
      "Training\n",
      "Epoch 144 complete\n",
      "Loss was 0.4913337342739105\n",
      "\n",
      "Training\n",
      "Epoch 145 complete\n",
      "Loss was 0.49270362758636477\n",
      "\n",
      "Training\n",
      "Epoch 146 complete\n",
      "Loss was 0.48902793860435484\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.85\n",
      "\n",
      "Training\n",
      "Epoch 147 complete\n",
      "Loss was 0.4914503755569458\n",
      "\n",
      "Training\n",
      "Epoch 148 complete\n",
      "Loss was 0.4957260575294495\n",
      "\n",
      "Training\n",
      "Epoch 149 complete\n",
      "Loss was 0.4913943190574646\n",
      "\n",
      "Training\n",
      "Epoch 150 complete\n",
      "Loss was 0.49023727130889894\n",
      "\n",
      "Training\n",
      "Epoch 151 complete\n",
      "Loss was 0.48750145387649535\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.25\n",
      "\n",
      "Training\n",
      "Epoch 152 complete\n",
      "Loss was 0.4876088514328003\n",
      "\n",
      "Training\n",
      "Epoch 153 complete\n",
      "Loss was 0.49207468175888064\n",
      "\n",
      "Training\n",
      "Epoch 154 complete\n",
      "Loss was 0.4869343059062958\n",
      "\n",
      "Training\n",
      "Epoch 155 complete\n",
      "Loss was 0.4913376002311707\n",
      "\n",
      "Training\n",
      "Epoch 156 complete\n",
      "Loss was 0.48208687925338745\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.08\n",
      "\n",
      "Training\n",
      "Epoch 157 complete\n",
      "Loss was 0.48126022624969483\n",
      "\n",
      "Training\n",
      "Epoch 158 complete\n",
      "Loss was 0.48449599838256835\n",
      "\n",
      "Training\n",
      "Epoch 159 complete\n",
      "Loss was 0.4888966279029846\n",
      "\n",
      "Training\n",
      "Epoch 160 complete\n",
      "Loss was 0.4877305870056152\n",
      "\n",
      "Training\n",
      "Epoch 161 complete\n",
      "Loss was 0.48034170603752135\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.58\n",
      "\n",
      "Training\n",
      "Epoch 162 complete\n",
      "Loss was 0.48384185338020325\n",
      "\n",
      "Training\n",
      "Epoch 163 complete\n",
      "Loss was 0.4829382674694061\n",
      "\n",
      "Training\n",
      "Epoch 164 complete\n",
      "Loss was 0.4829847769737244\n",
      "\n",
      "Training\n",
      "Epoch 165 complete\n",
      "Loss was 0.48219014501571655\n",
      "\n",
      "Training\n",
      "Epoch 166 complete\n",
      "Loss was 0.4824555261135101\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.73\n",
      "\n",
      "Training\n",
      "Epoch 167 complete\n",
      "Loss was 0.475011246919632\n",
      "\n",
      "Training\n",
      "Epoch 168 complete\n",
      "Loss was 0.47775520968437196\n",
      "\n",
      "Training\n",
      "Epoch 169 complete\n",
      "Loss was 0.4741327435970306\n",
      "\n",
      "Training\n",
      "Epoch 170 complete\n",
      "Loss was 0.4741031975746155\n",
      "\n",
      "Training\n",
      "Epoch 171 complete\n",
      "Loss was 0.4802626101970673\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.45\n",
      "\n",
      "Training\n",
      "Epoch 172 complete\n",
      "Loss was 0.47654822492599486\n",
      "\n",
      "Training\n",
      "Epoch 173 complete\n",
      "Loss was 0.4790091071128845\n",
      "\n",
      "Training\n",
      "Epoch 174 complete\n",
      "Loss was 0.4772722795009613\n",
      "\n",
      "Training\n",
      "Epoch 175 complete\n",
      "Loss was 0.47887015223503115\n",
      "\n",
      "Training\n",
      "Epoch 176 complete\n",
      "Loss was 0.47469021773338316\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.48\n",
      "\n",
      "Training\n",
      "Epoch 177 complete\n",
      "Loss was 0.48009715461730956\n",
      "\n",
      "Training\n",
      "Epoch 178 complete\n",
      "Loss was 0.47474287676811217\n",
      "\n",
      "Training\n",
      "Epoch 179 complete\n",
      "Loss was 0.47172050762176515\n",
      "\n",
      "Training\n",
      "Epoch 180 complete\n",
      "Loss was 0.4792769010066986\n",
      "\n",
      "Training\n",
      "Epoch 181 complete\n",
      "Loss was 0.4757447154521942\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.36\n",
      "\n",
      "Training\n",
      "Epoch 182 complete\n",
      "Loss was 0.4705430014133453\n",
      "\n",
      "Training\n",
      "Epoch 183 complete\n",
      "Loss was 0.47260963249206545\n",
      "\n",
      "Training\n",
      "Epoch 184 complete\n",
      "Loss was 0.47001747584342957\n",
      "\n",
      "Training\n",
      "Epoch 185 complete\n",
      "Loss was 0.4718349697589874\n",
      "\n",
      "Training\n",
      "Epoch 186 complete\n",
      "Loss was 0.47517514777183534\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.42\n",
      "\n",
      "Training\n",
      "Epoch 187 complete\n",
      "Loss was 0.47391520309448243\n",
      "\n",
      "Training\n",
      "Epoch 188 complete\n",
      "Loss was 0.47547650694847104\n",
      "\n",
      "Training\n",
      "Epoch 189 complete\n",
      "Loss was 0.4707983682155609\n",
      "\n",
      "Training\n",
      "Epoch 190 complete\n",
      "Loss was 0.4655201189517975\n",
      "\n",
      "Training\n",
      "Epoch 191 complete\n",
      "Loss was 0.47699103307724\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.1\n",
      "\n",
      "Training\n",
      "Epoch 192 complete\n",
      "Loss was 0.4721349818706512\n",
      "\n",
      "Training\n",
      "Epoch 193 complete\n",
      "Loss was 0.4703619704246521\n",
      "\n",
      "Training\n",
      "Epoch 194 complete\n",
      "Loss was 0.4718840627670288\n",
      "\n",
      "Training\n",
      "Epoch 195 complete\n",
      "Loss was 0.46737072920799255\n",
      "\n",
      "Training\n",
      "Epoch 196 complete\n",
      "Loss was 0.46551502990722654\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.81\n",
      "\n",
      "Training\n",
      "Epoch 197 complete\n",
      "Loss was 0.4698744697570801\n",
      "\n",
      "Training\n",
      "Epoch 198 complete\n",
      "Loss was 0.4725973012447357\n",
      "\n",
      "Training\n",
      "Epoch 199 complete\n",
      "Loss was 0.4651224684715271\n",
      "\n",
      "Training\n",
      "Epoch 200 complete\n",
      "Loss was 0.4693438458442688\n",
      "\n",
      "Training\n",
      "Epoch 201 complete\n",
      "Loss was 0.4633978419303894\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.53\n",
      "\n",
      "Training\n",
      "Epoch 202 complete\n",
      "Loss was 0.4703884079456329\n",
      "\n",
      "Training\n",
      "Epoch 203 complete\n",
      "Loss was 0.4692319839000702\n",
      "\n",
      "Training\n",
      "Epoch 204 complete\n",
      "Loss was 0.4675621430873871\n",
      "\n",
      "Training\n",
      "Epoch 205 complete\n",
      "Loss was 0.4628284275531769\n",
      "\n",
      "Training\n",
      "Epoch 206 complete\n",
      "Loss was 0.45697405815124514\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.93\n",
      "\n",
      "Training\n",
      "Epoch 207 complete\n",
      "Loss was 0.4650130591392517\n",
      "\n",
      "Training\n",
      "Epoch 208 complete\n",
      "Loss was 0.4637476048469543\n",
      "\n",
      "Training\n",
      "Epoch 209 complete\n",
      "Loss was 0.45823411679267884\n",
      "\n",
      "Training\n",
      "Epoch 210 complete\n",
      "Loss was 0.462172709941864\n",
      "\n",
      "Training\n",
      "Epoch 211 complete\n",
      "Loss was 0.466725234746933\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.07\n",
      "\n",
      "Training\n",
      "Epoch 212 complete\n",
      "Loss was 0.460789573431015\n",
      "\n",
      "Training\n",
      "Epoch 213 complete\n",
      "Loss was 0.4620608184337616\n",
      "\n",
      "Training\n",
      "Epoch 214 complete\n",
      "Loss was 0.4664693334102631\n",
      "\n",
      "Training\n",
      "Epoch 215 complete\n",
      "Loss was 0.46179345226287843\n",
      "\n",
      "Training\n",
      "Epoch 216 complete\n",
      "Loss was 0.46314560556411744\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.4\n",
      "\n",
      "Training\n",
      "Epoch 217 complete\n",
      "Loss was 0.4620817098617554\n",
      "\n",
      "Training\n",
      "Epoch 218 complete\n",
      "Loss was 0.461991947889328\n",
      "\n",
      "Training\n",
      "Epoch 219 complete\n",
      "Loss was 0.461429963350296\n",
      "\n",
      "Training\n",
      "Epoch 220 complete\n",
      "Loss was 0.45404725742340085\n",
      "\n",
      "Training\n",
      "Epoch 221 complete\n",
      "Loss was 0.46577021980285643\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.19\n",
      "\n",
      "Training\n",
      "Epoch 222 complete\n",
      "Loss was 0.46419834637641905\n",
      "\n",
      "Training\n",
      "Epoch 223 complete\n",
      "Loss was 0.4619990215301514\n",
      "\n",
      "Training\n",
      "Epoch 224 complete\n",
      "Loss was 0.45885691690444946\n",
      "\n",
      "Training\n",
      "Epoch 225 complete\n",
      "Loss was 0.4558904049396515\n",
      "\n",
      "Training\n",
      "Epoch 226 complete\n",
      "Loss was 0.4588881893157959\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.51\n",
      "\n",
      "Training\n",
      "Epoch 227 complete\n",
      "Loss was 0.45972405195236205\n",
      "\n",
      "Training\n",
      "Epoch 228 complete\n",
      "Loss was 0.4622988040447235\n",
      "\n",
      "Training\n",
      "Epoch 229 complete\n",
      "Loss was 0.460434424161911\n",
      "\n",
      "Training\n",
      "Epoch 230 complete\n",
      "Loss was 0.4518742380142212\n",
      "\n",
      "Training\n",
      "Epoch 231 complete\n",
      "Loss was 0.4604783756732941\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.18\n",
      "\n",
      "Training\n",
      "Epoch 232 complete\n",
      "Loss was 0.45864589619636537\n",
      "\n",
      "Training\n",
      "Epoch 233 complete\n",
      "Loss was 0.46103686237335206\n",
      "\n",
      "Training\n",
      "Epoch 234 complete\n",
      "Loss was 0.45768075323104856\n",
      "\n",
      "Training\n",
      "Epoch 235 complete\n",
      "Loss was 0.4560935277938843\n",
      "\n",
      "Training\n",
      "Epoch 236 complete\n",
      "Loss was 0.4556603355407715\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.45\n",
      "\n",
      "Training\n",
      "Epoch 237 complete\n",
      "Loss was 0.4596887791156769\n",
      "\n",
      "Training\n",
      "Epoch 238 complete\n",
      "Loss was 0.4557250869274139\n",
      "\n",
      "Training\n",
      "Epoch 239 complete\n",
      "Loss was 0.45349787068367003\n",
      "\n",
      "Training\n",
      "Epoch 240 complete\n",
      "Loss was 0.45755471324920655\n",
      "\n",
      "Training\n",
      "Epoch 241 complete\n",
      "Loss was 0.4498160092830658\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.13\n",
      "\n",
      "Training\n",
      "Epoch 242 complete\n",
      "Loss was 0.45786971163749696\n",
      "\n",
      "Training\n",
      "Epoch 243 complete\n",
      "Loss was 0.4576155710220337\n",
      "\n",
      "Training\n",
      "Epoch 244 complete\n",
      "Loss was 0.4487341282367706\n",
      "\n",
      "Training\n",
      "Epoch 245 complete\n",
      "Loss was 0.45508477902412414\n",
      "\n",
      "Training\n",
      "Epoch 246 complete\n",
      "Loss was 0.4557281198501587\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.94\n",
      "\n",
      "Training\n",
      "Epoch 247 complete\n",
      "Loss was 0.4509774658679962\n",
      "\n",
      "Training\n",
      "Epoch 248 complete\n",
      "Loss was 0.45868888759613036\n",
      "\n",
      "Training\n",
      "Epoch 249 complete\n",
      "Loss was 0.45302852129936216\n",
      "\n",
      "Training\n",
      "Epoch 250 complete\n",
      "Loss was 0.4557033681869507\n",
      "\n",
      "Training\n",
      "Epoch 251 complete\n",
      "Loss was 0.44924506878852843\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.59\n",
      "\n",
      "Training\n",
      "Epoch 252 complete\n",
      "Loss was 0.4534767098426819\n",
      "\n",
      "Training\n",
      "Epoch 253 complete\n",
      "Loss was 0.45234842896461486\n",
      "\n",
      "Training\n",
      "Epoch 254 complete\n",
      "Loss was 0.4497673840522766\n",
      "\n",
      "Training\n",
      "Epoch 255 complete\n",
      "Loss was 0.45613578152656553\n",
      "\n",
      "Training\n",
      "Epoch 256 complete\n",
      "Loss was 0.45336993360519406\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.56\n",
      "\n",
      "Training\n",
      "Epoch 257 complete\n",
      "Loss was 0.454524742603302\n",
      "\n",
      "Training\n",
      "Epoch 258 complete\n",
      "Loss was 0.4476328556537628\n",
      "\n",
      "Training\n",
      "Epoch 259 complete\n",
      "Loss was 0.45040053415298464\n",
      "\n",
      "Training\n",
      "Epoch 260 complete\n",
      "Loss was 0.45317994832992553\n",
      "\n",
      "Training\n",
      "Epoch 261 complete\n",
      "Loss was 0.44536527395248415\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.93\n",
      "\n",
      "Training\n",
      "Epoch 262 complete\n",
      "Loss was 0.4500002098083496\n",
      "\n",
      "Training\n",
      "Epoch 263 complete\n",
      "Loss was 0.45571538972854614\n",
      "\n",
      "Training\n",
      "Epoch 264 complete\n",
      "Loss was 0.45205018877983094\n",
      "\n",
      "Training\n",
      "Epoch 265 complete\n",
      "Loss was 0.4466029660701752\n",
      "\n",
      "Training\n",
      "Epoch 266 complete\n",
      "Loss was 0.4573493320941925\n",
      "\n",
      "Testing\n",
      "Test accuracy was 83.14\n",
      "\n",
      "Training\n",
      "Epoch 267 complete\n",
      "Loss was 0.4449449944496155\n",
      "\n",
      "Training\n",
      "Epoch 268 complete\n",
      "Loss was 0.45274423360824584\n",
      "\n",
      "Training\n",
      "Epoch 269 complete\n",
      "Loss was 0.4433908674716949\n",
      "\n",
      "Training\n",
      "Epoch 270 complete\n",
      "Loss was 0.4544557282924652\n",
      "\n",
      "Training\n",
      "Epoch 271 complete\n",
      "Loss was 0.44909199833869934\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.64\n",
      "\n",
      "Training\n",
      "Epoch 272 complete\n",
      "Loss was 0.44615273976325986\n",
      "\n",
      "Training\n",
      "Epoch 273 complete\n",
      "Loss was 0.45100436806678773\n",
      "\n",
      "Training\n",
      "Epoch 274 complete\n",
      "Loss was 0.4466981518268585\n",
      "\n",
      "Training\n",
      "Epoch 275 complete\n",
      "Loss was 0.44820195364952087\n",
      "\n",
      "Training\n",
      "Epoch 276 complete\n",
      "Loss was 0.44509558749198913\n",
      "\n",
      "Testing\n",
      "Test accuracy was 81.98\n",
      "\n",
      "Training\n",
      "Epoch 277 complete\n",
      "Loss was 0.4500150015354156\n",
      "\n",
      "Training\n",
      "Epoch 278 complete\n",
      "Loss was 0.44769211649894713\n",
      "\n",
      "Training\n",
      "Epoch 279 complete\n",
      "Loss was 0.4447344536781311\n",
      "\n",
      "Training\n",
      "Epoch 280 complete\n",
      "Loss was 0.4416920557022095\n",
      "\n",
      "Training\n",
      "Epoch 281 complete\n",
      "Loss was 0.44821799635887144\n",
      "\n",
      "Testing\n",
      "Test accuracy was 82.83\n",
      "\n",
      "Training\n",
      "Epoch 282 complete\n",
      "Loss was 0.4454543046951294\n",
      "\n",
      "Training\n",
      "Epoch 283 complete\n",
      "Loss was 0.44746878242492677\n",
      "\n",
      "Training\n",
      "Epoch 284 complete\n",
      "Loss was 0.44368971800804136\n",
      "\n",
      "Training\n",
      "Epoch 285 complete\n",
      "Loss was 0.4539855053424835\n",
      "\n",
      "Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18420\\3636907201.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m     \u001B[0mepoch_loss\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;31m# if i % 1000 == 999:    # every 1000 mini-batches...\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "confusion_matrix = torch.zeros(10, 10)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "test_accuracy_per_class = pd.DataFrame(confusion_matrix.diag()/confusion_matrix.sum(1), test_data.classes, [\"Accuracy\"])\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.grid(color='black', axis='y', linestyle='dashed', zorder = 1)\n",
    "bar = plt.bar(test_accuracy_per_class.index, height=test_accuracy_per_class.Accuracy*100, zorder = 2)\n",
    "for rect in bar:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width() / 2.0, height, f'{height:.2f}%', ha='center', va='bottom', zorder = 3)\n",
    "plt.yticks(range(0, 101, 5))\n",
    "plt.axhline((confusion_matrix.diag()/confusion_matrix.sum(1)).mean()*100, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def baseline_func(input):\n",
    "  return 0\n",
    "\n",
    "visualizer = AttributionVisualizer(\n",
    "    models=[CNN],\n",
    "    score_func=lambda o: torch.nn.Dropout ,\n",
    "    features=[\n",
    "        ImageFeature(\n",
    "            \"Photo\",\n",
    "            baseline_transforms=[baseline_func],\n",
    "            input_transforms=[test_transform],\n",
    "        )\n",
    "    ],\n",
    "    dataset=test_data,\n",
    ")\n",
    "visualizer.render()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "visualizer.serve()"
   ],
   "metadata": {
    "id": "bYyMlOlfiyV6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_graph(model_copy, images)\n",
    "writer.add_image('first_visualization_test', img_grid)\n",
    "writer.close()"
   ],
   "metadata": {
    "id": "bGHX3IX3iyYc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/first_visualization_test/"
   ],
   "metadata": {
    "id": "A-g1rugJiybL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}