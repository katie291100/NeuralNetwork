{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "85% after 28 epochs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-Team2/NeuralNetwork/blob/Adam/INT2%20Group2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install captum\n",
        "pip install flask_compress\n",
        "conda install freetype=2.10.4"
      ],
      "metadata": {
        "id": "q2C1BTjcSRKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/first_visualization_test')"
      ],
      "metadata": {
        "id": "KpN-GwNSoMVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import LayerConductance\n",
        "from captum.attr import NeuronConductance\n",
        "from captum.insights import AttributionVisualizer, Batch\n",
        "from captum.insights.attr_vis.features import ImageFeature\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "0xH_hHVqFbZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): # use gpu if possible\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "FFdWQBwiFgwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# only need resize so AlexNet works\n",
        "transform = transforms.Compose([transforms.ToTensor(), \n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), \n",
        "                                                     (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "RlqjK1yMFg3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get training/test data from CIFAR10 dataset\n",
        "train_data = torchvision.datasets.CIFAR10(root = \"./dataset\", \n",
        "                                        train = True, \n",
        "                                        transform = transform, \n",
        "                                        download = True)\n",
        "test_data = torchvision.datasets.CIFAR10(root = \"./dataset\", \n",
        "                                       train = False, \n",
        "                                       transform = transform, \n",
        "                                       download = True)"
      ],
      "metadata": {
        "id": "hpne52DpFg7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397107b2-68a4-43dd-f1b6-ff14fc6ccb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = True, \n",
        "                                           num_workers = 2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = False, \n",
        "                                          num_workers = 2)"
      ],
      "metadata": {
        "id": "GQ1RfNQ9Fg9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, 128, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(128, 256, 3, 1, padding=2)\n",
        "    self.conv3 = nn.Conv2d(256, 256, 3, 1, padding=2)\n",
        "    self.conv4 = nn.Conv2d(256, 512, 3, 1, padding=1)\n",
        "    self.conv5 = nn.Conv2d(512, 512, 3, 1, padding=1)\n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3, 1)\n",
        "    self.conv7 = nn.Conv2d(1024, 1024, 3, 1)\n",
        "\n",
        "    self.maxPool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    self.drop1 = nn.Dropout(0.3)\n",
        "    self.drop2 = nn.Dropout(0.3)\n",
        "    self.drop3 = nn.Dropout(0.2)\n",
        "    self.drop4 = nn.Dropout(0.4)\n",
        "\n",
        "    self.fc1 = nn.Linear(1024, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 4096)\n",
        "    self.fc3 = nn.Linear(4096, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    i = 0\n",
        "    f = lambda i: [i+1,print(i,x.shape)][0]\n",
        "\n",
        "\n",
        "    x = nn.functional.rrelu(self.conv1(x))\n",
        "    x = self.drop1(x)\n",
        "    x = self.maxPool(x)\n",
        "    x = nn.functional.rrelu(self.conv2(x))\n",
        "    x = self.drop2(x)\n",
        "    x = self.maxPool(x)\n",
        "    x = nn.functional.rrelu(self.conv3(x))\n",
        "    x = nn.functional.rrelu(self.conv4(x))\n",
        "    x = self.drop3(x)\n",
        "    x = self.maxPool(x)\n",
        "    x = nn.functional.rrelu(self.conv5(x))\n",
        "    x = nn.functional.rrelu(self.conv6(x))\n",
        "    x = self.drop4(x)\n",
        "    x = nn.functional.rrelu(self.conv7(x))\n",
        "    #i=f(i)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    #i=f(i)\n",
        "    x = nn.functional.rrelu(self.fc1(x))\n",
        "    x = nn.functional.rrelu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    #i=f(i)\n",
        "    return x\n",
        "  "
      ],
      "metadata": {
        "id": "TxH5nWm3FhAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation\n",
        "\n",
        "model_copy = CNN()\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "7plTux-MVcJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    try:\n",
        "      npimg = img.numpy()\n",
        "    except:\n",
        "      npimg = img.cpu().data.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "metadata": {
        "id": "PXIkd1UaoJc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.cpu().data.numpy())\n",
        "    return preds, [nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 48))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            train_data.classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            train_data.classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "fqUutMIS0IEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  print(\"Testing\")\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    samples = 0\n",
        "\n",
        "    for (images, labels) in test_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      _, predictions = outputs.max(1)\n",
        "\n",
        "      samples += labels.size(0)\n",
        "      correct += (predictions == labels).sum()\n",
        "\n",
        "    print(\"Test accuracy was\",100*float(correct)/float(samples))\n",
        "    print()"
      ],
      "metadata": {
        "id": "7o82gzD7UCBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training\n",
        "\n",
        "# try other loss functions/optimizers\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.0015)\n",
        "\n",
        "test_per_epoch = True\n",
        "train_for_time = 0 # how many minutes to train for (and then finish current epoch)\n",
        "\n",
        "if train_for_time:\n",
        "  epochs = train_for_time*1000\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Training\")\n",
        "  epoch_loss = 0\n",
        "  previous_loss = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forwards\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backwards\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "\n",
        "            # ...log the running loss\n",
        "            writer.add_scalar('training loss',\n",
        "                            epoch_loss-previous_loss / 1000,\n",
        "                            epoch * len(train_loader) + i)\n",
        "\n",
        "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "            # random mini-batch\n",
        "            writer.add_figure('predictions vs. actuals',\n",
        "                            plot_classes_preds(model, images, labels),\n",
        "                            global_step=epoch * len(train_loader) + i)\n",
        "            previous_loss = epoch_loss\n",
        "  \n",
        "  print(\"Epoch\", epoch+1, \"complete\")\n",
        "  print(\"Loss was\", epoch_loss/len(train_loader))\n",
        "  print()\n",
        "  if test_per_epoch:\n",
        "    test()\n",
        "  \n",
        "  if train_for_time and time.time()-start >= train_for_time*60:\n",
        "    break\n",
        "\n",
        "if not test_per_epoch:\n",
        "  test()"
      ],
      "metadata": {
        "id": "vNIB2TF7FhDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525b6a9e-c6b2-489d-a62a-c6e3d397f15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training\n",
            "Epoch 1 complete\n",
            "Loss was 1.5382346243286134\n",
            "\n",
            "Testing\n",
            "Test accuracy was 56.87\n",
            "\n",
            "Training\n",
            "Epoch 2 complete\n",
            "Loss was 1.0675819040679932\n",
            "\n",
            "Testing\n",
            "Test accuracy was 64.51\n",
            "\n",
            "Training\n",
            "Epoch 3 complete\n",
            "Loss was 0.8741394630384445\n",
            "\n",
            "Testing\n",
            "Test accuracy was 71.57\n",
            "\n",
            "Training\n",
            "Epoch 4 complete\n",
            "Loss was 0.757213262591362\n",
            "\n",
            "Testing\n",
            "Test accuracy was 71.84\n",
            "\n",
            "Training\n",
            "Epoch 5 complete\n",
            "Loss was 0.6811322256231308\n",
            "\n",
            "Testing\n",
            "Test accuracy was 77.1\n",
            "\n",
            "Training\n",
            "Epoch 6 complete\n",
            "Loss was 0.6212235785436631\n",
            "\n",
            "Testing\n",
            "Test accuracy was 77.59\n",
            "\n",
            "Training\n",
            "Epoch 7 complete\n",
            "Loss was 0.576225539085865\n",
            "\n",
            "Testing\n",
            "Test accuracy was 78.4\n",
            "\n",
            "Training\n",
            "Epoch 8 complete\n",
            "Loss was 0.5359133397430181\n",
            "\n",
            "Testing\n",
            "Test accuracy was 80.0\n",
            "\n",
            "Training\n",
            "Epoch 9 complete\n",
            "Loss was 0.5090344622266293\n",
            "\n",
            "Testing\n",
            "Test accuracy was 78.11\n",
            "\n",
            "Training\n",
            "Epoch 10 complete\n",
            "Loss was 0.48367076645731927\n",
            "\n",
            "Testing\n",
            "Test accuracy was 80.62\n",
            "\n",
            "Training\n",
            "Epoch 11 complete\n",
            "Loss was 0.45181775357842446\n",
            "\n",
            "Testing\n",
            "Test accuracy was 81.57\n",
            "\n",
            "Training\n",
            "Epoch 12 complete\n",
            "Loss was 0.4332794177857041\n",
            "\n",
            "Testing\n",
            "Test accuracy was 82.26\n",
            "\n",
            "Training\n",
            "Epoch 13 complete\n",
            "Loss was 0.41145934684872626\n",
            "\n",
            "Testing\n",
            "Test accuracy was 81.71\n",
            "\n",
            "Training\n",
            "Epoch 14 complete\n",
            "Loss was 0.4007371741303802\n",
            "\n",
            "Testing\n",
            "Test accuracy was 81.87\n",
            "\n",
            "Training\n",
            "Epoch 15 complete\n",
            "Loss was 0.38545141189455984\n",
            "\n",
            "Testing\n",
            "Test accuracy was 81.91\n",
            "\n",
            "Training\n",
            "Epoch 16 complete\n",
            "Loss was 0.3648254494103789\n",
            "\n",
            "Testing\n",
            "Test accuracy was 82.41\n",
            "\n",
            "Training\n",
            "Epoch 17 complete\n",
            "Loss was 0.3542948328459263\n",
            "\n",
            "Testing\n",
            "Test accuracy was 82.9\n",
            "\n",
            "Training\n",
            "Epoch 18 complete\n",
            "Loss was 0.3456814255648851\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.27\n",
            "\n",
            "Training\n",
            "Epoch 19 complete\n",
            "Loss was 0.33351902460604904\n",
            "\n",
            "Testing\n",
            "Test accuracy was 81.42\n",
            "\n",
            "Training\n",
            "Epoch 20 complete\n",
            "Loss was 0.32361755277872084\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.89\n",
            "\n",
            "Training\n",
            "Epoch 21 complete\n",
            "Loss was 0.3116942642018199\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.41\n",
            "\n",
            "Training\n",
            "Epoch 22 complete\n",
            "Loss was 0.30345200253874066\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.6\n",
            "\n",
            "Training\n",
            "Epoch 23 complete\n",
            "Loss was 0.29680135213404896\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.55\n",
            "\n",
            "Training\n",
            "Epoch 24 complete\n",
            "Loss was 0.28362664476051924\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.91\n",
            "\n",
            "Training\n",
            "Epoch 25 complete\n",
            "Loss was 0.2783407899568975\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.65\n",
            "\n",
            "Training\n",
            "Epoch 26 complete\n",
            "Loss was 0.2748642555718124\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.27\n",
            "\n",
            "Training\n",
            "Epoch 27 complete\n",
            "Loss was 0.2693292506244034\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.83\n",
            "\n",
            "Training\n",
            "Epoch 28 complete\n",
            "Loss was 0.26476713247030975\n",
            "\n",
            "Testing\n",
            "Test accuracy was 85.0\n",
            "\n",
            "Training\n",
            "Epoch 29 complete\n",
            "Loss was 0.25563981776624917\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.9\n",
            "\n",
            "Training\n",
            "Epoch 30 complete\n",
            "Loss was 0.2526489550834149\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.75\n",
            "\n",
            "Training\n",
            "Epoch 31 complete\n",
            "Loss was 0.24785508151784538\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.28\n",
            "\n",
            "Training\n",
            "Epoch 32 complete\n",
            "Loss was 0.24091582105860115\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.38\n",
            "\n",
            "Training\n",
            "Epoch 33 complete\n",
            "Loss was 0.2340885305735469\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.66\n",
            "\n",
            "Training\n",
            "Epoch 34 complete\n",
            "Loss was 0.23263387931667268\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.05\n",
            "\n",
            "Training\n",
            "Epoch 35 complete\n",
            "Loss was 0.2283624532714486\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.42\n",
            "\n",
            "Training\n",
            "Epoch 36 complete\n",
            "Loss was 0.22300634900301694\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.11\n",
            "\n",
            "Training\n",
            "Epoch 37 complete\n",
            "Loss was 0.22229181648239493\n",
            "\n",
            "Testing\n",
            "Test accuracy was 84.33\n",
            "\n",
            "Training\n",
            "Epoch 38 complete\n",
            "Loss was 0.2156851466141641\n",
            "\n",
            "Testing\n",
            "Test accuracy was 83.6\n",
            "\n",
            "Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "AbcR2LteVsKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_func(input):\n",
        "  return 0\n",
        "\n",
        "visualizer = AttributionVisualizer(\n",
        "    models=[CNN],\n",
        "    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n",
        "    classes= train_data.classes,\n",
        "    features=[\n",
        "        ImageFeature(\n",
        "            \"Photo\",\n",
        "            baseline_transforms=[baseline_func],\n",
        "            input_transforms=[transform],\n",
        "        )\n",
        "    ],\n",
        "    dataset=test_data,\n",
        ")"
      ],
      "metadata": {
        "id": "P-40g8R1GmaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer.render()"
      ],
      "metadata": {
        "id": "qgisu5rhVTRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer.serve()"
      ],
      "metadata": {
        "id": "5db2qU-wDEQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_graph(model_copy, images)\n",
        "writer.add_image('first_visualization_test', img_grid)\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "fMd9orbloOCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/first_visualization_test/"
      ],
      "metadata": {
        "id": "4au1KHAVoQRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}