{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "85% after 28 epochs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-Team2/NeuralNetwork/blob/Davide3/INT2_Group2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install captum\n",
        "pip install flask_compress\n",
        "pip install tqdm\n",
        "conda install freetype=2.10.4"
      ],
      "metadata": {
        "id": "q2C1BTjcSRKV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/first_visualization_test')"
      ],
      "metadata": {
        "id": "KpN-GwNSoMVA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import LayerConductance\n",
        "from captum.attr import NeuronConductance\n",
        "from captum.insights import AttributionVisualizer, Batch\n",
        "from captum.insights.attr_vis.features import ImageFeature\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0xH_hHVqFbZR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): # use gpu if possible\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "FFdWQBwiFgwx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only need resize so AlexNet works\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                                     (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "transform_train = transforms.Compose([transforms.ToTensor(), \n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomAffine(0, (0.1, 0.1)),\n",
        "                                transforms.RandomAdjustSharpness(1.5, 0.9),\n",
        "                                transforms.RandomAutocontrast(0.9),\n",
        "                                transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                                     (0.2470, 0.2435, 0.2616))])"
      ],
      "metadata": {
        "id": "RlqjK1yMFg3A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get training/test data from CIFAR10 dataset\n",
        "train_data = torchvision.datasets.CIFAR10(root = \"./dataset\", \n",
        "                                        train = True, \n",
        "                                        transform = transform_train, \n",
        "                                        download = True)\n",
        "test_data = torchvision.datasets.CIFAR10(root = \"./dataset\", \n",
        "                                       train = False, \n",
        "                                       transform = transform, \n",
        "                                       download = True)"
      ],
      "metadata": {
        "id": "hpne52DpFg7h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "c912994c-463c-4008-bd0b-3ae8f1caa1e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-887fb5be779d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                         \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                         download = True)\n\u001b[0m\u001b[1;32m      6\u001b[0m test_data = torchvision.datasets.CIFAR10(root = \"./dataset\", \n\u001b[1;32m      7\u001b[0m                                        \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files already downloaded and verified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgz_md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# expand redirect chain if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_redirect_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_redirect_hops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# check if file is located on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_hops\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Service Unavailable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, 128, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(128, 128, 3, 1, padding=2)\n",
        "    self.conv3 = nn.Conv2d(128, 128, 3, 1, padding=2)\n",
        "    self.conv4 = nn.Conv2d(128, 128, 3, 1, padding=1)\n",
        "    self.conv5 = nn.Conv2d(128, 128, 3, 1, padding=1)\n",
        "    self.conv6 = nn.Conv2d(128, 128, 3, 1)\n",
        "    self.conv7 = nn.Conv2d(128, 256, 3, 1)\n",
        "    self.conv8 = nn.Conv2d(256, 256, 3, 1)\n",
        "\n",
        "    self.maxPool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    self.drop1 = nn.Dropout(0.3)\n",
        "    self.drop2 = nn.Dropout(0.3)\n",
        "    self.drop3 = nn.Dropout(0.2)\n",
        "    self.drop4 = nn.Dropout(0.4)\n",
        "\n",
        "    self.BN1 = nn.BatchNorm2d(128)\n",
        "    self.BN2 = nn.BatchNorm2d(128)\n",
        "    self.BN3 = nn.BatchNorm2d(256)\n",
        "\n",
        "    self.fc1 = nn.Linear(256, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = nn.functional.rrelu(self.conv1(x))\n",
        "    x = self.maxPool(x)\n",
        "    x = self.drop1(x)\n",
        "    x = nn.functional.rrelu(self.conv2(x))\n",
        "    x = self.maxPool(x)\n",
        "    x = self.drop2(x)\n",
        "\n",
        "    x = self.BN1(x)\n",
        "\n",
        "    x = nn.functional.rrelu(self.conv3(x))\n",
        "\n",
        "    x = nn.functional.rrelu(self.conv4(x))\n",
        "    x = self.maxPool(x)\n",
        "    x = self.drop3(x)\n",
        "\n",
        "    x = nn.functional.rrelu(self.conv5(x))\n",
        "    x = self.BN2(x)\n",
        "    x = nn.functional.rrelu(self.conv6(x))\n",
        "    x = self.drop4(x)\n",
        "  # x = self.BN3(x)\n",
        "\n",
        "    x = nn.functional.rrelu(self.conv7(x))\n",
        "    x = self.BN3(x)\n",
        "    x = nn.functional.rrelu(self.conv8(x))\n",
        "\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    #print(x.shape)\n",
        "    x = nn.functional.rrelu(self.fc1(x))\n",
        "    x = nn.functional.rrelu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "  "
      ],
      "metadata": {
        "id": "TxH5nWm3FhAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation\n",
        "\n",
        "model_copy = CNN()\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "7plTux-MVcJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    try:\n",
        "      npimg = img.numpy()\n",
        "    except:\n",
        "      npimg = img.cpu().data.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "metadata": {
        "id": "PXIkd1UaoJc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.cpu().data.numpy())\n",
        "    return preds, [nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 48))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            train_data.classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            train_data.classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "fqUutMIS0IEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, pbar, print_result = True):\n",
        "  print(\"Testing\")\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    samples = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      _, predictions = outputs.max(1)\n",
        "\n",
        "      samples += labels.size(0)\n",
        "      correct += (predictions == labels).sum()\n",
        "      time.sleep(0.001)\n",
        "      pbar.update(labels.size(0))\n",
        "    if print_result:\n",
        "      print(\"Test accuracy was\",100*float(correct)/float(samples))\n",
        "      print()\n",
        "    else:\n",
        "      pbar.close()\n",
        "      return 100*float(correct)/float(samples)"
      ],
      "metadata": {
        "id": "7o82gzD7UCBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
        "                                           batch_size = 2, \n",
        "                                           shuffle = True, \n",
        "                                           num_workers = 2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
        "                                          batch_size = 2, \n",
        "                                          shuffle = False, \n",
        "                                          num_workers = 2)\n",
        "def train(model, epochs, batch_size, learning_rate, weightDecay=0.0015, train_for_minutes = 0, test_per_epoch = True, print_result = True, graphs = False):\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = True, \n",
        "                                           num_workers = 2)\n",
        "  test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
        "                                          batch_size = batch_size, \n",
        "                                          shuffle = False, \n",
        "                                          num_workers = 2)\n",
        "  \n",
        "  train_pbar = tqdm(desc = \"Trained images: \", total = 50000, leave = False)\n",
        "  test_pbar = tqdm(desc = \"Tested images: \", total = 10000, leave = False)\n",
        "\n",
        "  ## Training\n",
        "\n",
        "  # try other loss functions/optimizers\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay= weightDecay)\n",
        "\n",
        "  if train_for_minutes: # how many minutes to train for (and then finish current epoch)\n",
        "    epochs = train_for_minutes*1000\n",
        "  start = time.time()\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc= \"Epochs: \"):\n",
        "    train_pbar.reset()\n",
        "    test_pbar.reset()\n",
        "    print(\"Training\")\n",
        "    epoch_loss = 0\n",
        "    previous_loss = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # forwards\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # backwards\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      if i == batch_size-1 and graphs:    # every 1000 mini-batches...\n",
        "\n",
        "          # ...log the running loss\n",
        "          writer.add_scalar('training loss',\n",
        "                            epoch_loss-previous_loss / batch_size,\n",
        "                            epoch * len(train_loader) + i)\n",
        "\n",
        "          # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "          # random mini-batch\n",
        "          writer.add_figure('predictions vs. actuals',\n",
        "                             plot_classes_preds(model, images, labels),\n",
        "                             global_step=epoch * len(train_loader) + i)\n",
        "          previous_loss = epoch_loss\n",
        "      time.sleep(0.001)\n",
        "      train_pbar.update(batch_size)\n",
        "    print(\"Epoch %i completed:\", i)\n",
        "    print(\"Loss was\", epoch_loss/len(train_loader))\n",
        "    print()\n",
        "    if test_per_epoch:\n",
        "      test(test_loader, test_pbar)\n",
        "      \n",
        "    if train_for_minutes and time.time()-start >= train_for_minutes*60:\n",
        "      break\n",
        "      \n",
        "\n",
        "  if not test_per_epoch:\n",
        "    if print_result:\n",
        "      test(test_loader, test_pbar)\n",
        "    else:\n",
        "      return (test(test_loader, test_pbar, print_result = False), epoch_loss)\n",
        "  train_pbar.close()\n",
        "  test_pbar.close()"
      ],
      "metadata": {
        "id": "vNIB2TF7FhDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "AbcR2LteVsKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_func(input):\n",
        "  return 0\n",
        "\n",
        "visualizer = AttributionVisualizer(\n",
        "    models=[CNN],\n",
        "    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n",
        "    classes= train_data.classes,\n",
        "    features=[\n",
        "        ImageFeature(\n",
        "            \"Photo\",\n",
        "            baseline_transforms=[baseline_func],\n",
        "            input_transforms=[transform],\n",
        "        )\n",
        "    ],\n",
        "    dataset=test_data,\n",
        ")"
      ],
      "metadata": {
        "id": "P-40g8R1GmaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer.render()"
      ],
      "metadata": {
        "id": "qgisu5rhVTRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer.serve()"
      ],
      "metadata": {
        "id": "5db2qU-wDEQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for weight_decay in np.arange(0.0015, 0.005, 0.0005):\n",
        "  for learning_rate in np.arange(0.0001, 0.01, 0.0005):\n",
        "    for batch_size_power in range(2, 5, 1):\n",
        "      for epochs in range(1, 11):\n",
        "        (accuracy, loss) = train(CNN().to(device), epochs, 2**batch_size_power, learning_rate, weight_decay, 0, False, False, False)\n",
        "        hparams_dict = {\"Epochs\" : epochs, \"Batch Size\": 2**batch_size_power, \"Learning Rate\" : learning_rate, \"Weight Decay\" : weight_decay}\n",
        "        writer.add_hparams(hparams_dict, {\"Accuracy\":accuracy, \"Training Loss\": loss})\n",
        "'''"
      ],
      "metadata": {
        "id": "ehHMKlYXex13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, 400, 128, 0.0001)"
      ],
      "metadata": {
        "id": "nQLnW7KehsW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, 400, 128, 0.0001)"
      ],
      "metadata": {
        "id": "peqNraIq1C9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = torch.tensor([2, 3, 5])\n",
        "indices = (torch.tensor(train_data.targets)[..., None] == classes).any(-1).nonzero(as_tuple=True)[0]\n",
        "cats_and_dogs_data = torch.utils.data.Subset(train_data, indices)\n",
        "cats_and_dogs_loader = torch.utils.data.DataLoader(cats_and_dogs_data, batch_size=16, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "QmlROFO-LPp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
        "                                          batch_size = 16, \n",
        "                                          shuffle = False, \n",
        "                                          num_workers = 2)\n",
        "  \n",
        "train_pbar = tqdm(desc = \"Trained images: \", total = 15000, leave = False)\n",
        "test_pbar = tqdm(desc = \"Tested images: \", total = 10000, leave = False)\n",
        "\n",
        "  ## Training\n",
        "\n",
        "  # try other loss functions/optimizers\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 0.0001, weight_decay= 0.0015)\n",
        "\n",
        "for epoch in tqdm(range(2), desc= \"Epochs: \"):\n",
        "    train_pbar.reset()\n",
        "    test_pbar.reset()\n",
        "    print(\"Training\")\n",
        "    epoch_loss = 0\n",
        "    previous_loss = 0\n",
        "    for i, (images, labels) in enumerate(cats_and_dogs_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # forwards\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # backwards\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      time.sleep(0.001)\n",
        "      train_pbar.update(16)\n",
        "    print(\"Loss was\", epoch_loss/len(train_loader))\n",
        "    print()\n",
        "    test(test_loader, test_pbar)\n",
        "train_pbar.close()\n",
        "test_pbar.close()"
      ],
      "metadata": {
        "id": "hD6lxaBTPgbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_graph(model_copy, images)\n",
        "writer.add_image('first_visualization_test', img_grid)\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "fMd9orbloOCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/first_visualization_test/"
      ],
      "metadata": {
        "id": "4au1KHAVoQRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, \n",
        "                                           batch_size = 16, \n",
        "                                           shuffle = True, \n",
        "                                           num_workers = 2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, \n",
        "                                          batch_size = 16, \n",
        "                                          shuffle = False, \n",
        "                                          num_workers = 2)\n",
        "  \n",
        "train_pbar = tqdm(desc = \"Trained images: \", total = 50000, leave = False)\n",
        "test_pbar = tqdm(desc = \"Tested images: \", total = 10000, leave = False)\n",
        "\n",
        "  ## Training\n",
        "\n",
        "  # try other loss functions/optimizers\n",
        "criterion = nn.CrossEntropyLoss(weight = torch.add(1, nn.functional.normalize((confusion_matrix.diag()/confusion_matrix.sum(1)).neg(),p=1.0, dim = 0).to(device)))\n",
        "optimizer = torch.optim.Adam(model.parameters(), 0.0001, weight_decay= 0.0015)\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(10), desc= \"Epochs: \"):\n",
        "  confusion_matrix = torch.zeros(10, 10)\n",
        "  with torch.no_grad():\n",
        "      for i, (inputs, classes) in enumerate(test_loader):\n",
        "          inputs = inputs.to(device)\n",
        "          classes = classes.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                  confusion_matrix[t.long(), p.long()] += 1\n",
        "  criterion.weight = torch.add(1, nn.functional.normalize((confusion_matrix.diag()/confusion_matrix.sum(1)).neg(),p=1.0, dim = 0).to(device))\n",
        "  train_pbar.reset()\n",
        "  test_pbar.reset()\n",
        "  print(\"Training\")\n",
        "  epoch_loss = 0\n",
        "  previous_loss = 0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forwards\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "      # backwards\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    time.sleep(0.001)\n",
        "    train_pbar.update(16)\n",
        "  print(\"Loss was\", epoch_loss/len(train_loader))\n",
        "  print()\n",
        "  test(test_loader, test_pbar)\n",
        "      \n",
        "train_pbar.close()\n",
        "test_pbar.close()"
      ],
      "metadata": {
        "id": "ty_tkA-qDe-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = torch.zeros(10, 10)\n",
        "with torch.no_grad():\n",
        "   for i, (inputs, classes) in enumerate(test_loader):\n",
        "          inputs = inputs.to(device)\n",
        "          classes = classes.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                  confusion_matrix[t.long(), p.long()] += 1\n",
        "test_accuracy_per_class = pd.DataFrame(confusion_matrix.diag()/confusion_matrix.sum(1), test_data.classes, [\"Accuracy\"])\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.grid(color='black', axis='y', linestyle='dashed', zorder = 1)\n",
        "bar = plt.bar(test_accuracy_per_class.index, height=test_accuracy_per_class.Accuracy*100, zorder = 2)\n",
        "for rect in bar:\n",
        "    height = rect.get_height()\n",
        "    plt.text(rect.get_x() + rect.get_width() / 2.0, height, f'{height:.2f}%', ha='center', va='bottom', zorder = 3)\n",
        "plt.yticks(range(0, 101, 5))\n",
        "plt.axhline((confusion_matrix.diag()/confusion_matrix.sum(1)).mean()*100, color='r', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NCzu20AVqcXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=test_data.classes, yticklabels=test_data.classes, square=True, annot=True, cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "vcxs7pBjoXMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}