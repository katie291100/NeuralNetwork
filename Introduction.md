Image classification is the basis of Computer Vision, with it being the backbone for many other computer vision problems. It has uses in many fields including medicine and the military.
Prior to the use of Convolutional Neural Networks for image classification, the problem was tackled using methods such as Histogram of Oriented Graphs [1] and Scale Invariant Feature Transform [2], the latter of which was used to tackle the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) in 2011 with a 24% error rate. Use of these methods has been overshadowed by CNNs as they only use two stages and the classification accuracy is heavily reliant on the feature extractor stage. In 2012 AlexNet [3], a convolutional neural network, achieved a 16% error rate on ILSVRC. As the first CNN to use the GPU to accelerate deep learning, the paper that introduces the architecture is often regarded as one of the most influential in computer vision and image classification. In the years following, new models were developed and the error rate continued to shrink, with 2021 models achieving as small as a 2% error rate. 
In this paper we aim to solve the problem of image classification by creating our own deep neural network to classify single-label images into a set of defined categories. To do this we have designed and implemented a convolutional neural network using PyTorch and have trained and tested it using the CIFAR-10 dataset with GPU acceleration. 

[1]N. Dalal and B. Triggs, "Histograms of oriented gradients for human detection," 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05), 2005, pp. 886-893 vol. 1, doi: 10.1109/CVPR.2005.177.

[2]D. G. Lowe, “Distinctive Image Features from Scale-Invariant Keypoints,” International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, Nov. 2004, doi: 10.1023/b:visi.0000029664.99615.94.

[3]A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification with deep convolutional neural networks,” Communications of the ACM, vol. 60, no. 6, pp. 84–90, May 2017, doi: 10.1145/3065386.
