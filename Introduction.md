Image classification can be considered as the fundamental problem of computer vision which is used in many fields such as medical imagery, satellite object recognition and more recently improving augmented reality [1]. 
Prior to the use of Convolutional Neural Networks for image classification, the problem was tackled using methods such as Histogram of Oriented Graphs [2] and Scale Invariant Feature Transform [3], the latter of which was used to tackle the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) in 2011 with a 24% error rate. Use of these methods has been overshadowed by CNNs as they only use two stages and the classification accuracy is heavily reliant on the feature extractor stage. In 2012 AlexNet, a convolutional neural network, achieved a 16% error rate on ILSVRC. As the first CNN to use the GPU to accelerate deep learning, the paper that introduces the architecture is often regarded as one of the most influential in computer vision and image classification. In the years following, new models were developed and the error rate continued to shrink, with 2021 models achieving as small as a 2% error rate. 
In this paper we aim to solve the problem of image classification by creating our own deep neural network to classify single-label images into a set of defined categories. To do this we have designed and implemented a convolutional neural network using PyTorch and have trained and tested it using the CIFAR-10 dataset with GPU acceleration. 

[1] Cruz, E., Orts-Escolano, S., Gomez-Donoso, F. et al. An augmented reality application for improving shopping experience in large retail stores. Virtual Reality 23, 281–291 (2019). https://doi.org/10.1007/s10055-018-0338-3

[2] N. Dalal and B. Triggs, "Histograms of oriented gradients for human detection," 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05), 2005, pp. 886-893 vol. 1, doi: 10.1109/CVPR.2005.177.

[3] Lowe, D.G. Distinctive Image Features from Scale-Invariant Keypoints. International Journal of Computer Vision 60, 91–110 (2004). https://doi.org/10.1023/B:VISI.0000029664.99615.94
